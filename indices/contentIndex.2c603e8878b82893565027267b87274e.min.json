{"/":{"title":"Morioh","content":"# Welcome :)\n\nMain hub for all the different note categories :)\n\n\u003ccenter\u003e\u003cimg src=\"https://media2.giphy.com/media/TI9HiyUqRm75jPyKQ5/giphy.gif?cid=ecf05e4799x4brmyrv3lgup74b1onq4s89nps3z3lwxmbls2\u0026rid=giphy.gif\u0026ct=g\"\u003e\u003c/center\u003e\n\n## All of my knowledge ðŸ˜¬\n- [Hub](notes/knowledge-hub.md)\n\n## Work\n- [Hub](notes/work-hub.md)\n\n## University\n- [Hub](notes/university-hub.md)\n","lastmodified":"2022-07-02T12:03:24.336674244Z","tags":null},"/notes/2-3-trees":{"title":"2-3 Trees","content":"# 2-3 Trees\n---\nA tree, where every internal node has either:\n- two children and one data element (2-node); or\n- three children and two data elements (3-node).\n\nLeaf nodes have no children and one or two data elements.\n\n**2-3 trees are required to be balanced**.\n\n![](content/images/2-3-tree.png)\n","lastmodified":"2022-07-02T12:03:24.352674319Z","tags":null},"/notes/admonition-cheatsheet":{"title":"Admonition Cheatsheet","content":"# Admonition Cheatsheet\n---\n```\nad-\u003ctype\u003e # Admonition type. \ntitle: # Admonition title.\ncollapse: # Create a collapsible admonition.\nicon: # Override the icon.\ncolor: # Override the color.\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla.\n```\n\n## Code Block\n```ad-bug\ntitle: I'm a bug!\n~~~javascript\nthrow new Error(\"Oops, I'm a bug.\");\n~~~\n```\n\n## Nested\n````ad-info\n\n```ad-bug\ntitle: I'm Nested!\n~~~javascript\nthrow new Error(\"Oops, I'm a bug.\");\n~~~\n```\n\n```javascript\nconsole.log(\"Hello!\");\n```\n\n````\n\n## Admonition Types\n\nThe following admonition types are currently supported:\n\n| Type     | Aliases                     |\n| -------- | --------------------------- |\n| note     | note, seealso               |\n| abstract | abstract, summary, tldr     |\n| info     | info, todo                  |\n| tip      | tip, hint, important        |\n| success  | success, check, done        |\n| question | question, help, faq         |\n| warning  | warning, caution, attention |\n| failure  | failure, fail, missing      |\n| danger   | danger, error               |\n| bug      | bug                         |\n| example  | example                     |\n| quote    | quote, cite                 |\n\n---\nMore info [here](https://squidfunk.github.io/mkdocs-material/reference/admonitions/) and [here is the repo](https://github.com/valentine195/obsidian-admonition).","lastmodified":"2022-07-02T12:03:24.352674319Z","tags":null},"/notes/algorithms-and-data-structure":{"title":"Algorithms and Data Structure","content":"# Algorithms and Data Structure\n---\n## Topics\n- [Sets and Maps](notes/sets-and-maps.md)\n- [Vectors and Arrays](notes/vectors-arrays.md)\n- [Big O Notation](notes/big-o-notation.md)\n- [Lists](notes/lists.md)\n- [Stacks and Queues](notes/stacks-and-queues.md)\n- [Hash Tables](notes/hash-tables.md)\n- [Trees](notes/trees.md)\n- [Sorting](notes/sorting.md)\n- [Graphs](notes/graphs.md)\n    - [Minimum Spanning Subtree](notes/minimum-spanning-subtree.md)\n    - [Dijkstra](notes/dijkstra-algorithm.md)\n    - [Floyd-Warshall](notes/floyd-warshall.md)\n    - [Inkblot](notes/inkblot-algorithm.md)\n- [Garbage Collection](notes/garbage-collection.md)\n- [Problems](notes/cs-problems.md)\n\n### Extra Resources\n- [Visualisation](https://visualgo.net/en)\n- [Youtube Course in Java 1](https://www.youtube.com/playlist?list=PLpPXw4zFa0uKKhaSz87IowJnOTzh9tiBk)\n- [Youtube Course in Java 2](https://www.youtube.com/watch?v=RBSGKlAvoiM)\n- [Princeton Course](https://www.youtube.com/watch?v=RBSGKlAvoiM)\n- [Java MOOC by University of Helsinki](https://java-programming.mooc.fi/)\n\n## Mathematical Algorithms\n- [Linear Equations](notes/linear-equations.md)\n- [Newton-Raphson Iteration](notes/newton-raphson.md)","lastmodified":"2022-07-02T12:03:24.352674319Z","tags":null},"/notes/ambiguous-grammars":{"title":"Ambiguous Grammars","content":"# Ambiguous Grammars\n---\nAn ambiguous grammar permits more than one parse [tree](notes/trees.md) for some sentences. For example, parsing **xxx** with the following grammar:\n\nS $\\rightarrow$ AA\nA $\\rightarrow$ x | xx\n\nBut useful:\n\nexpression $\\rightarrow$ expression binop expression | integer\nbinop $\\rightarrow$ + | - | * | /\n\nUse rules (e.g. BODMAS) to disambiguate, and/or rewrite:\n\nexpression $\\rightarrow$ expression termop term | term\ntermop $\\rightarrow$ + | -\nterm $\\rightarrow$ term factorop integer | integer\nfactorop $\\rightarrow$ * | /\n\n## See Also\n- [Formal Languages](notes/formal-languages.md)","lastmodified":"2022-07-02T12:03:24.352674319Z","tags":null},"/notes/b-trees":{"title":"B-Trees","content":"# B-Trees\n---\nA B-tree of order **m** has the following properties:\n- every node has at most **m** children.\n- every non-leaf node (except root) has at least **m/2** children.\n- the root has at least 2 children if its not a leaf.\n- a non-leaf node with **k** children contains **k**-1 data elements.\n- all leaves appear in the same level and carry no information.\n\n## Sorted B-Trees\nIf the data elements of a node are $a_1$, $a_2$, ..., $a_n$, then:\n* all elements in the leftmost subtree will be **less than** $a_1$.\n* all elements in the rightmost subtree will be **greater than** $a_n$.\n* all elements in the subtree between $a_{k-1}$ and $a_k$ will be **greater than** $a_{k-1}$ and **less than** $a_k$.\n\n**2-3 trees are B-trees of order 3**.\n\nB-trees are useful where data is in large blocks, hence databases and filesystems.","lastmodified":"2022-07-02T12:03:24.352674319Z","tags":null},"/notes/big-o-notation":{"title":"Big O Notation","content":"# Big O Notation\n---\nIt describes how the performance of an algorithm scales with the size of the problem.\n\n[](notes/compiler-optimisation.md#Performance|Performance) may be **time to execute** or **amount of memory**.\n\nSize must be a quantitative measure of the scale of the problem. For example:\n- Number of items to sort.\n- Number of nodes in a graph.\n\nAn everyday example would be `n` people shaking hands in a room where the **number of handshakes** is $O(n^2)$ and **time to shake hands** is $O(n)$.\n\n## Performance Families\n![](content/images/5067FFC5-4A77-4CF9-A02B-8E0619F149B9.jpeg)\n\nClassifications ordered by **decreasing** efficiency:\n- Constant: O(1)\n- Logarithmic: O($log_n$)\n- Sublinear: O($n^d$) for d \u003c 1\n- Linear: O(n)\n- Linearithmic: O($n log_n$)\n- Quadratic: O($n^2$)\n- Exponential: O($2^n$)\n","lastmodified":"2022-07-02T12:03:24.352674319Z","tags":null},"/notes/binary-heap":{"title":"Binary Heap","content":"# Binary Heap\n---\nA binary heap is a form of [binary tree](notes/binary-trees.md), with two additional properties:\n\n- It is a **complete** binary tree, meaning that all levels of the tree (except possibly the last one) are full.\n    - If not complete, the last level is filled from left to right.\n\n- The data stored in each node is greater than or equal to the data in the node's **children**.\n    - With the variant which is less than or equal.\n\n![](content/images/binary-heap.png)\n\n## Binary Heap Representation\nUse an array with **N** elements.\n\n- Root at index 0.\n- Children of node at index **i** at $2i+1$ and $2i + 2$\n- Parent of node at index **i** at $floor((i-1)/2)$.\n\n![](content/images/binary-heap-representation.png)\n\n## Reference\n- [Heapsort](notes/heapsort.md)\n","lastmodified":"2022-07-02T12:03:24.352674319Z","tags":null},"/notes/binary-trees":{"title":"Binary Trees","content":"# Binary Trees\n---\nA binary tree is a set of _nodes_ linked into a simple structure. Every node has at most two children.\n\n- Each node has **data**, a **left pointer** and a **right pointer**.\n- Each **pointer** can point to one other node (or be NULL).\n\n![](content/images/binary-tree.png)\n\n## Nomenclature\n- A node is the **parent** of any node to which it pointer.\n- A node is the **child** of any node that points to it.\n- A node can be a **child** and a **parent**.\n- A node is the **root** of the tree if it has **no parent**.\n- A node is a **leaf** is it has **no children**.\n\n![](content/images/binary-tree-example.png)\n\n## Searching\n```bash\n23 57 62 123 159 194 215 274 287 384\n```\n![](content/images/binary-tree-search.png)\n\n### In code\n```c\nstruct node {\n  node *left;\n  node *right;\n  int data;\n};\n\nnode *\ntreesearch (node *n, int *k) {\n  if (NULL = n) {\n    return NULL;\n  }\n  else if (k == n.data) {\n    return n;\n  }\n  else if (k \u003c n.data) {\n    return treesearch (node-\u003eleft, k)\n  }\n  else {\n    return treesearch (node-\u003eright, k)\n  }\n}\n```\n\n## Tree Traversal\nDepth first (**inorder** or infix):\n- left subtree.\n- root.\n- right subtree.\n\n Depth first (**preorder** or prefix):\n - root.\n - left subtree.\n - right subtree.\n\nDepth first (**postorder** or postfix):\n- left subtree.\n- right subtree.\n- root.\n\nBreath first:\n- all roots at each level in turn.\n- to do efficiently needs the right representation.\n\n### Direction of Traversal\nAll traversals can be right to left instead.\n\n- R-\u003eL inorder is the inverse of L-\u003eR inorder.\n- R-\u003eL preorder is the inverse of L-\u003eR postorder.\n- R-\u003eL postorder is the inverse of L-\u003eR preorder.\n\n![](content/images/binary-tree-expr.png)\n","lastmodified":"2022-07-02T12:03:24.352674319Z","tags":null},"/notes/bubble-sort":{"title":"Bubble Sort","content":"# Bubble Sort\n---\nBubble sort is $O(n_2)$ meaning it is:\n- efficient if **n** is small.\n- efficient if the array is mostly sorted.\n\nIt is a **stable** sort.\n\n```c\n#define N 5\n\nvoid swap (int *a, int *b) {\n  int t = *a;\n  *a = *b;\n  *b = t;\n}\n\nint main () {\n  int a[N];\n  int j, k;\n\n  for (k=1; k\u003cN; k++) {\n  for (j=k; (j\u003e0) \u0026\u0026 (a[j] \u003c a[j-1]); j--)\n    swap (\u0026(a[j]), \u0026(a[j-1]));\n  }\n}\n```\n\nOutput:\n```bash\n$ ./bubble5\n96 96 20 94 9\n96 20 96 94 9\n20 96 96 94 9\n20 96 94 96 9\n20 94 96 96 9\n20 94 96 9 96\n20 94 9 96 96\n20 9 94 96 96\n9 20 94 96 96\n```\n\n## Code Example\n```c\n/* Basic bubble sort\n\n   Copyright (C) 2020 Embecosm Limited \u003cwww.embecosm.com\u003e\n   Contributor: Jeremy Bennett \u003cjeremy.bennett@embecosm.com\u003e\n   SPDX-License-Identifier: GPL-3.0-or-later */\n\n#include \u003cstdlib.h\u003e\n#include \u003cstdio.h\u003e\n\n#ifndef N\n#define N 5\n#endif\n\nvoid\npopulate (int arr[])\n{\n  for (int i = 0; i \u003c N; i++)\n    arr[i] = rand () % 100;\n}\n\nvoid\nswap (int *a, int *b)\n{\n  int t = *a;\n  *a = *b;\n  *b = t;\n}\n\nvoid\ndump_array (int arr[])\n{\n  for (int i = 0; i \u003c N; i++)\n    printf (\"%d \", arr[i]);\n\n  printf (\"\\n\");\n}\n\nint\nmain ()\n{\n  int a[N];\n  int j, k;\n\n  srand (561U);\n\n  populate (a);\n  dump_array (a);\n\n  for (k = 1; k \u003c N; k++)\n    for (j = k; (j \u003e 0) \u0026\u0026 (a[j] \u003c a[j - 1]); j--)\n      {\n\tswap (\u0026(a[j]), \u0026(a[j - 1]));\n\tdump_array (a);\n      }\n\n  return 0;\n}\n\n/*\nLocal Variables:\nmode: C\nc-file-style: \"gnu\"\nEnd:\n*/\n```","lastmodified":"2022-07-02T12:03:24.352674319Z","tags":null},"/notes/bucket-sort":{"title":"Bucket Sort","content":"# Bucket Sort\n---\nGenerally you can't do better than $O_{n\\ log\\ n}$ with **binary comparison**.\n\nHowever, can do better if the structure of the data is known, which allows to sort it into **buckets** in a single operation.\n\nFor example:\n- Integers (buckets on digits), a.k.a. [_radix_ sort](https://en.wikipedia.org/wiki/Radix_sort).\n- Words (buckets on letters).\n\nThe [](notes/compiler-optimisation.md#Performance|performance) for bucket for on a given number of digit is $O_{_(n)}$ but also $O_(d)$ in the number of digits.\n\nIt is [](notes/sorting.md#Stability|stable).\n\n## Example\n```bash\n```\n\nStart by sorting on the least significant digit:\n| Bins | Sublist       |\n| ---- | ------------- |\n| 0    |               |\n| 1    |               |\n| 2    | 472  432      |\n| 3    |               |\n| 4    | 254  534  654 |\n| 5    |               |\n| 6    |               |\n| 7    | 477           |\n| 8    |               |\n| 9    | 459  649  239 | \n\nThen we go to the second digit, preserving ordering from first sort:\n| Bins | Sublist       |\n| ---- | ------------- |\n| 0    |               |\n| 1    |               |\n| 2    |               |\n| 3    | 432  534  239 |\n| 4    | 649           |\n| 5    | 654  254  459 |\n| 6    |               |\n| 7    | 472  477      | \n| 8    |               |\n| 9    |               |\n\nAnd then finally on the third digit, again preserving ordering:\n| Bins | Sublist            |\n| ---- | ------------------ |\n| 0    |                    |\n| 1    |                    |\n| 2    | 239  254           |\n| 3    |                    |\n| 4    | 432  459  472  477 |\n| 5    | 534                |\n| 6    | 649  654           |\n| 7    | 472  477           |\n| 8    |                    |\n| 9    |                    |","lastmodified":"2022-07-02T12:03:24.352674319Z","tags":null},"/notes/chomsky-grammars":{"title":"Chomsky Grammars","content":"# Chomsky Grammars\n---\nType 0 (free) grammars:\n- Productions of the form u $\\rightarrow$ v, where:\n    - **u**, **v** are arbitrary string in **V**.\n    - **u** is non-null.\n\nType 1 (context-sensitive) grammars:\n- Productions of the form uXw $\\rightarrow$ uvw, where:\n- X $\\exists$ N\n- **u**, **v**, **w** are arbitrary strings in V.\n- v is non-null.\n\nType 2 (context-free) grammars:\n- Productions of the form X $\\rightarrow$ v, where:\n- X $\\exists$ N\n- v is an arbitrary string in V\n\nType 3 (regular or free) grammars:\n- Productions of the form X $\\rightarrow$ a or X $\\rightarrow$ aY, where:\n- X, Y $\\exists$ N\n- a $\\exists$ T\n\nAll **Type 2** grammars can be parsed, but there are some subsets, commonly used for programming language definition - which can be parsed particularly efficiently.\n\nAlthough **Type 3** grammars are not powerful enough for complete languages, they are widely used to define the lexical elements of a programming language. They can be parsed very efficiently, in particular by a **finite state machine**.\n\n## See Also\n- [Formal Languages](notes/formal-languages.md)","lastmodified":"2022-07-02T12:03:24.352674319Z","tags":null},"/notes/code-generation":{"title":"Code Generation","content":"# Code Generation\n---\nThe first part of a [compiler](notes/compilers.md) analyses the source code into a structure that carries the meaning of the program; this structure is generally the abstract syntax tree that's been checked and decorated","lastmodified":"2022-07-02T12:03:24.352674319Z","tags":null},"/notes/compiler-flags":{"title":"Compiler Flags","content":"# Compiler Flags\n---\nAn industrial-strength [compiler](notes/compilers.md) like GCC and LLVM has hundreds of flags that affect how the [compiler](notes/compilers.md) behaves. There are many types of [compiler](notes/compilers.md) flags and there is no easy way to classify types of [compiler](notes/compilers.md) flags. But, for simplicity, we attempt to classify the flags to make it easier to understand different kinds of flags briefly:\n\n### Optimisation flags\nFlags like `-O2`, `-O3`, `-funroll-loops` can be classified as optimisation flags, as they provide the [compiler](notes/compilers.md) with what optimisations to perform.\n\n### Diagnostic flags\nFlags like `-Wall`, `-Werror`, `-Wnull-dereference` affect the diagnostic outputs by the [compiler](notes/compilers.md).\n\n### Tuning parameters\nFlags like `--param max-inline-insns-small=70`Â take different values, often numeric, to tune how much of a specific optimisation will be performed.\n    \n### Instrumentation flags\nFlags like `-finstrument-function`, `-profile-generate` enables [compiler](notes/compilers.md) instrumentation. The instrumented binary will collect runtime profiles that can help with optimisations, detecting bugs, etc.\n    \n### Linker flags\nFlags like `-lpthread`, which is a flag used by the linker to find symbol definitions, make optimisation decisions, etc.\n    \n### Value supplying flags\nFlags like `-D`, `-fprofile-use`, `-stdlib=libstdc++`, supply additional input to the [compiler](notes/compilers.md) that can help with optimisation, diagnostics, instrumentations, etc.\n\n## Optimising for Performance\n[Compilers](notes/compilers.md) offer various optimisations to improve performance and/or reduce code size. A set of [compiler](notes/compilers.md) optimisations are put together in umbrella [compiler](notes/compilers.md) flags referred to as â€˜optimisation levelsâ€™. The following [compiler](notes/compilers.md) optimisation levels are common among most compilers:\n\n### -O0\nThis is the trivial case where no [compiler](notes/compilers.md) optimisation is performed. However, language-specific optimisations as mandated by the standard are still performed. For example, **compile-time** evaluations required by the C++ standard are still performed. This level is very useful for debugging purposes when combined with the `-g` [compiler](notes/compilers.md) flag. As `-O0` does not perform optimisations, **compile-time** is the fastest which is quite useful for iterative development.\n\n### -O1\nAt this level, many optimisations are enabled that improve the performance of the program. For example, loop unrolling, inlining, instruction scheduling, etc. This optimisation level is rarely used as more aggressive optimisation levels are available now.\n\n### -O2\nThis is one of the most popular optimisation levels. It enables all of `-O1` optimisations, as well as more aggressive optimisations in register allocation, instruction scheduling, partial redundancy elimination, etc. This level is used in building code dominated with branches, for example operating systems.\n\n### -O3\nThis level includes all of `-O2`, as well as some of the modern optimisations like vectorisation. `-O3` is the de facto optimisation level for maximising the performance of most applications. `-O3` is also used for benchmarking purposes, as it will have all the â€˜battle-testedâ€™ [compiler](notes/compilers.md) optimisations.\n\n### -Ofast\nThis is simply `-O3` with `-ffast-math`. The `-ffast-math` flag tells the [compiler](notes/compilers.md) to relax some requirements of floating-point arithmetic, like associativity and commutativity. In many applications, the errors introduced after relaxing this requirement are tolerable at the benefit of higher performance. Without `-ffast-math`, many loops with floating-point operations canâ€™t be vectorised.\n\n### -Os\n`-Os` optimises for **code size**. So, most of the optimisations that increase code size will be less aggressive at this level. This is a popular optimisation among embedded systems and mobile applications, as code size is a big concern there.\n\n### -g\nTo be able to debug an application with source code annotations, the [compiler](notes/compilers.md) needs to provide additional information in the binary. The `-g` flag tells the [compiler](notes/compilers.md) to do that. Without this flag, the debugger will only show global symbol names and the disassembly, as it cannot associate a source line of code with the assembly.\n\n### -Og\nThis enables debugging capabilities just like `-g`, but it also enables some [compiler](notes/compilers.md) optimisations that benefit debugging, as opposed to `-O0`. So instead of `-O0 -g`, it is preferable to use `-Og`. Because `-Og` enables some optimisations, the application under test runs faster than `-O0`, so the turnaround time for testing may be better with it.\n\n### -finstrument-functions\nThis flag is used to instrument the entry and exit of functions. Instrumentation allows us to get insights into the behaviour of programs. While using this flag, we also need to define two functions `__cyg_profile_func_enter` and `__cyg_profile_func_exit`, which are called respectively at the entry and exit of each function invocation. If there are functions that should not be instrumented, `__attribute__((no_instrument_function))` can be added to them.\n\n### -fprofile-generate, -fprofile-arcs, -pg\nThese flags are used in order to instrument programs to collect runtime profiles of different program points. This allows the [compiler](notes/compilers.md) to do profile-guided optimisations in subsequent compilations. Depending on which flags you use, different types of instrumentation can be achieved. For a detailed overview of various flags see theÂ [gcc(1) - Linux manual page](https://man7.org/linux/man-pages/man1/gcc.1.html).\n\n### -fstack-protector, -fstack-protector-all, -fstack-protector-strong\nThese options instrument vulnerable functions by inserting guard variables onto its stack frame. Before the function returns, the guard variable is checked to make sure it wasnâ€™t overwritten, thus making sure the stack wasnâ€™t corrupted. \n\nThis is a trivial way to improve buffer overflow attacks. This however may increase the code size of the application. In case this creates an overhead, you may only want to compile security-critical parts of the application with this [compiler](notes/compilers.md) flag. More details about how to use this flag can be found [here](https://www.keil.com/support/man/docs/armclang_ref/armclang_ref_cjh1548250046139.htm).\n\n## Optimisation for Code Size Reduction\nHere are the most common compiler optimisations that can reduce a fair amount of binary size. All the flags mentioned here are widely used in the industry.\n\n- `-Os`: Explained [](notes/compiler-flags.md#-Os|here).\n- `-Wl`,`--strip-all` (Or do not pass the `-g` flag): This flag tells the linker to remove the debug section.\n- `-fno-unroll-loops`: Disable loop unrolling, which is one of the popular compiler optimisations for performance and it increases code size.\n- `-fno-exceptions`: Removes exception handling code from the binary. Note that this is not always possible if there is code that â€˜throwsâ€™.\n- `lto (-flto)`: Enabling link-time optimisations with `-flto` results in aggressive compiler optimisations. Many functions and global variables get optimised away, many call sites get de-virtualised. The resulting binary is faster and smaller at the same time. There could be significant compile-time overheads.","lastmodified":"2022-07-02T12:03:24.352674319Z","tags":null},"/notes/compiler-instrumentation":{"title":"Compiler Instrumentation","content":"# Compiler Instrumentation\n---\nAs the [compiler](notes/compilers.md) transforms the source code, it can also 'insert' additional code into a program. These transformations are called [compiler](notes/compilers.md) instrumentation. There are many uses of [compiler](notes/compilers.md) instrumentation, one of the common purposes is to collect the 'runtime profile' of a program. \n\nTo collect the runtime profile, a [compiler](notes/compilers.md) would insert 'counters' at certain parts of the program and those counters would increment every time the program execution reaches the site of instrumentation. \n\nAfter the program is finished, the counters can be used to understand the performance profile. The hottest parts of the program are most interesting to performance engineers.\n\n## Using Compiler Instrumentation\nCompilers can insert â€˜countersâ€™ at interesting program points to collect runtime profiles. The code is instrumented by passing `-fprofile-generate` to the compiler.\n\n```bash\n$ gcc -O2 -fprofile-generate=/path/to/outputfile test.c -o a.out\n```\n\nBecause of instrumentation, the application itself will then log events/counters that can be used by the compiler during the next compilation. After the program exits, it will create a file in the `/path/to/outputfile/` directory with `.gcda` extension. Then recompiling the application with `-fprofile-use=/path/to/outputfile` will result in an optimised program.\n\n```bash\n$ gcc -O2 -fprofile-use=/path/to/outputfile test.c -o b.out\n```\n\n`b.out` is optimised with profile information. The compiler often optimises the code layout, function inlining, and loops with profile information. It is common to see performance improvements of over 10% with PGO (Profile-Guided Optimisation).","lastmodified":"2022-07-02T12:03:24.352674319Z","tags":null},"/notes/compiler-optimisation":{"title":"Compiler Optimsation","content":"# Compiler Optimisation\n---\n[Compilers](notes/compilers.md) perform a set of transformations on the source code. While some of the transformations are necessary to generate machine code, most of the transformations are done to improve the performance of programs or to reduce the code size. \n\nThese transformations are called _compiler optimisations_. This chapter introduces both types of compiler optimisations. The goal of this chapter is to enable learners to use the optimisations effectively. We do not discuss how these optimisations are implemented in the [compilers](notes/compilers.md).\n\n## Performance\nWhen we talk about the performance of an application, we generally refer to how much time it takes to do a certain task. \n\nAn application needs to perform tasks within a reasonable amount of time to be practically useful. In many cases, we want applications to run as fast as possible. Although there are several ways to improve the performance of applications, one of them is taking advantage of compiler optimisation techniques. \n\nIt should be noted that not all parts of a program need to be performant to be practically usable. Only certain parts often called a â€˜bottleneckâ€™ need to be as performant as possible.\n\n## Flags\n- [](notes/compiler-flags.md#Optimising%20for%20Performance|Optimisation%20flags)\n\n## Optimising Programs for Code Size\nThe code size of embedded applications has been a concern for a very long time. While storage becomes cheaper and smaller, developers find creative ways to increase code size by adding features or unnecessary software engineering. \n\nCompilers have come a long way in optimising applications for code size. While most compiler optimisations were focused on application performance, we have seen an increase in code size optimisations in recent years.\n\n### Measuring Code Size and Different Sections\nThere are three popular tools to measure the code size of a binary.\n\n1.  Size:Â [GNU Binutils](https://www.gnu.org/software/binutils/)\n2.  Strings: [GNU Binutils](https://www.gnu.org/software/binutils/)\n3.  [Bloaty](https://github.com/google/bloaty)\n\n#### Size  \nThe size utility can show the size of each section of a binary.\n\n```bash\n$ size gcc/11/libstdc++.dylib\n\n__TEXTÂ  Â  __DATAÂ  Â  __OBJCÂ  Â  othersÂ  Â  decÂ  Â  hex  \n1703936Â  Â  65536Â  Â  0Â  Â  1851392Â  Â  3620864Â  Â  374000\n```\n\n#### Strings  \nShows all the strings in a binary.\n\n```bash\n$ strings gcc/11/libstdc++.dylib | wc -l\n\n2180\n```\n\n#### Bloaty\nThis can be used to have a deeper analysis of binaries for different platforms. It even annotates code size to the source file to help better discover code-size opportunities.\n\n```bash\n$ bloaty gcc/11/libstdc++.dylib\n\nÂ  Â  Â FILE SIZEÂ  Â  Â VM SIZE**  \n--------------Â  -------------- \nÂ 29.1%Â  1.00MiÂ  29.0%. 1.00MiÂ  Â __TEXT,__text \nÂ 25.0%Â  Â 882KiÂ  25.0%Â  Â 882KiÂ  Â String Table \nÂ 16.6%Â  Â 583KiÂ  16.5%Â  Â 583KiÂ  Â Symbol Table \nÂ 12.3%Â  Â 433KiÂ  12.2%Â  Â 433KiÂ  Â __TEXT,__eh_frame \nÂ  5.0%Â  Â 176KiÂ  Â 5.0%Â  Â 176KiÂ  Â Export Info\nÂ  4.1%Â  Â 146KiÂ  Â 4.1%Â  Â 146KiÂ  Â __TEXT,__consts \nÂ  2.5%Â  87.8KiÂ  Â 2.5%Â  87.8KiÂ  Â Weak Binding Infos \nÂ  1.2%Â  41.6KiÂ  Â 1.2%Â  41.6KiÂ  Â __DATA,__gcc_except_tabs \nÂ  1.0%Â  36.9KiÂ  Â 1.0%Â  36.9KiÂ  Â __DATA_CONST,__consts \nÂ  0.9%Â  33.3KiÂ  Â 0.9%Â  33.3KiÂ  Â __TEXT,__text_colds\nÂ  0.5%Â  16.1KiÂ  Â 0.5%Â  16.1KiÂ  Â [10 Others]s \nÂ  0.5%Â  15.9KiÂ  Â 0.0%Â  Â  Â 945Â  Â [__DATA]s \nÂ  0.4%Â  15.0KiÂ  Â 0.4%Â  15.0KiÂ  Â __TEXT,__cstrings \nÂ  0.0%Â  Â  4Â  Â  Â  0.3%Â  11.3KiÂ  Â [__LINKEDIT]s \nÂ  0.0%Â  Â  0Â  Â  Â  0.2%Â  8.12KiÂ  Â __DATA,__bss  \nÂ  0.2%Â  8.01KiÂ  Â 0.2%Â  8.01KiÂ  Â [__DATA_CONST]s \nÂ  0.2%Â  7.43KiÂ  Â 0.2%Â  7.43KiÂ  Â Function Start Addressess \nÂ  0.0%Â  Â  0Â  Â  Â  0.2%Â  6.88KiÂ  Â __DATA,__commons \nÂ  0.2%Â  6.08KiÂ  Â 0.2%Â  6.08KiÂ  Â Indirect Symbol Tables \nÂ Â 0.1%Â  4.59KiÂ  Â 0.1%Â  4.59KiÂ  Â __DATA,__la_symbol_ptrs \nÂ  0.1%Â  3.44KiÂ  Â 0.1%Â  3.44KiÂ  Â __TEXT,__stubs100.0%Â  3.44Mi 100.0%Â  3.45MiÂ  Â TOTAL\n```","lastmodified":"2022-07-02T12:03:24.352674319Z","tags":null},"/notes/compiler-toolchains":{"title":"Compiler Toolchains","content":"# Compiler Toolchains\n---\n- [GCC Toolchain](notes/gcc.md)\n- [LLVM Toolchain](notes/llvm.md)\n- [RISC-V Toolchain](notes/riscv-toolchain.md)\n- [CORE-V Toolchain](notes/corev-toolchain.md)\n\n## What is a Compiler Toolchain?\nA compiler toolchain is a set of tools, supporting libraries, and header files that help build a program from source to an executable that can run on a machine.\n\nHave you ever wondered what dependencies are required to compile a simple `hello-world` program? Even a small `hello-world` program needs a set of header files and libraries that are used by the compiler. \n\nThe header file (e.g., `iostream`), is required to find the declaration of functions that are not available in the `hello-world` program (e.g, `std::cout`). \n\nThe libraries are required to find definitions of functions (e.g., `std::operator\u003c\u003c`) during the linkage process. As a result of the compilation process, an executable is created and runs on the machine.\n\n## The Compilation Process\nWhen a compiler like g++ is used to compile a C++ program, the compilation process actually involves multiple steps depending on what output is desired. To see the steps involved in the compilation process, `-v` needs to be passed to the compiler. \n\nWe can use a small `hello-world` program like the following to understand the compilation process:\n\n```c\n#include\u003ciostream\u003e  \nint main() {  \nÂ  Â std::court \u003c\u003c \"Hello world\\n\";  \nÂ  Â return 0;  \n}\n```\n\nLetâ€™s inspect the output of the invocation of the g++ compiler by enabling the verbose output. Although the verbose invocation outputs a lot of information, the relevant lines are the compiler invocation, the assembler invocation, and the linker invocation. \n\nDidnâ€™t we say just before that `g++ hello.cpp` was a compiler invocation? That is partially true because g++ is not a compiler, it is a _compiler-driver_. This may sound strange to many, but that is true. A _compiler-driver_ is a program that invokes different tools in the compiler toolchain to translate source code to a target language.\n\nThe compiler in this case is `cclplus` and the invocation is below.\n\n```bash\n$ g++ hello.cpp -v  \n/usr/lib/gcc/x86_64-linux-gnu/7/cc1plus -quiet -v -imultiarch  \nx86_64-linux-gnu -D_GNU_SOURCE hello.cpp -quiet -dumpbase hello.cpp  \n-mtune=generic -march=x86-64 -auxbase hello -version  \n-fstack-protector-strong -Wformat -Wformat-security -o /tmp/ccWH0EQc.s  \n...  \nGGC heuristics: --param ggc-min-expand=100 --param  \nggc-min-heapsize=131072  \nignoring duplicate directory \"/usr/include/x86_64-linux-gnu/c++/7\"  \nignoring nonexistent directory \"/usr/local/include/x86_64-linux-gnu\"  \nignoring nonexistent directory  \n\"/usr/lib/gcc/x86_64-linux-gnu/7/../../../../x86_64-linux-gnu/include\"  \ninclude \"â€¦\" search starts here:  \ninclude \u003câ€¦\u003e search starts here:  \n/usr/include/c++/7  \n/usr/include/x86_64-linux-gnu/c++/7  \n...\n```\n\nAs we can see from the command, the compiler compiles `hello.cpp` and outputs assembly code in the file `/tmp/ccWH0EQc.s`. During the compilation,Â `cc1plus` needs to find the header file `iostream`, which is present in `/usr/include/c++/7`.\n\nNext up is the assembler invocation. It reads the output of the compiler (i.e., `/tmp/ccWH0EQc.s`) and outputs an 'object-file'Â `/tmp/ccTpqU8Z.o`. The assembler does not have any dependencies:\n\n```bash\n/usr/bin/x86_64-linux-gnu-as -v --64 -o /tmp/ccTpqU8Z.o /tmp/ccWH0EQc.s**\n```\n\nAnd lastly, we have the linker invocation. The linker `collect2` reads the output of assembler `/tmp/ccTpqU8Z.o`, an object file, and outputs the executable. The linker has a lot of dependencies. \n\nThe most interesting ones are the runtime support files viz. `crt1.o`, `crti.o`, `crtendS.o`, `crtn.o` and the standard libraries `libc`, `libgcc`, `libgcc_s`, `libm`, etc. See if you can spot how these dependencies are passed to the linker. Now the linker needs to know where these files are; actually, the compiler-driver g++ needs to know where these files are such that it can invoke the linker with appropriate libraries (see the flags starting with `-l`) and appropriate paths (see the flags starting with `-L`).\n\n```bash\n/usr/lib/gcc/x86_64-linux-gnu/7/collect2 -plugin\n/usr/lib/gcc/x86_64-linux-gnu/7/liblto_plugin.so\n-plugin-opt=/usr/lib/gcc/x86_64-linux-gnu/7/lto-wrapper\n-plugin-opt=-fresolution=/tmp/cc2j00rN.res\n-plugin-opt=-pass-through=-lgcc_s -plugin-opt=-pass-through=-lgcc\n-plugin-opt=-pass-through=-lc -plugin-opt=-pass-through=-lgcc_s\n-plugin-opt=-pass-through=-lgcc --sysroot=/ --build-id --eh-frame-hdr\n-m elf_x86_64 --hash-style=gnu --as-needed -dynamic-linker\n/lib64/ld-linux-x86-64.so.2 -pie -z now -z relro\n/usr/lib/gcc/x86_64-linux-gnu/7/../../../x86_64-linux-gnu/Scrt1.o\n/usr/lib/gcc/x86_64-linux-gnu/7/../../../x86_64-linux-gnu/crti.o\n/usr/lib/gcc/x86_64-linux-gnu/7/crtbeginS.o\n-L/usr/lib/gcc/x86_64-linux-gnu/7\n-L/usr/lib/gcc/x86_64-linux-gnu/7/../../../x86_64-linux-gnu\n-L/usr/lib/gcc/x86_64-linux-gnu/7/../../../../lib\n-L/lib/x86_64-linux-gnu -L/lib/../lib -L/usr/lib/x86_64-linux-gnu\n-L/usr/lib/../lib -L/usr/lib/gcc/x86_64-linux-gnu/7/../../..\n/tmp/ccTpqU8Z.o -lstdc++ -lm -lgcc_s -lgcc -lc -lgcc_s -lgcc\n/usr/lib/gcc/x86_64-linux-gnu/7/crtendS.o\n/usr/lib/gcc/x86_64-linux-gnu/7/../../../x86_64-linux-gnu/crtn\n```\n\nSo, essentially, **a compiler toolchain is a set of tools, supporting libraries, and header files that help build a program from source to an executable that can run on a machine**. \n\nNote that a compiler toolchain is necessary to build executables, but it is not sufficient. What is missing from the toolchain to have 'everything' that is needed to build executable programs is the [sysroot](notes/sysroot.md).\n\n## The Compiler Toolchain\nApart from sysroot, a compiler toolchain contains various other binaries to help in the compilation process. In some cases, the compiler itself comes as a part of the toolchain. The following is a list of items packaged with the toolchain.\n\n- binutils (assembler, linker, etc.)  \n- Various compilers (gcc, g++, etc.)  \n- C-Library (glibc, uClibc, etc.)  \n- Runtime support libraries (crtbegin.o, crtend.o, etc.)  \n- debugger (gdb) - C/C++ standard header files (iostream, stdio.h, etc.)  \n- standard libraries (libstdc++, libm, libgcc, libunwind, etc.)  \n- Compiler specific header files (stdint.h, stdc-predef.h)  \n- Runtime support libraries for sanitizers (libasan, libubsan, etc.)\n\n### Further Reading\n-   [Toolchains](https://elinux.org/Toolchains)\n-   [How Initialisation Functions Are Handled (C runtime)](https://gcc.gnu.org/onlinedocs/gccint/Initialization.html)","lastmodified":"2022-07-02T12:03:24.352674319Z","tags":null},"/notes/compilers":{"title":"Compilers","content":"# Compilers\n---\nA compiler is a system that converts a program from one language to another. In the context of this course, we refer to a compiler as a program that converts a high-level language like C, C++ to a low-level language like assembly language or an executable format. Open source compilers like gcc and clang are commonly used to achieve this. These compilers are quite advanced. InÂ aÂ nutshell, they:\n\n- Compile several high-level languages: C, C++, Fortran, Objective C, etc.\n- Target several architectures: ARM, Aarch64, MIPS, RISC-V, WebAssembly, X86-64, etc.\n- Optimise programs to run faster: Loop unrolling, inlining, vectorisation, etc.\n- Provide linting and other software engineering capabilities: static analysis, warnings, etc.\n- Provide APIs to be used by other source code introspection and transformation tools.\n- Provide source code instrumentation capabilities for performance analysis, program introspection.\n\n- [LLVM](notes/llvm.md)\n- [GCC](notes/gcc.md)\n\n## Topics\n- [Cross-Compilation](notes/cross-compilation.md)\n- [Compiler Optimisation](notes/compiler-optimisation.md)\n- [Compiler Instrumentation](notes/compiler-instrumentation.md)\n- [Compiler Flags](notes/compiler-flags.md)\n- [Formal Languages](notes/formal-languages.md)\n- [Intermediate Representations](notes/intermediate-representations.md)\n- [Lexical Analysis](notes/lexical-analysis.md)\n- [Code Generation](notes/code-generation.md)\n\n## Structure of a Compiler\n![](content/images/compiler-structure.png)\n\n## Languages for Writing Compilers\nPossible approaches:\n\n- Use assembly language.\n- Use a high level language that is widely available.\n- Use the source language itself.\n    - Ultimate in portability, but not always suitable.\n- Generalised assembly language.\n\nIncreasingly mainstream compilers use the **second** approach, with C++ now the language of choice (being ubiquitous (found everywhere)).\n\n## Tools\n- [GDB](notes/gdb.md)\n\n## Related Notes\n- [Compiler Toolchains](notes/compiler-toolchains.md)\n- [Instruction Set Semantics](notes/instruction-set-semantics.md)\n- [](notes/llvm.md#Online%20resources|Lots%20of%20Online%20Resources)\n- [Writing a C compiler](https://norasandler.com/2017/11/29/Write-a-Compiler.html)\n","lastmodified":"2022-07-02T12:03:24.352674319Z","tags":null},"/notes/config":{"title":"Configuration","content":"\n## Configuration\nQuartz is designed to be extremely configurable. You can find the bulk of the configuration scattered throughout the repository depending on how in-depth you'd like to get.\n\nThe majority of configuration can be found under `data/config.yaml`. An annotated example configuration is shown below.\n\n```yaml {title=\"data/config.yaml\"}\n# The name to display in the footer\nname: Jacky Zhao\n\n# whether to globally show the table of contents on each page\n# this can be turned off on a per-page basis by adding this to the\n# front-matter of that note\nenableToc: true\n\n# whether to by-default open or close the table of contents on each page\nopenToc: false\n\n# whether to display on-hover link preview cards\nenableLinkPreview: true\n\n# whether to render titles for code blocks\nenableCodeBlockTitle: true \n\n# whether to try to process Latex\nenableLatex: true\n\n# whether to enable single-page-app style rendering\n# this prevents flahses of unstyled content and overall improves\n# smoothness of quartz. More info in issue #109 on GitHub\nenableSPA: true\n\n# whether to render a footer\nenableFooter: true\n\n# whether backlinks of pages should show the context in which\n# they were mentioned\nenableContextualBacklinks: true\n\n# whether to show a section of recent notes on the home page\nenableRecentNotes: false\n\n# page description used for SEO\ndescription:\n  Host your second brain and digital garden for free. Quartz features extremely fast full-text search,\n  Wikilink support, backlinks, local graph, tags, and link previews.\n\n# title of the home page (also for SEO)\npage_title:\n  \"ðŸª´ Quartz 3.2\"\n\n# links to show in the footer\nlinks:\n  - link_name: Twitter\n    link: https://twitter.com/_jzhao\n  - link_name: Github\n    link: https://github.com/jackyzha0\n```\n\n### Code Block Titles\n\nTo add code block titles with Quartz:\n\n1. Ensure that code block titles are enabled in Quartz's configuration:\n\n    ```yaml {title=\"data/config.yaml\", linenos=false}\n    enableCodeBlockTitle: true\n    ```\n\n2. Add the `title` attribute to the desired [code block\n   fence](https://gohugo.io/content-management/syntax-highlighting/#highlighting-in-code-fences):\n\n      ```markdown {linenos=false}\n       ```yaml {title=\"data/config.yaml\"}\n       enableCodeBlockTitle: true  # example from step 1\n       ```\n      ```\n\n**Note** that if `{title=\u003cmy-title\u003e}` is included, and code block titles are not\nenabled, no errors will occur and the title attribute will be ignored.\n\n### HTML Favicons\nIf you would like to customize the favicons of your quartz-based website, you \ncan add them to the `data/config.yaml` file. The **default** without any set \n`favicon` key is:\n\n```html {title=\"layouts/partials/head.html\", linenostart=15}\n\u003clink rel=\"shortcut icon\" href=\"icon.png\" type=\"image/png\"\u003e\n```\n\nThe default can be overridden by defining a value to the `favicon` key in your \n`data/config.yaml` file. Here is a `List[Dictionary]` example format, which is\nequivalent to the default:\n\n```yaml {title=\"data/config.yaml\", linenos=false}\nfavicon:\n  - { rel: \"shortcut icon\", href: \"icon.png\", type: \"image/png\" }\n#  - { ... } # Repeat for each additional favicon you want to add\n```\n\nIn this format, the keys are identical to their HTML representations.\n\nIf you plan to add multiple favicons generated by a website (see list below), it\nmay be easier to define it as HTML. Here is an example which appends the \n**Apple touch icon** to quartz's default favicon:\n\n```yaml {title=\"data/config.yaml\", linenos=false}\nfavicon: |\n  \u003clink rel=\"shortcut icon\" href=\"icon.png\" type=\"image/png\"\u003e\n  \u003clink rel=\"apple-touch-icon\" sizes=\"180x180\" href=\"/apple-touch-icon.png\"\u003e\n```\n\nThis second favicon will now be used as a web page icon when someone adds your \nwebpage to the home screen of their Apple device. If you are interested in more \ninformation about the current, and past, standards of favicons, you can read \n[this article](https://www.emergeinteractive.com/insights/detail/the-essentials-of-favicons/).\n\n**Note** that all generated favicon paths, defined by the `href` \nattribute, are relative to the `static/` directory.\n\n### Graph View\nTo customize the Interactive Graph view, you can poke around `data/graphConfig.yaml`.\n\n\n```yaml {title=\"data/graphConfig.yaml\"}\n# if true, a Global Graph will be shown on home page with full width, no backlink.\n# A different set of Local Graphs will be shown on sub pages.\n# if false, Local Graph will be default on every page as usual\nenableGlobalGraph: false\n\n### Local Graph ###\nlocalGraph:\n\t# whether automatically generate a legend\n    enableLegend: false\n    \n    # whether to allow dragging nodes in the graph\n    enableDrag: true\n    \n    # whether to allow zooming and panning the graph\n    enableZoom: true\n    \n    # how many neighbours of the current node to show (-1 is all nodes)\n    depth: 1\n    \n    # initial zoom factor of the graph\n    scale: 1.2\n    \n    # how strongly nodes should repel each other\n    repelForce: 2\n\n    # how strongly should nodes be attracted to the center of gravity\n    centerForce: 1\n\n    # what the default link length should be\n    linkDistance: 1\n    \n    # how big the node labels should be\n    fontSize: 0.6\n    \n    # scale at which to start fading the labes on nodes\n    opacityScale: 3\n\n### Global Graph ###\nglobalGraph:\n\t# same settings as above\n\n### For all graphs ###\n# colour specific nodes path off of their path\npaths:\n  - /moc: \"#4388cc\"\n```\n\n\n## Styling\nWant to go even more in-depth? You can add custom CSS styling and change existing colours through editing `content/images/styles/custom.scss`. If you'd like to target specific parts of the site, you can add ids and classes to the HTML partials in `/layouts/partials`. \n\n### Partials\nPartials are what dictate what actually gets rendered to the page. Want to change how pages are styled and structured? You can edit the appropriate layout in `/layouts`.\n\nFor example, the structure of the home page can be edited through `/layouts/index.html`. To customize the footer, you can edit `/layouts/partials/footer.html`\n\nMore info about partials on [Hugo's website.](https://gohugo.io/templates/partials/)\n\nStill having problems? Checkout our [FAQ and Troubleshooting guide](notes/troubleshooting.md).\n\n## Language Support\n[CJK + Latex Support (æµ‹è¯•)](notes/CJK%20+%20Latex%20Support%20(æµ‹è¯•).md) comes out of the box with Quartz.\n\nWant to support languages that read from right-to-left (like Arabic)? Hugo (and by proxy, Quartz) supports this natively.\n\nFollow the steps [Hugo provides here](https://gohugo.io/content-management/multilingual/#configure-languages) and modify your `config.toml`\n\nFor example:\n\n```toml\ndefaultContentLanguage = 'ar'\n[languages]\n  [languages.ar]\n    languagedirection = 'rtl'\n    title = 'Ù…Ø¯ÙˆÙ†ØªÙŠ'\n    weight = 1\n```\n","lastmodified":"2022-07-02T12:03:24.352674319Z","tags":null},"/notes/corev-toolchain":{"title":"CORE-V Toolchain","content":"# CORE-V Toolchain\n---\nCORE-V is a family of RISC-V cores developed by the OpenHW Group.\n\nThe first two projects within the OpenHW Groupâ€™s CORE-V family of RISC-V cores are the **CV32E40P** and **CVA6**.\n\nCurrently, **two variants** of the CV32E40P are defined: the **CV32E40X** and **CV32E40S**. The OpenHW Groupâ€™s work builds on several RISC-V open-source projects, particularly the **RI5CY** and **Ariane** projects from PULP-Platform. \n\n**CV32E40P** is a derivation of the **RI5CY** project, and CVA6 is derived from Ariane.\n\nIn addition, the verification environment for CORE-V leverages previous work done by **lowRISC** and others for the Ibex project, which is a fork of the PULP-Platformâ€™s zero-riscy core.\n\n## Repositories\n- binutils-gdb - [GitHub](https://github.com/openhwgroup/corev-binutils-gdb) (development)\n- GCC - [GitHub](https://github.com/openhwgroup/corev-gcc) (development)\n- CORE-V docs - [GitHub](https://github.com/openhwgroup/core-v-sw)\n\n### To build\n- binutils-gdb-sim - [GitHub](https://github.com/embecosm/riscv-binutils-gdb.git) (spc-cgen-sim-rve)\n- newlib - [GitHub](https://mirrors.git.embecosm.com/mirrors/newlib-cygwin.git) (master)\n\n## `-march` Options\nAll instructions must work for the xcorev -march option as well as their specific option:\n\n- Hardware Loop: xcorevhwlp1p0 (or 1p1 but not sure)\n- Multiply-Accumulate: xcorevmac\n- Post-Increment and Register-Indexed Load/Store: xcorevpostinc\n- Direct Branches: xcorevbi\n- General ALU Operations: xcorevalu\n\n## Environment\n```bash\n#!/usr/bin/env bash\n\nexport PULP_RISCV_GCC_TOOLCHAIN=/home/pietraferreira/corev/install/\nexport DEJAGNU=/home/pietraferreira/corev/riscv-toolchain-scripts/site.exp\nexport PATH=/home/pietraferreira/corev/install/bin:$PATH\nsource \"/home/pietraferreira/corev/pulp-sdk/configs/pulp-open-cv32e40p.sh\"\n```\n\n## Resources\n- [Docs](https://core-v-docs-verif-strat.readthedocs.io/en/latest/intro.html)\n- [Assembly Test Example](work/assembly-test-example-corev.md)\n- [CORE-V Relocations](work/corev-relocations.md)","lastmodified":"2022-07-02T12:03:24.352674319Z","tags":null},"/notes/courses-dump":{"title":"Courses Dump","content":"# Courses Dump\n---\nHere you can find all of the cool courses and guides I find online.\n\n- [Algorithms](https://algs4.cs.princeton.edu/home/) by Princeton\n- NYU Compilers - [Class Notes](https://cs.nyu.edu/~gottlieb/courses/compilers/class-notes.html)\n- Compiler Principles - [Notes](https://github.com/dengking/compiler-principle) (GitHub)\n- Project Based Learning - [Various Projects](https://github.com/practical-tutorials/project-based-learning)\n- [Build your own Lisp](https://buildyourownlisp.com/)\n- Lots of RISC-V resources - [Nikiv Wiki](https://wiki.nikiv.dev/hardware/cpu/risc-v)\n- Linux Up Skill Challenge - [Website](https://linuxupskillchallenge.org/)\n\n## On going\n- Courses I am taking: [here](kanban/what-am-i-studying-kanban.md).","lastmodified":"2022-07-02T12:03:24.352674319Z","tags":null},"/notes/cross-compilation":{"title":"Cross-Compilation","content":"# Cross-Compilation\n---\nTo understand the concept of cross-compilation, letâ€™s revisit the definition of a [compiler](notes/compilers.md). A [compiler](notes/compilers.md) is a program that converts a program from one language to another. But the word 'compiler' is often used to refer to a program that translates a program to a machine language to create an executable that runs on a computing device. Commonly, a [compiler](notes/compilers.md) is used to generate machine code for the same machine that the [compiler](notes/compilers.md) itself is running. By the same machine,Â we mean the same architecture. For example, a [compiler](notes/compilers.md) running on a linux-x64 machine compiling a C++ program and generating machine code for the same linux-x64 machine. This program can run on all linux-x64 machines, as long as a similar environment is provided.\n\nHowever, there are situations where we want to generate binaries for a machine type other than the [compiler](notes/compilers.md) it is running on. For example, if the target machine is not powerful enough. This is often the case while generating binaries for embedded devices, mobile apps, etc. A cross-compiler generates binaries that will run on a different machine (target machine) than the one where the [compiler](notes/compilers.md) itself is running (the host machine). This is a slightly complicated process, as it requires all the dependencies of the target machine to be present on the host machine.\n\nAs an example, when compiling a simple `hello-world` program for a host machine, the `stdio.h` header file in place like `/usr/include/stdio.h` is used. For generating a cross-compiled `hello-world` program, the `stdio.h` will be found in a different [sysroot](notes/sysroot.md). So, the [compiler](notes/compilers.md) invocation may look like:\n\n```bash\ngcc --sysroot=/path/to/aarch64/sysroot -march=armv8-a hello.c\n```\n\nAn even more convoluted setup is the [Canadian cross-compiler](https://en.wikipedia.org/wiki/Cross_compiler#Canadian_Cross), where there are two cross-compilers involved. In this setup, there are three machines A, B, and C. The cross-compiler in A (CA) will generate another cross-compiler (CB) that will run on B. CB will generate code for machine C.","lastmodified":"2022-07-02T12:03:24.352674319Z","tags":null},"/notes/cs-problems":{"title":"CS Problems","content":"# CS Problems\n---\n- [P vs NP problem.](notes/p-vs-np.md)\n- K-clique in a graph.\n- Boolean satisfiability.\n- Travelling Salesman problem.\n- Knapsack problem.\n- [Linear Knapsack Problem.](notes/linear-knapsack-problem.md)\n- Optimise branches and short branches.\n- Colour vertices of graph with k colours.\n- [Halting Problem](notes/halting-problem.md)\n\n## Harder Problems\n- Ackermann's function.\n- Does a regular expression cover all regular expressions possible for its alphabet.","lastmodified":"2022-07-02T12:03:24.352674319Z","tags":null},"/notes/debugging-techniques":{"title":"Debugging Techniques","content":"# Debugging Techniques\n---\nDebugging is an essential part of the software development lifecycle. Even with the most robust programming practices bugs creep in, and debugging them is not a pleasant experience. On any widely used software, there are many developers contributing code, and debugging takes a significant portion of developers' time. \n\nThat is why software development methodologies like [Test Driven Development](https://en.wikipedia.org/wiki/Test-driven_development), [Defensive Programming](https://en.wikipedia.org/wiki/Defensive_programming), andÂ [Programming/Design by contract](https://en.wikipedia.org/wiki/Design_by_contract) are adopted by many organisations. Some programming languages even provide supportÂ for some methodologies; for example,Â [D](https://en.wikipedia.org/wiki/D_(programming_language)) implementsÂ [contract programming](https://dlang.org/spec/contracts.html) features.\n\nDebugging native applications is difficult because of the semantics of the programming language, the variety of dependent software, the dependencies on hardware features like threading model, memory model, etc. It is therefore essential to know the different debugging technologies available to us.\n\n## Types of Bugs in Programs\nIn general, application failures can be broadly classified into three categories:\n\n1. Programming errors (syntax errors, semantic errors, runtime errors)\n2. System failure (memory errors, file corruption, network failure, etc.)\n3. Invalid data (bad file name, bad data)\n\nSome bugs are difficult to classify in a specific bucket as the classification may depend on the point of reference. For example, data corruption by one application may cause a dependent application to throw a runtime error. \n\nDepending on the type of failure, different tools and methodologies are deployed. In this chapter, we focus on programming errors and the following sections introduce tools and techniques pertaining to those.\n\n## Debugging Tools and Techniques\nWhile working on toolchains, system bringup or developing system software, commonly used debugging techniques can be divided into four categories:\n\n1. Instrumentation-based debugging\n2. Debugging using a debugger\n3. Remote debugging using gdb\n4. JTAG-based debugging\n\n### Instrumentation debugging\nInstrumentation-based debugging techniques are methods to insert code to programs, either manually or programmatically. This helps get insights into the code when the program runs. There are three commonly used techniques in this category:\n\n1. Print debugging\n2. Assertion-based debugging\n3. Sanitisers\n\nWhile print and assertion-based debugging are some of the earliest debugging techniques, sanitisers are relatively new. We briefly describe each technique below.\n\n#### Print Debugging \nThe simplest debugging technique is to add a set of print statements in the program and observe the printed values. Inserting print statements at carefully identified program points can help debug the program. \n\nThis is one of the earliest debugging techniques and is quite useful even today. This approach however fails in several cases, as it does not scale well. Unless the programmer has good knowledge of the code at hand, it is difficult to find issues quickly with this approach.\n\n#### Assertion-based Debugging\nIn order to establish preconditions and postconditions at various program points, it is common to insert assertions. Failure of assertion simplifies debugging. It also helps detect bugs early during the development stage. Usually, assertions are disabled in production code, so one of the first steps to debug is to enable assertions and run the failing test scenario.\n\n#### Sanitisers\nBoth clang and GCC provide instrumentations (sanitisers) that can detect several well-known classes of errors like buffer overflow, memory corruption, etc. There are sanitiser, sanitiser, undefined behaviour sanitiser, thread sanitiser, etc.\n\nThis provides an automated way of detecting bugs. Sanitisers also require runtime support to find bugs and it is not available on all platforms. RISC-V for example currently has support for sanitiser and sanitiser only.Â [This document](https://github.com/google/sanitizers) is the source of truth for all sanitiser documentation.\n\nOn some platforms,Â [Valgrind](https://valgrind.org/) can also detect errors that are detected by some sanitisers, like memory corruption, leaks, etc. Unfortunately, Valgrind is currently not available for RISC-V platforms.\n\n## Debugging Using a Debugger\nWhen a debugger is available, it becomes very convenient to inspect programs, get backtraces, values of objects, the state of different threads, etc. Learning to effectively use a debugger like [gdb](notes/gdb.md) greatly simplifies software development. [](notes/useful-commands-dump.md#GDB|Frequently%20used%20`gdb`%20commands.)\n\n## Remote Debugging\nInfo on remote debugging on GDB can be found [](notes/gdb.md#Remote%20Debugging|here).\n\n## JTAG-based Debugging\nDuring the early bringup phase of hardware, there are no software capabilities. In order to debug bare metal applications or access different hardware blocks, JTAG (named after the Joint Test Action Group) is used as the transport mechanism. \n\nMost modern hardware provides ways to directly trace instructions and data using a standard protocol called JTAG, although each hardware vendor may have different levels of support. It is frequently used to debug hardware issues. \n\nRISC-V defines a standard interface for external debugging, this includes accessing hardware threads (hart) from the very first instruction, accessing memory, single-stepping instructions, etc.\n\n## References\n- [Cornell University, CS312 Lecture 26, Debugging Techniques](https://www.cs.cornell.edu/courses/cs312/2006fa/lectures/lec26.html)\n- [Debugging with GDB](https://www.sourceware.org/gdb/current/onlinedocs/gdb.html)\n- [Tim Newsome - RISC-V External Debug (aka JTAG debugging)](https://riscv.org/wp-content/uploads/2016/01/Tues1030-RISC-V-External-Debug.pdf)\n- [Tim Newsome and Megan Wachs - RISC-V External Debug Support Version 0.13.2](https://riscv.org/wp-content/uploads/2019/03/riscv-debug-release.pdf)\n- [Five EmbedDev - An Embedded RISC-V Blog](https://five-embeddev.com/riscv-debug-spec/latest/introduction.html#sec:intro)\n- [University of San Francisco - Programming \"By Contract\"](https://www.cs.usfca.edu/~parrt/course/601/lectures/programming.by.contract.html)\n- [Debugging With Gdb](https://github.com/riscv/riscv-isa-sim#debugging-with-gdb)","lastmodified":"2022-07-02T12:03:24.352674319Z","tags":null},"/notes/dijkstra-algorithm":{"title":"Dijkstra Algorithm","content":"# Dijkstra Algorithm\n---\nIt is used to determine the **shortest path** from one node in the graph to **every other** node within the same graph, provided they can be reached from the source node.\n\nIts complexity is $O_(n^2)$.\n\nThe graph must have **non-negative weights** on **all** edges.\n\n \n## How It Works\n![](content/images/dijkstra_graph.png)\n- Given the graph above, to find the shortest path between A and F, three values need to be initialised:\n\n1. Array of distances from the source node (A) to each node in the graph. The weight of the source node is instantiated as 0 while all the other nodes initial value is infinity.\n2. Array of all nodes in the graph, which will be empty by the end (unvisited array).\n3. Array of all the nodes that the algorithm has visited, which by the end will contain all the nodes of the graph (visited array).\n\n### Example\nStarting from the source (A), we visit its neighbour with the lowest weight (B).\n\nWe then check:\n```c\nif (D[current_node]) + D[adjacent_edge] \u003c D[adjacent])\n```\n\nIf **true**, we update the adjacent distance with the new shortest path.\n\nUsing A as a starting point, from A to B: D = 0 + 2 which is \u003c D[B] = infinity. Therefore, we update.\n\nAs you can see on the graph, when in current node A (starting node), the cost of going to its neighbours, B and C, is of 2 and 4 respectively. Because 2 and 4 are less than B and C current values (infinity), we update the table.\n\nNote that the letter next to the number indicates what path is was taken:\n| Current Node | A   | B   | C   | D   | E   | F   |\n| ------------ | --- | --- | --- | --- | --- | --- |\n| A            | 0A  | 2A  | 4A  |     |     |     |\n\nNow with **B** being the current node, we repeat. For example, to get C there is a cost of 1. We sum B's current distance from the source with the distance to C and check if it is less than the current value (infinity).\n| Current Node | A   | B   | C   | D   | E   | F   |\n| ------------ | --- | --- | --- | --- | --- | --- |\n| A            | 0A  | 2A  | 4A  |     |     |     |\n| B            | 0A  | 2A  | 3B  | 6B  | 4B  |     |\n\nNow moving on to **C**, it has only one unchecked neighbour, E. The cost of getting to E, through C, is 4 + 3 = 7. However, the cost of getting to E (through B) is currently 4. Therefore, we don't update the table as C isn't the shorted path to E.\n\nWe then iterate until we visit all the nodes. The completed table for that graph would look like this:\n| Current Node | A   | B   | C   | D   | E   | F   |\n| ------------ | --- | --- | --- | --- | --- | --- |\n| A            | 0A  | 2A  | 4A  |     |     |     |\n| B            | 0A  | 2A  | 3B  | 6B  | 4B  |     |\n| C            | 0A  | 2A  | 3B  | 6B  | 4B  |     |\n| E            | 0A  | 2A  | 3B  | 6B  | 4B  | 6E  |\n| D            | 0A  | 2A  | 3B  | 6B  | 4B  | 6E  |\n| F            | 0A  | 2A  | 3B  | 6B  | 4B  | 6E  |\n\n## See also\n- [Graphs](notes/graphs.md)\n- [Floyd-Warshall](notes/floyd-warshall.md)\n","lastmodified":"2022-07-02T12:03:24.352674319Z","tags":null},"/notes/dotfile-management":{"title":"Dotfile Management","content":"# Dotfile Management\n---\nMy dotfiles can be found on [GitHub](https://github.com/pietraferreira/dotfiles).\n\nJust type `config` anywhere, for example `config status` to manage the repo.\n\n## Resources\n* [Dotfiles management](https://www.ackama.com/what-we-think/the-best-way-to-store-your-dotfiles-a-bare-git-repository-explained/)","lastmodified":"2022-07-02T12:03:24.352674319Z","tags":null},"/notes/embedded-applications":{"title":"Embedded Applications","content":"# Embedded Applications\n---\nThe definition and use case of embedded systems have evolved over time. While embedded systems are used to denote computing systems performing very specific tasks, it is no longer the case in many situations. Although most embedded systems are designed to perform a limited set of tasks, depending on the application, the tasks themselves may be simple or quite complex. \n\nEmbedded systems may have simple microcontrollers, or complex Digital Signal Processors (DSPs), or even microprocessors. Even with substantial variabilities across systems, few things are generally true for all:\n\n-   They are low-powered or battery-operated devices.\n-   They have limited storage.\n-   They do not upgrade the applications frequently.\n\nThere might be other things, but these three are a good starting point to understand how we can optimise these applications using compiler techniques.\n\n## Optimising for Power\nIn order to reduce the power consumed while the application is running, there are two schools of thought:\n\n- Execute/Design instructions that are low-powered\n- Execute instructions as fast as possible and go to idle mode.\n\nEach approach has its pros and cons.\n\n### Execute/Design instructions that are low-powered\nA processor has many instructions that can achieve the same computation. Each type of instruction consumes different amounts of system resources and is suitable for specific cases. For example, a floating-point operation may be more expensive than integer operations. In several embedded hardware, floating-point units arenâ€™t present to begin with, and they use software routines to perform in case any floating-point operations arise in rare cases.\n\nCompilers, to the best ofÂ our knowledge, do not have a direct way to select only low-power consuming instructions. As a result, this approach is mostly applicable for hardware engineers. In limited situations, compiler engineers can take advantage of this approach when they have better insight into the processor and running applications; for example, vectorisation can be disabled as vector units often consume more power than scalar instructions.\n\nThere are also situations where a system can have [big+little configuration](https://www.arm.com/why-arm/technologies/big-little). The more powerful processors are only used when the demand for compute increases, otherwise computations are performed on low-power processors. If we can compile compute-heavy parts of the code for powerful processors ([`-mtune` flag](https://gcc.gnu.org/onlinedocs/gcc/ARM-Options.html)) and rest for the low-power processor, we can take advantage of this feature. This strategy will require regular updates to build flags combined with profile-guided optimisation.\n\n### Execute instructions as fast as possible and go to idle mode\nSome processors can have advancedÂ [dynamic voltage and frequency scaling](https://en.wikipedia.org/wiki/Dynamic_frequency_scaling) capabilities. So, whenever there is no work to do, processors go into low-power idle mode. As a result, it makes sense to run applications as fast as possible and defer the responsibility of power management to the processor. To run the application as fast as possible, we can use higher optimisation levels like `-O3`, `-Ofast`; we can combine that with link time optimisations and profile guided optimisation to achieve even better performance.\n\n## Optimising for Binary Size\nCheck out [](notes/compiler-optimisation.md#Optimising%20Programs%20for%20Code%20Size|Optimising%20for%20Code%20Size).\n\n## References\n- [RISC-V Toolchain and Compiler Optimization Techniques](https://learning.edx.org/course/course-v1:LinuxFoundationX+LFD113x+3T2021/home)\n- [Aditya Kumar - Code Size Compiler Optimizations and Techniques for Embedded Systems](https://www.youtube.com/watch?v=6IuDWfuMEno)\n- [Aditya Kumar \u0026 Sebastian Pop - Performance analysis and optimization of C++ standard libraries](https://www.youtube.com/watch?v=OTCp_AkAyRQ)\n- [Visual Studio Developer Community - pragma optimize off is not working as expected](https://developercommunity.visualstudio.com/t/192628900-pragma-optimize-off-is-not-working-as-ex/1091452)\n- [nm(1) - Linux man page](https://linux.die.net/man/1/nm)\n- [GCC Instrument functions](https://hacktalks.blogspot.com/2013/08/gcc-instrument-functions.html)\n- [Nitin Kumar - Profile-guided optimization (PGO) using GCC on IBM AIX](https://developercommunity.visualstudio.com/t/192628900-pragma-optimize-off-is-not-working-as-ex/1091452)\n- [Aditya Kumar - Performance analysis and optimization](https://developercommunity.visualstudio.com/t/192628900-pragma-optimize-off-is-not-working-as-ex/1091452)\n- [Vinodha Ramasamy, Paul Yuan, Dehao Chen, Robert Hundt - Feedback-Directed Optimizations in GCC with Estimated Edge Profiles from Hardware Event Sampling](https://research.google/pubs/pub36576/)","lastmodified":"2022-07-02T12:03:24.352674319Z","tags":null},"/notes/engineer-training-hub":{"title":"Engineer Training Hub","content":"# Engineer Training Hub\n---\n## Syllabus:\n[Algorithms and Data Structure](notes/algorithms-and-data-structure.md)\n\n### Assembly programming\n\n### C/C++ Programming\n\n[Compilers](notes/compilers.md)\n\n### Functional Programming\n\n### Modeling\n\n### Operating Systems\n\n### Other Languages\n\n### Software Engineering","lastmodified":"2022-07-02T12:03:24.352674319Z","tags":null},"/notes/equivalent-grammars":{"title":"Equivalent Grammars","content":"# Equivalent Grammars\n---\nEquivalent grammars define the same language:\n\n- G\nA $\\rightarrow$ Ax | y\n\n- G'\nA $\\rightarrow$ yB\nB $\\rightarrow$ yB | $\\varepsilon$\n\n- L(G) = L(G')\n\nOne grammar may be easier to parse than the other. \n\nNote however that they have very different parse [trees](notes/trees.md), and if the parse tree reflects the semantic structure for the language then the semantic information is lost.\n\nParse tree for yxx:\n![](content/images/parse-tree-leftmost-rightmost.png)\n\n## See Also\n- [Formal Languages](notes/formal-languages.md)\n","lastmodified":"2022-07-02T12:03:24.352674319Z","tags":null},"/notes/fixups":{"title":"Fixups","content":"# Fix-ups\n---\nFix-ups are used to represent information in instructions which is currently\nunknown. During instruction encoding, if some information is unknown (such as a memory location of an external symbol), it is encoded as if the value is equal\nto 0 and a fix-up is emitted which contains information on how to rewrite the\nvalue when information is known.\n\nThe assembler goes through a stage of relaxation, applying fix-ups and modifying instruction values when they become known to the system. Once complete, any remaining fix-ups are converted to [relocations](notes/relocations.md) and stored in the object file.\n\nSource: Embecosm","lastmodified":"2022-07-02T12:03:24.352674319Z","tags":null},"/notes/floyd-warshall":{"title":"Floyd-Warshall","content":"# Floyd-Warshall\n---\nIt is a **shortest path** algorithm that calculates the shorted path between **all** pairs of vertices.\n\n- Negative edges are allowed.\n- No negative cycles.\n- $O(V^3)$, where V is the number of vertices.\n\n## Pseudo-code\n```c\nlet V = number of vertices of graph\nlet dist[V][V] = 2D array of minimum distances (the answers)\n\nfor each vertex v\n  dist[V][V] \u003c- 0\n\nfor each edge (u, v)\n  dist[u][V] \u003c- weight(u,V)\n\nfor k from 1 to V\n  for i from 1 to V\n    for j from 1 to V\n      if dist[i][j] \u003e dist [i][k] + dist[k][j]\n       dist[i][j] \u003c- dist[i][k] + dist[k][j]\n```\n\n## Example\nHere is a graph with four vertices (V = 4) and `dist[4][4]`:\n![](content/images/fw-graph1.png)\n\n```c\nfor each vertex v\n  dist[v][v] \u003c- 0\n```\n![](content/images/fw-graph2.png)\n\n```c\nfor each edge (u,v)\n  dist[u][v] \u003c- weight(u,v)\n```\n![](content/images/fw-graph3.png)\n\n```c\nfor k from 1 to V\n  for i from 1 to V\n    for j from 1 to V\n    if dist[i][j] \u003e dist[i][k] + dist[k][j]\n      dist[i][j] \u003c- dist[i][k] + dist[k][j]\n```\n\nIf k = A, i = A and j = A:\n```c\ndist[i][j] \u003e dist[i][k] + dist[k][j]\ndist[A][A] \u003e dist[A][A] + dist[A][A]\n    0      \u003e     0      +     0\n```\n\nThis statement is **false**. Therefore, `dist` does not get updated:\n![](content/images/fw-graph4.png)\n\nIf k = A, i = A and j = B then there is not yet a value for A-\u003eB. It is assumed to be infinite:\n```c\ndist[i][j] \u003e dist[i][k] + dist[k][j]\ndist[A][B] \u003e dist[A][A] + dist[A][B]\n infinity  \u003e     0      +  infinity\n```\n\nThis statement is **false**. Therefore, `dist` does not get updated.\n![](content/images/fw-graph4.png)\n\nIf k = A, i = B and j = C:\n```c\ndist[i][j] \u003e dist[i][k] + dist[k][j]\ndist[B][C] \u003e dist[B][A] + dist[A][C]\n    3      \u003e     4      +    -2\n```\n\nThis statement is **true**. Therefore, `dist` gets updated:\n![](content/images/fw-graph5.png)\n\n## See also\n- [Dijkstra](notes/dijkstra-algorithm.md)\n- [Graphs](notes/graphs.md)\n- [Big O Notation](notes/big-o-notation.md)\n","lastmodified":"2022-07-02T12:03:24.352674319Z","tags":null},"/notes/formal-languages":{"title":"Formal Languages","content":"# Formal Languages\n---\nFormal languages are used among others as the basis for defining the grammar of programming languages and formalised versions of subsets of natural languages in which the words of the language represent concepts that are associated with particular meanings or semantics.\n\n- [Parse Trees](notes/parse-trees.md)\n    - [Chomsky Grammars](notes/chomsky-grammars.md)\n    - [Equivalent Grammars](notes/equivalent-grammars.md)\n    - [Ambiguous Grammars](notes/ambiguous-grammars.md)\n- [Syntax Directed Translation](notes/syntax-directed-translation.md)\n\n## Defining a Language\n- **Non-terminal** symbols appear on the **left** of productions.\n- **Terminal** symbols only ever appear on the **right** of productions.\n\n A **grammar** is a 4-tuple {_S_, P, N, T}, were S $\\exists$ N is the **sentence** symbol, P is a set of **productions**, N is the set of **non-terminal** symbols and T is the set of **terminal** symbols.\n\nGrammars generate strings. They are description of languages that provide a mean for generating all possible strings contained in the language.\n\nA **sentence** is a string of symbols in T derived from S using one or more applications of productions in P.\n\nThe **language**, L(G) defined by a grammar, G, is the set of sentences derivable using G.\n\n## Context-Free Grammar (CFG)\nEach production has the form A $\\rightarrow$ w, where A is a **nonterminal** and w is a string of terminals and nonterminals.  Informally, a CFG is a grammar where any nonterminal can be expanded out to any of its productions at any point. The language of a grammar is the set of strings of terminals that can be derived from the start symbol.\n\nA **context-free grammar** (CFG) consists of:\n1.  A set of _terminals_ (tokens produced by the lexer).\n2.  A set of _nonterminals_.\n3.  A set of _productions_ (rules for transforming nonterminals). These are written  \n    Â  Â  LHS â†’ RHS  \n    where the LHS is a **single** nonterminal (that is why this grammar is **context-free**) and the RHS is a string containing nonterminals and/or terminals.\n4.  A specific nonterminal designated as start symbol.\n\n## Context-Sensitive Grammar (CSG)\nEach production has the form wAx $\\rightarrow$ wyx, where w and x are strings of terminals and nonterminals and y is also a string of terminals. In other words, the productions give rules saying \"if you see A **in a given context**, you may replace A by the string y.\" It's an unfortunate that these grammars are called \"context-sensitive grammars\" because it means that \"context-free\" and \"context-sensitive\" are not opposites, and it means that there are certain classes of grammars that arguably take a lot of contextual information into account but aren't formally considered to be context-sensitive.\n\nTo determine whether a string is contained in a CFG or a CSG, there are many approaches. First, you could build a recogniser for the given grammar. For CFGs, the _[pushdown automaton](http://en.wikipedia.org/wiki/Pushdown_automaton)_ (PDA) is a type of automaton that accepts precisely the context-free languages, and there is a simple construction for turning any CFG into a PDA. For the context-sensitive grammars, the automaton you would use is called a _[linear bounded automaton](http://en.wikipedia.org/wiki/Linear_bounded_automaton)_ (LBA).\n\nMore info [here](https://stackoverflow.com/questions/8236422/context-free-grammars-versus-context-sensitive-grammars).\n## Derivation\n- Productions (Backus-Naur Form, BNF):\n$A \\rightarrow B_1, B_2, B_3, ..., B_n$\nassign_stmnt $\\rightarrow$ variable := expression\nassign_stmnt := variable ':=' expression\n\nSentence symbol at the top of the grammar:\n$S\\rightarrow A_1, A_2, A_3, ..., A_n$\n\nAlternative definitions of a symbol:\n$A\\rightarrow B_1, B_2, B_3, ..., B_n$\n$A\\rightarrow C_1, C_2, C_3, ..., C_n$\n\n$A\\rightarrow B_1, B_2, B_3, ..., B_n | C_1, C_2, C_3, ..., C_n$\n\nSelf-referential (recursive productions):\n$A \\rightarrow A\\ x | y$\n\nEmpty production:\n$A \\rightarrow B\\ |\\ \\varepsilon$\n\n### Another Example\nTerminals: 0 1 2 3 4 5 6 7 8 9 + -\n    Nonterminals: list digit\n    Productions:\n        list â†’ list + digit\n        list â†’ list - digit\n        list â†’ digit\n        digit â†’ 0 | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9\n    Start symbol: list\n\nWatch how we can generate the string 7+4-5 beginning with the start symbol, applying productions, and stopping when no productions can be applied (because only terminals remain).\n\n    list â†’ list - digit\n         â†’ list - 5\n         â†’ list + digit - 5\n         â†’ list + 4 - 5\n         â†’ digit + 4 - 5\n         â†’ 7 + 4 - 5s\n\n## Recursive Productions\nRecursive productions are defined in terms of themselves:\n\nvarlist $\\rightarrow$ variable | varlist, variable\n\nif one of the alternatives contains the recursion at its **leftmost end**, the production is called **left recursive**:\n\nA $\\rightarrow$ u | Av\n\nWhere A $\\exists$ N and u, v are arbitrary strings in V.\n\nWe also have **right recursive** productions:\n\nA $\\rightarrow$ u | vA\n\nLeft recursion in particular can be problematic.\n\n## Attribute Types\nValues of attributes of items on the LHS of productions derived from values of attributes on the RHS are known as **synthesised** attributes:\n\nX $\\rightarrow$ $Y_1, Y_2, ..., Y_n$\n\nEach semantic rule can be written as:\n\nX.a = f($Y_1$.a, $Y_2$.a, ..., $Y_n$.a)\n\nWe can also have **inherited attributes**, where values of attributes on the RHS are derived from values of attributes on both the LHS and RHS.\n\n## Types of Attribute Grammars\n**S-attributed** grammars only use synthesised attributes, can evaluate correctly by a bottom-up walk over the parse tree.\n\n**L-attributed** grammars have inherited attributes in which all inherited attributes are only functions of symbols to their left in the production. They can be evaluated by left-to-right depth first traversal of the parse tree.\n\n## See Also\n- [Compilers](notes/compilers.md)\n- [Trees](notes/trees.md)","lastmodified":"2022-07-02T12:03:24.352674319Z","tags":null},"/notes/garbage-collection":{"title":"Garbage Collection","content":"# Garbage Collection\n---\nHow do you reuse memory in a program?\n\nExplicit allocation and free: `malloc`/`free` (C), `new`/`delete` (C++).\n\nIt traces garbage collection and does reference counting.\n\n**Reachability**: reference directly or indirectly by one or more variables.\n    - Global variables.\n    - Stack variables.\n\n## Syntactic and Semantic Garbage\n```c\nclass Foo;\nclass Bar;\n\nmain ()\n{\n  Foo *x = new Foo ();\n  Bar *y = new Bar ();\n  x = new Foo ();\n  // The old Foo object assigned to x can never be accessed\n  // x is syntactic garbage\n  if (x.checkit ())\n    x.doit (y);\n  else\n    x.dontdoit ();\n  // In the above, whether y is garbage depends on the result\n  // of x.checkit (). y could be semantic garbage\n\n  exit (EXIT_SUCCESS);\n}\n```\n\n## Tracing\n### Mark and Sweep\nNaive mark-and-sweep. Start with *root* set:\n\n![](content/images/mark-and-sweep-1.png)\n\nNow sweep up anything not marked:\n\n![](content/images/mark-and-sweep-2.png)\n\n### Tri-Colour Marking\nTree sets:\n- White set (**condemned** set): candidates for memory recycling.\n- Black set: object shown to have no reference to the white set and reachable from the root set.\n- Grey set: object reachable from the root set, but not yet scanned for reference to white objects.\n\nTri-colour **invariant**: no black objects reference white objects.\n\nCan be performed \"on-the-fly\".\n\nStarting state:\n- Black set is empty.\n- Grey set has objects directly referenced from the root set.\n- White set has all other objects.\n\n#### Algorithm\n1. Pick an object from the grey set and move it to the black set.\n2. Move each white object it references to the grey set.\n3. Repeat previous two steps until the grey set is empty.\n4. All white objects can now be garbage collected.\n\n## Moving vs Non-Moving\nWhen you free space, should you compact all the free space?\n\n### Advantages\n- Clearing mark is trivial.\n- New objects can be allocated quickly.\n- Can move objects close to the objects they refer to, which is good for caches.\n\n### Disadvantages\n- More work when garbage collecting.\n- Pointer arithmetic is not preserved.\n\n## Reference Count\n### Advantages\n- Objects reclaimed as soon as they can no longer be referenced.\n- Simple to implement.\n- Can be useful input to other parts of the system.\n\n### Disadvantages\n- Frequent updates are inefficient.\n- Reference cycles are a problem.\n- Cannot optimise for caches.\n","lastmodified":"2022-07-02T12:03:24.352674319Z","tags":null},"/notes/gcc":{"title":"GCC","content":"# GCC\n---\nThe popular gcc [compiler](notes/compilers.md) ships with the gcc toolchain. It can be downloaded fromÂ [GCC mirror sites](https://gcc.gnu.org/mirrors.html). In order to download the precompiled binaries that are ready to use, go to theÂ _[Installing GCC: Binaries](https://gcc.gnu.org/install/binaries.html)_ page.\n\nThe toolchain contains the following top-level directories:\n\n```bash\nbin include libexec lib share\n```\n\nThe `bin` folder contains all the executable binaries, like the C [compiler](notes/compilers.md) (gcc), the C++ [compiler](notes/compilers.md) (g++), the Fortran [compiler](notes/compilers.md) (gfortran), and the D [compiler](notes/compilers.md)(gdc). It may contain the Go [compiler](notes/compilers.md) (gccgo) depending on the distribution. It also contains a set of other useful tools like `gcov`, `lto-dump`, etc.\n\nThe `include` folder contains a set of header files that are included during compilation. For example, the C++ header files like `iostream`, etc. Notice that C header files like `stdio.h` are not supplied with the toolchain because they are part ofÂ [sysroot](notes/sysroot.md).\n\nThe `lib` folder contains libraries like libstdc++, libatomic, etc. These libraries may be used by the gcc [compiler](notes/compilers.md) during the compilation process or can be used as a reusable set of libraries.\n\nThe `libexec` folder contains binaries that are invoked by the driver programs (gcc, g++, gdc). For example, gcc invokes `cc1` (the C [compiler](notes/compilers.md)), `collect2` (the linker), `lto1` (the link time optimiser), etc.\n\nThe `share` folder contains the documentation which can be installed as man pages, and a non-essential set of scripts.\n\n## Online resources\n-   [GCC online documentation](https://gcc.gnu.org/onlinedocs/)\n-   [GCC Resource Center](https://www.cse.iitb.ac.in/grc/)\n-   [Essential Abstractions in GCC](https://www.cse.iitb.ac.in/grc/index.php?page=gcc-pldi14-tut)\n-   [Videos of Lectures on Essential Abstractions in GCC -2012](https://www.cse.iitb.ac.in/grc/index.php?page=videos)\n-   [Compiler Internals Lecture by IIT Bombay [Part 1]](https://www.youtube.com/watch?v=IlovhbAI7Cw\u0026list=PLy-CGmBdq2VGjl56cyaEjxcAMyAvUKbCz)\n-   [GNU Tools Cauldron](https://www.youtube.com/channel/UCQ4JGczdlU3ofHWf3NuCX8g/featured)\n\n### Mailing lists\n-   [The Gcc-help Archives](https://gcc.gnu.org/pipermail/gcc-help/)","lastmodified":"2022-07-02T12:03:24.352674319Z","tags":null},"/notes/gdb":{"title":"GDB","content":"# GDB\n---\nAll the basic commands can be found [](notes/useful-commands-dump.md#GDB|here).\n\n## Remote Debugging\ngdb can be used to debug programs running on another machine. On the remote machine, a program called `gdbserver` is run, which responds and acts on the requests made by gdb on the client machine. \n\nRemote debugging can be more convenient in some cases; for example, it enables inspecting the program on the machine where the bug has occurred instead of trying to replicate the scenario on a dev machine. This can save a lot of time. Remote debugging is quite popular among mobile app developers, where the app runs on a mobile device, while the debugger runs on the development machine.\n\nTheÂ [_Remote debugging with GDB_ blog post](https://developers.redhat.com/blog/2015/04/28/remote-debugging-with-gdb) can get you started in case you are interested. TheÂ [gdbserver(1) - Linux manual page](https://man7.org/linux/man-pages/man1/gdbserver.1.html) also offers great documentation. The official [RISC-V binutils repository](https://github.com/riscv-collab/riscv-binutils-gdb) has the `gdbserver` source code.\n\n## See Also\n- [Debugging Techniques](notes/debugging-techniques.md)","lastmodified":"2022-07-02T12:03:24.352674319Z","tags":null},"/notes/graphs":{"title":"Graphs","content":"# Graphs\n---\nA graph consists of:\n- A set of fixed objects, **nodes**.\n- A set of **edges**, which may have arrows and have values attached.\n\n![](content/images/graph.png)\n\n## Terminology\n- An **undirected** graph has no arrows on edges.\n- A **directed** graph or **digraph** has arrows on edges.\n- Two nodes connected by an edge are **adjacent**.\n- A **weighted graph** has values attached to edges.\n- A path from a node back to itself is a **cycle**.\n- An **undirected** graph with **no cycles** is a [tree](notes/trees.md).\n- A **directed** graph with **no cycles** is a **directed acyclic graph** or DAG.\n- A **DAG** where no node is pointed to by more than one node is a **directed** [tree](notes/trees.md).\n\n## See also\n- [Trees](notes/trees.md)\n- [Minimum Spanning Subtree](notes/minimum-spanning-subtree.md)\n- [Dijkstra](notes/dijkstra-algorithm.md)\n- [Floyd-Warshall](notes/floyd-warshall.md)\n- [Inkblot](notes/inkblot-algorithm.md)\n- [Graphviz](notes/graphviz.md)\n","lastmodified":"2022-07-02T12:03:24.352674319Z","tags":null},"/notes/graphviz":{"title":"Graphviz","content":"# Graphviz\n---\nGraphiz is a package of tools supporting the DOT [graph](notes/graphs.md) description language.\n\n**DOT** is a textual representation of arbitrary graphs (suffix `.dot` or preferably `.gv`).\n\nTools can visualise those graphs. For example `xdot`.\n\n```bash\nsudo apt install graphviz\n```\n\nOfficial website [here](https://graphviz.org/).\n\n## See also\n- [Graphs](notes/graphs.md)","lastmodified":"2022-07-02T12:03:24.352674319Z","tags":null},"/notes/halting-problem":{"title":"Halting Problem","content":"# Halting Problem\n---\nA program to determine if **any** given program will complete in finite time.\n\nSo imagine you write this program, P, and in its main program it has:\n```c\nif (willhalt (prog))\n  printf (\"Supplied program will halt\");\nelse\n  printf (\"Supplied program will not halt\");\n```\n\nNow edit P to create program Q:\n```c\nif (willhalt (q))\n  whilte (1);\nelse\n  exit (0);\n```\n\nFeed Q to itself. Will it halt?\n\n- Restricting the problem makes it tractable.\n- Event loops are often infinite loops.\n- Beware requirements masquerading as the halting problem.\n\n## See also\n- [Problems](notes/cs-problems.md)","lastmodified":"2022-07-02T12:03:24.352674319Z","tags":null},"/notes/hash-tables":{"title":"Hash Tables","content":"# Hash Tables\n---\nA hash table is a data structure which offers a fast implementation of the associative array (abstract data structure, also called a map, symbol table or dictionary) [](notes/hash-tables.md#API|API). \n\nA hash table consists of an array of 'buckets', each of which stores a key-value pair. In order to locate the bucket where the key-value pair should be stored, the key is passed through a hashing function. This function returns an integer which is used as the pair's index in the array of buckets. When we want to retrieve a key-value pair, we supply the key to the same hashing function, receive its index, and use the index to find it in the array.\n\nArray indexing has algorithmic [complexity](notes/big-o-notation.md) `O(1)`, making hash tables fast at storing and retrieving data.\n\n- Hash tables are [vector](notes/vectors-arrays.md) with *n* entries.\n\nHash functions:\n- H(**k**) gives a key, **k**, yields a value in the range [0,n] (it is important to have an even distribution).\n- Store key, **k**, and value, **v**, at index H(**k**) in the [vector](notes/vectors-arrays.md).\n    - May end up with multiple keys with the same H(**k**).\n        - Build up a double linked list of entries (_open_ hash table).\n        - Use next available free slot (_closed_ hash table).\n\n## Efficiency\nHash function must have a good distribution and must be **large enough**. _Closed_ tables may run out of space, _open_ tables may get inefficiently large lists.\n\n- Algorithms exist for the [perfect hash function](https://en.wikipedia.org/wiki/Perfect_hash_function).\n\nA well design insertion and lookup is $O(1)$.\n\n## API\nAssociative arrays are a collection of unordered key-value pairs. Duplicate keys are not permitted. The following operations are supported:\n\n- `search(a, k)`: return the value `v` associated with key `k` from the associative array `a`, or `NULL` if the key does not exist.\n- `insert(a, k, v)`: store the pair `k:v` in the associative array `a`.\n- `delete(a, k)`: delete the `k:v` pair associated with `k`, or do nothing if `k` does not exist.","lastmodified":"2022-07-02T12:03:24.352674319Z","tags":null},"/notes/heapsort":{"title":"Heapsort","content":"# Heapsort\n---\nUses [binary heap trees](notes/binary-heap.md) to [sort](notes/sorting.md) (I think!).\n\nIt has average [](notes/compiler-optimisation.md#Performance|performance): $O_{n\\ log\\ n}$\nWorst case performance: $O_{n\\ log\\ n}$\n\n- Refer to [big o notation](notes/big-o-notation.md).\n\nIt is not [](notes/sorting.md#Stability|stable).\n\nValuable data representation for anything where you need to quickly access the largest (smallest) element.    \n- e. g.:  time ordered queue, with the next item at the root.\n\n```c\nvoid\nheapify (int *a, int i, int n)\n{\n  int lc = 2 * i + 1;          /* Index of left child */\n  int rc = 2 * i + 2;          /* Index of right child */\n\n  if (lc \u003c= (n - 1))           /* Not a leaf */\n  {\n    int k;                     /* Larger child (if \u003e a[i]) */\n    if (rc \u003e (n - 1))\n      if (a[lc] \u003e a[i])\n        k = lc;                /* Swap left child */\n      else\n        return;                /* Heap in order */\n    else if ((a[lc] \u003e= a[i]) \u0026\u0026 (a[lc] \u003e= a[rc]))\n      k = lc;                  /* Swap left child */\n    else if (a[rc] \u003e= a[i])\n      k = rc;                  /* Swap right child */\n    else\n      return;                  /* Heap in order */\n\n    swap ((\u0026a[i]), \u0026(a[k]));   /* Swap the larger child */\n    heapify (a, k, n);\n  }\n}\n```\n\n## Buildheap\n```c\nvoid\nbuildheap (int *a)\n{\n  int i;\n\n  for (i = N - 1; i \u003e= 0; i--)\n    heapify (a, i, N);\n}\n```\n\n### To sort with a binary heap:\n```c\nbuildheap(a);\n\nfor (i = N - 1; i \u003e= 0; i--)\n{\n  swap (\u0026(a[0]), \u0026(a[i]));\n  heapify (a, 0, i);\n}\n```\n\n## Output\n### Building the heap\n```bash\n16 16  0 14  9 11 10  2  3  4  1 11  8 17 14  5 11 12 15 16\n16 16  0 14  9 11 10  2  3 16  1 11  8 17 14  5 11 12 15  4\n16 16  0 14  9 11 10  2 15 16  1 11  8 17 14  5 11 12  3  4\n16 16  0 14  9 11 10 11 15 16  1 11  8 17 14  5  2 12  3  4\n16 16  0 14  9 11 17 11 15 16  1 11  8 10 14  5  2 12  3  4\n16 16  0 14 16 11 17 11 15  9  1 11  8 10 14  5  2 12  3  4\n16 16  0 15 16 11 17 11 14  9  1 11  8 10 14  5  2 12  3  4\n16 16 17 15 16 11  0 11 14  9  1 11  8 10 14  5  2 12  3  4\n16 16 17 15 16 11 14 11 14  9  1 11  8 10  0  5  2 12  3  4\n16 16 17 15 16 11 14 11 14  9  1 11  8 10  0  5  2 12  3  4\n17 16 16 15 16 11 14 11 14  9  1 11  8 10  0  5  2 12  3  4\n```\n\n### Creating the sort\n```bash\n16  4 16 15 16 11 14 11 14  9  1 11  8 10  0  5  2 12  3 17\n16 16 16 15  4 11 14 11 14  9  1 11  8 10  0  5  2 12  3 17\n16 16 16 15  9 11 14 11 14  4  1 11  8 10  0  5  2 12  3 17\n16  3 16 15  9 11 14 11 14  4  1 11  8 10  0  5  2 12 16 17\n16 15 16  3  9 11 14 11 14  4  1 11  8 10  0  5  2 12 16 17\n16 15 16 14  9 11 14 11  3  4  1 11  8 10  0  5  2 12 16 17\n16 15 16 14  9 11 14 11 12  4  1 11  8 10  0  5  2  3 16 17\n16 15  3 14  9 11 14 11 12  4  1 11  8 10  0  5  2 16 16 17\n16 15 14 14  9 11  3 11 12  4  1 11  8 10  0  5  2 16 16 17\n16 15 14 14  9 11 10 11 12  4  1 11  8  3  0  5  2 16 16 17\n15  2 14 14  9 11 10 11 12  4  1 11  8  3  0  5 16 16 16 17\n15 14 14  2  9 11 10 11 12  4  1 11  8  3  0  5 16 16 16 17\n15 14 14 12  9 11 10 11  2  4  1 11  8  3  0  5 16 16 16 17\n14  5 14 12  9 11 10 11  2  4  1 11  8  3  0 15 16 16 16 17\n14 12 14  5  9 11 10 11  2  4  1 11  8  3  0 15 16 16 16 17\n14 12 14 11  9 11 10  5  2  4  1 11  8  3  0 15 16 16 16 17\n14 12  0 11  9 11 10  5  2  4  1 11  8  3 14 15 16 16 16 17\n14 12 11 11  9  0 10  5  2  4  1 11  8  3 14 15 16 16 16 17\n14 12 11 11  9 11 10  5  2  4  1  0  8  3 14 15 16 16 16 17\n12  3 11 11  9 11 10  5  2  4  1  0  8 14 14 15 16 16 16 17\n12 11 11  3  9 11 10  5  2  4  1  0  8 14 14 15 16 16 16 17\n12 11 11  5  9 11 10  3  2  4  1  0  8 14 14 15 16 16 16 17\n11  8 11  5  9 11 10  3  2  4  1  0 12 14 14 15 16 16 16 17\n11  9 11  5  8 11 10  3  2  4  1  0 12 14 14 15 16 16 16 17\n11  9  0  5  8 11 10  3  2  4  1 11 12 14 14 15 16 16 16 17\n11  9 11  5  8  0 10  3  2  4  1 11 12 14 14 15 16 16 16 17\n11  9  1  5  8  0 10  3  2  4 11 11 12 14 14 15 16 16 16 17\n11  9 10  5  8  0  1  3  2  4 11 11 12 14 14 15 16 16 16 17\n10  9  4  5  8  0  1  3  2 11 11 11 12 14 14 15 16 16 16 17\n 9  2  4  5  8  0  1  3 10 11 11 11 12 14 14 15 16 16 16 17\n 9  8  4  5  2  0  1  3 10 11 11 11 12 14 14 15 16 16 16 17\n 8  3  4  5  2  0  1  9 10 11 11 11 12 14 14 15 16 16 16 17\n 8  5  4  3  2  0  1  9 10 11 11 11 12 14 14 15 16 16 16 17\n 5  1  4  3  2  0  8  9 10 11 11 11 12 14 14 15 16 16 16 17\n 5  3  4  1  2  0  8  9 10 11 11 11 12 14 14 15 16 16 16 17\n 4  3  0  1  2  5  8  9 10 11 11 11 12 14 14 15 16 16 16 17\n 3  2  0  1  4  5  8  9 10 11 11 11 12 14 14 15 16 16 16 17\n 2  1  0  3  4  5  8  9 10 11 11 11 12 14 14 15 16 16 16 17\n 1  0  2  3  4  5  8  9 10 11 11 11 12 14 14 15 16 16 16 17\n 0  1  2  3  4  5  8  9 10 11 11 11 12 14 14 15 16 16 16 17\n```\n\n## Code Example\n```c\n/* Basic heapsort\n\n   Copyright (C) 2020 Embecosm Limited \u003cwww.embecosm.com\u003e\n   Contributor: Jeremy Bennett \u003cjeremy.bennett@embecosm.com\u003e\n   SPDX-License-Identifier: GPL-3.0-or-later */\n\n#include \u003cstdlib.h\u003e\n#include \u003cstdio.h\u003e\n\n#ifndef N\n#define N 20\n#endif\n\nvoid\npopulate (int arr[])\n{\n  for (int i = 0; i \u003c N; i++)\n    arr[i] = rand () % N;\n}\n\nvoid\nswap (int *a, int *b)\n{\n  int t = *a;\n  *a = *b;\n  *b = t;\n}\n\nvoid\ndump_array (int arr[])\n{\n  for (int i = 0; i \u003c N; i++)\n    printf (\"%2d \", arr[i]);\n\n  printf (\"\\n\");\n}\n\nvoid\nheapify (int *a, int i, int n)\n{\n  int lc = 2 * i + 1;\t\t/* Index of left child */\n  int rc = 2 * i + 2;\t\t/* Index of right child */\n\n  if (lc \u003c= (n - 1))\t\t/* Not a leaf) */\n    {\n      int  k;\t\t\t/* Larger child (if \u003e a[i]) */\n      if (rc \u003e (n - 1))\n\tif (a[lc] \u003e a[i])\n\t  k = lc;\t\t/* Swap left child */\n\telse\n\t  return;\t\t/* Heap in order */\n      else if ((a[lc] \u003e a[i]) \u0026\u0026 (a[lc] \u003e= a[rc]))\n\tk = lc;\t\t\t/* Swap left child */\n      else if (a[rc] \u003e= a[i])\n\tk = rc;\t\t\t/* Swap right child */\n      else\n\treturn;\t\t\t/* Heap in order */\n\n      swap ((\u0026a[i]), \u0026(a[k]));\t/* Swap the larger child */\n      dump_array (a);\n      heapify (a, k, n);\n    }\n}\n\nvoid\nbuildheap (int *a)\n{\n  int i;\n\n  for (i = N - 1; i \u003e= 0; i--)\n    heapify (a, i, N);\n}\n\nint\nmain ()\n{\n  int a[N];\n  int i;\n\n  srand (561U);\n\n  populate (a);\n  dump_array (a);\n\n  buildheap (a);\n  printf (\"\\n\");\n\n  for (i = N - 1; i \u003e= 0; i--)\n    {\n      swap (\u0026(a[0]), \u0026(a[i]));\n      heapify (a, 0, i);\n    }\n  dump_array (a);\n  return 0;\n}\n\n/*\nLocal Variables:\nmode: C\nc-file-style: \"gnu\"\nEnd:\n*/\n```","lastmodified":"2022-07-02T12:03:24.352674319Z","tags":null},"/notes/help":{"title":"Help","content":"\n# HELP\n\nVarious cheatsheets of different application I use and all the help I can get compiled in one place.\n\n\u003ccenter\u003e\u003cimg src=\"https://c.tenor.com/_h_1fcwEkHYAAAAC/studying-windy.gif\"\u003e\u003c/center\u003e\n\n## Cheatsheets\n- [Vim](notes/vim-cheatsheet.md)\n- [iTerm2](notes/iterm2-cheatsheet.md)\n- [Obsidian](notes/obsidian-cheatsheet.md)\n- [Tmux](notes/tmux-cheatsheet.md)\n\n## Hacking\n- [x86 CheatSheet](https://trailofbits.github.io/ctf/vulnerabilities/references/X86_Win32_Reverse_Engineering_Cheat_Sheet.pdf)\n- [Reverse Engineering Malicious Code](https://zeltser.com/media/docs/reverse-engineering-malicious-code-tips.pdf)\n- [x86 Opcode and Instructions](http://ref.x86asm.net/coder64.html#x02)\n- [Linux System Call Table for x86-64](https://blog.rchapman.org/posts/Linux_System_Call_Table_for_x86_64/)\n- [HTTP Status List](https://en.wikipedia.org/wiki/List_of_HTTP_status_codes#3xx_redirection)\n\n## Other\n- [Commands Dump](notes/useful-commands-dump.md)\n- [Linux Fundamentals](notes/linux-fundamentals.md)\n- [Dotfiles Management](notes/dotfile-management.md)\n- [Courses Dump](notes/courses-dump.md)\n\n## All of them\n```dataview\ntable without ID\ntitle as \"Title\", file.ctime as \"Created Time\", file.link as \"Link\"\nfrom #help and -#hub\nsort file.ctime desc\n```","lastmodified":"2022-07-02T12:03:24.352674319Z","tags":null},"/notes/hosting":{"title":"Deploying Quartz to the Web","content":"\n## Hosting on GitHub Pages\nQuartz is designed to be effortless to deploy. If you forked and cloned Quartz directly from the repository, everything should already be good to go! Follow the steps below.\n\n### Enable GitHub Actions\nBy default, GitHub disables workflows from running automatically on Forked Repostories. Head to the 'Actions' tab of your forked repository and Enable Workflows to setup deploying your Quartz site!\n\n![Enable GitHub Actions](content/images/github-actions.png)*Enable GitHub Actions*\n\n### Enable GitHub Pages\n\nHead to the 'Settings' tab of your forked repository and go to the 'Pages' tab.\n\n1. (IMPORTANT) Set the source to deploy from `master` (and not `hugo`) using `/ (root)`\n2. Set a custom domain here if you have one!\n\n![Enable GitHub Pages](/content/images/github-pages.png)*Enable GitHub Pages*\n\n### Pushing Changes\nTo see your changes on the internet, we need to push it them to GitHub. Quartz is a `git` repository so updating it is the same workflow as you would follow as if it were just a regular software project.\n\n```shell\n# Navigate to Quartz folder\ncd \u003cpath-to-quartz\u003e\n\n# Commit all changes\ngit add .\ngit commit -m \"message describing changes\"\n\n# Push to GitHub to update site\ngit push origin hugo\n```\n\nNote: we specifically push to the `hugo` branch here. Our GitHub action automatically runs everytime a push to is detected to that branch and then updates the `master` branch for redeployment.\n\n### Setting up the Site\nNow let's get this site up and running. Never hosted a site before? No problem. Have a fancy custom domain you already own or want to subdomain your Quartz? That's easy too.\n\nHere, we take advantage of GitHub's free page hosting to deploy our site. Change `baseURL` in `/config.toml`. \n\nMake sure that your `baseURL` has a trailing `/`!\n\n[Reference `config.toml` here](https://github.com/jackyzha0/quartz/blob/hugo/config.toml)\n\n```toml\nbaseURL = \"https://\u003cYOUR-DOMAIN\u003e/\"\n```\n\nIf you are using this under a subdomain (e.g. `\u003cYOUR-GITHUB-USERNAME\u003e.github.io/quartz`), include the trailing `/`. **You need to do this especially if you are using GitHub!**\n\n```toml\nbaseURL = \"https://\u003cYOUR-GITHUB-USERNAME\u003e.github.io/quartz/\"\n```\n\nChange `cname` in `/.github/workflows/deploy.yaml`. Again, if you don't have a custom domain to use, you can use `\u003cYOUR-USERNAME\u003e.github.io`.\n\nPlease note that the `cname` field should *not* have any path `e.g. end with /quartz` or have a trailing `/`.\n\n[Reference `deploy.yaml` here](https://github.com/jackyzha0/quartz/blob/hugo/.github/workflows/deploy.yaml)\n\n```yaml {title=\".github/workflows/deploy.yaml\"}\n- name: Deploy  \n  uses: peaceiris/actions-gh-pages@v3  \n  with:  \n\tgithub_token: ${{ secrets.GITHUB_TOKEN }} # this can stay as is, GitHub fills this in for us!\n\tpublish_dir: ./public  \n\tpublish_branch: master\n\tcname: \u003cYOUR-DOMAIN\u003e\n```\n\nHave a custom domain? [Learn how to set it up with Quartz ](notes/custom%20Domain.md).\n\n### Ignoring Files\nOnly want to publish a subset of all of your notes? Don't worry, Quartz makes this a simple two-step process.\n\nâŒ [Excluding pages from being published](notes/ignore%20notes.md)\n\n---\n\nNow that your Quartz is live, let's figure out how to make Quartz really *yours*!\n\n\u003e Step 6: ðŸŽ¨ [Customizing Quartz](notes/config.md)\n\nHaving problems? Checkout our [FAQ and Troubleshooting guide](notes/troubleshooting.md).\n","lastmodified":"2022-07-02T12:03:24.352674319Z","tags":null},"/notes/how-to-write-a-llvm-backend":{"title":"How to Write a LLVM Backend","content":"# How to Write a LLVM Backend\n---\nMore information [here](https://llvm.org/docs/WritingAnLLVMBackend.html).\n\nLLVM converts LLVM IR to code for a specific target, the steps are:\n1. Create a subclass of the **TargetMachine** class (describes the actual target machine characteristics - `BSCTargetMachine.h` and `BSCTargetMachine.cpp`)\n2. Describe the register set of the target. TableGen generates code for register definition, aliases and classes from a target-specific file (`BSCRegisterInfo.td`)\n3. Describe the instruction set of the target, you should write a subclass of the `TargetInstrInfo` class to represent machine instructions supported by the target machine.\n4. Describe the selection and conversion of the LLVM IR from a DAG representation of instructions. Write code for `ISelLowering.cpp` to replace or remove operations and data types that are not supported natively in a SelectionDAG.\n5. Write code for assembly printer, which converts LLVM IR to a GAS format for the target machine. Add assembly strings to the instructions defined in target-specific version of `TargetInstInfo.td`, also code for a subclass of `AsmPrinter` that performs the LLVM-to-assembly conversion.\n6. Add support for subtargets, also subclass which allows the use of `-mcpu=` and `-matter=`.\n7. Optionally JIT support.\n\n* `BSCTargetMachine.h` - declares the BSC specific subclass of TargetMachine\n* `BSCTargetMachine.cpp` - implements the BSC specific subclass of TargetMachine","lastmodified":"2022-07-02T12:03:24.352674319Z","tags":null},"/notes/howto-table":{"title":"Howto Table","content":"# Howto Table a.k.a. Relocation Table\n---\nThe relocation table records the list of items that the file needs (from other object files or libraries).\n\n- The relocation record contains information like: which instructions need to be\nrelocated (the offsets), which symbols are involved with the relocation and how to\nrelocate the files relative to the symbols.\n\n## How it works (according to CORE-V)\n### `tc-riscv.c (:3129/48)` steps\n1. Check that symbol address exists via `fixPâ†’fx_addsy`. If false the case will just break and not go through the following steps.\n2. Uses the howto table to look up the relocation. The howto table can be found in `bfd/elfxx-riscv.c`. The first field uses the table from `include/elf/riscv.h`.\n3. Set the _delta_ and _target_ values to increase objdump readability.\n\n- *Delta* is the PC relative value found via â€œ_target - md_pcrel_from (fixP)â€_, where fixP is the symbol.\n- *Target* is the value of the symbol found using `S_GET_VALUE`. Since the symbol is local, it will use `resolve_symbol_value` to find the value. This is called during the final pass over the symbol table to resolve any symbols with complex values.\n\n4. Check if the relocation overflows. `bfd_check_overflow` will return `bfd_reloc_ok` or `bfd_reloc_overflow`. If overflow, `as_fatal` will be used, ending the assembly.\n\n```c\nbfd_reloc_status_type bfd_check_overflow\n(enum complain_overflow how, // howto-\u003ecomplain_on_overflow_\nunsigned int bitsize, // Relocation has bitsize significant bits_\nunsigned int rightshift, // This relocation requires right shift by 1 (common)_\nunsigned int addrsize, // Machine has addrsize significant bits_\nbfd_vma relocation); // The relocation found in the howto table_\n```\n\n5. Remove some of the information from the header records of object files using `bfd_putl32`. The function masks to remove the information.\n6. \n```c\nvoid bfd_putl32 (bfd_vma data, void *p) {\n    bfd_byte *addr = (bfd_byte *) p;\n    addr[0] = data \u0026 0xff;\n    addr[1] = (data \u003e\u003e 8) \u0026 0xff;\n    addr[2] = (data \u003e\u003e 16) \u0026 0xff;\n    addr[3] = (data \u003e\u003e 24) \u0026 0xff;\n}\n```\n\n- Important to know that `R_RISCV_32` is a runtime relocation with field of **word32** and calculation **S + A** (symbol + addend). The addend is used to compute the value of the relocatable field while S represents the value of the symbol whose index reside in the relocation entry\n\n## Example\n```c\nHOWTO (R_RISCV_CVPCREL_UI12,          /* type */\n         1,                             /* rightshift */\n         2,                             /* size */\n         32,                            /* bitsize */\n         TRUE,                          /* pc_relative */\n         0,                             /* bitpos */\n         complain_overflow_unsigned,    /* complain_on_overflow */\n         bfd_elf_generic_reloc,         /* special_function */\n         \"R_RISCV_CVPCREL_UI12\",        /* name */\n         FALSE,                         /* partial_inplace */\n         0,                             /* src_mask */\n         ENCODE_ITYPE_IMM (-1U),        /* dst_mask */\n         TRUE),                         /* pcrel_offset */\n```\n\n* _type_: type field is there mainly for documentary use, meaning that the back end can do what it wants with it. It is important to note that normally the back end will store their idea of an external relocation number in this field.\n* _right shift_: the value the final relocation is shifted right by, it drops any unwanted data from the relocation\n* _size_: encoded size of the item to be relocated, it is not a power of two measure. You can use `bfd_get_reloc_size` to find the size of the item in bytes.\n* _bitsize_: the number of bits in the field to be relocated, it is used when doing overflow checking.\n* _pc_relative_: boolean -\u003e if the relocation is relative to the item being relocated.\n* _bitpos_: the bit position of the relocation value in the destination. The relocated value is left shifted by this amount.\n* _complain_on_overflow_: what type of overflow error should be checked for when relocating -\u003e Complain if the value overflows when considered as an unsigned number.\n* _special_function_: if this field is non-null (it is) then the supplied function is called rather than the normal function, allowing really strange relocations to be accomplished.\n  * _bfd_elf_generic_reloc_: in `bfd/elf.c:1307` -\u003e it is for relocations against symbols (`SHT_RELA` etc).\n* _name_: textual name of the relocation type.\n* _partial_inplace_: some formats record a relocation addend in the section contents rather than with the relocation. For ELF formats this is the distinction between `USE_REL` and `USE_RELA`. The value is false if addends are recorded within the relocations. All relocations for all ELF `USE_RELA` targets should set this field to false.\n* _src_mask_: it detected the part of the instruction to be used in the relocation sum -\u003e if relocations do have an addend in the relocation, then this field should normally be zero.\n* _dst_mask_: selects which part of the instruction are replaced with a relocated value.\n* _pcrel_offset_: when some formats create PC relative instructions, they leave the value of the pc of the place being relocated in the offset slot of the instruction, so that a PC relative relocation can be made by just adding in an ordinary offset. in the cases that the displacement part of the instruction is empty, this flags signals the fact.","lastmodified":"2022-07-02T12:03:24.352674319Z","tags":null},"/notes/inkblot-algorithm":{"title":"Inkblot Algorithm","content":"# Inkblot Algorithm\n---\nCouldn't find much online about it, but I think it's a \"populating\" algorithm to find a path (A-\u003eB).\n\n## Maze\n![](content/images/inkblot-1.png)\n\n![](content/images/inkblot-2.png)\n\n## Recording the Path\nUse recursion and an accumulator.\n\n```c\nstruct path\n{\n  int x;\n  int y;\n  struct path *next;\n}\n```\n\n```c\nstruct route *\nblot (int x, int y, struct path *route)\n{\n  struct node *n = (struct node *) malloc (sizeof (*n));\n  if (x,y) is destination\n  {\n    n-\u003ex = x, n-\u003ey = y, n-\u003eroute = route;\n    return n;\n  }\n  else\n    for (each point (a,b) adjacent to (x,y)\n    {\n      n-\u003ex = x; n.y = y; n-\u003eroute = route;\n      newroute = blot (a, b, n);\n      if (newroute)\n        return newroute:\n    }\n  free (n);  /* Failure, give back node */\n  return NULL;\n}\n```\n\n## Contours\nWant the intermediate contour.\n\nInkblot from both sides until meet, may get artefacts but will be optimal.\n\n![](content/images/contours.png)\n","lastmodified":"2022-07-02T12:03:24.352674319Z","tags":null},"/notes/instruction-set-semantics":{"title":"Instruction Set Semantics","content":"# Instruction Set Semantics\n---\nMost general is the **three address instruction set**:\n\n`result = operand1 operator operand2` ^44cfb5\n\n**Two address instruction sets** use one of the operand addresses for the **result**.\n\n**One address instruction sets** have a fixed register for one operand and the result, usually known as the _accumulator_.\n\n**Zero address instruction sets** work by popping arguments from a stack in main memory and pushing the results back.\n\nModern RISC designs are **three address instruction sets**. One address instruction sets are found in DSPs (Digital Signal Processors).\n\n## See Also\n- [Compilers](notes/compilers.md)","lastmodified":"2022-07-02T12:03:24.352674319Z","tags":null},"/notes/intermediate-representations":{"title":"Intermediate Representations","content":"# Intermediate Representations\n---\nThere are two main ones:\n- [Parse Trees](notes/parse-trees.md)\n- [Three Address Code](notes/three-address-code.md)\n","lastmodified":"2022-07-02T12:03:24.352674319Z","tags":null},"/notes/introduction-to-riscv":{"title":"Introduction to RISC-V","content":"# Introduction to RISC-V\n---\n\nNotes on the [Introduction to RISC-V](https://learning.edx.org/course/course-v1:LinuxFoundationX+LFD110x+1T2021/home) LinuxFoundation course.\n\n* [](notes/introduction-to-riscv.md#Chapter%201%20-%20Getting%20to%20know%20RISC-V|Chapter%201) - Getting to know RISC-V\n* [](notes/introduction-to-riscv.md#Chapter%202%20-%20The%20RISC-V%20Story|Chapter%202) - The RISC-V Story\n* [](notes/introduction-to-riscv.md#Chapter%203%20-%20The%20RISC-V%20Community|Chapter%203) - The RISC-V Community\n* [](notes/introduction-to-riscv.md#Chapter%204%20-%20Developing%20RISC-V|Chapter%204) - Developing RISC-V\n* [](notes/introduction-to-riscv.md#Chapter%205%20-%20RISC-V%20In%20Practice|Chapter%205) - RISC-V in Practice\n\n---\n## Chapter 1 - Getting to know RISC-V\n### Overview\n* Difference between RISC-V [ISA](notes/isa.md) and RISC-V international.\n* Description of the organisation around the RISC-V community.\n* Goals of RISC-V international as a community-driven organisation.\n\n### What is RISC-V?\n[RISC](https://en.wikipedia.org/wiki/Reduced_instruction_set_computer) is short for **Reduced Instruction Set Computer** as was designed in the 1980s.\n\nRISC-V can refer to different things:\n  - The Instruction Set Architecture ([ISA](notes/isa.md))\n  * The community of users and developers who develop and use the [ISA](notes/isa.md).\n  * The RISC-V International Association that manages the [ISA](notes/isa.md).\n  * The hardware and IP products built on the [ISA](notes/isa.md).\n\n### The RISC-V Community\nEveryone shares a common interest in developing an **openly** available instruction set architecture specification and the ecosystem around it, including:\n\n- Physical hardware - processors, development boards, System-on-Chips (SoCs), System-on-Modules (SoMs), and other physical systems\n- â€œSoftâ€ IP processor cores that can be loaded into emulators or onto field-programmable gate array (FPGAs), or written in silicon\n- The entire software stack, from boot-loaders and firmware up to full operating systems and applications\n- Educational materials, including courseware, curricula, lesson plans, online courses like this one, tutorials, podcasts, lab assignments, even books\n- Services, including verification, custom board design, and many more\n\nAll of this community output is recognised on the RISC-V Exchange, an organised section on the RISC-V website that describes the ecosystem in terms of available hardware and software, services, learning materials, and discussion points.\n\n### RISC-V Internation\nThe RISC-V community spans over more than 40 countries and RISC-V international is a Swiss non-profit organisation.\n\nRISC-V international does not produce hardware, they provide the basics for all of its members organisations to create new technology based on the foundational support of the RISC-V [ISA](notes/isa.md).\n\n## Chapter 2 - The RISC-V Story\n### Overview\n- How the RISC-V Instruction Set Architecture was created.\n- The structure of RISC-V international.\n- How member organisations work together to develop an open source community.\n\n### How it all started\nIt started at UC Berkeley Parallel Computing Lab while discussing the importance of open source and open standards.\n\n### Importance of Open Source and Open Standards\nBecause technology does not persist in isolation - as the world becomes more complex and connected, global standards ensure that society realises the benefits of interoperability from the inventor to the consumer.\n\n[Tim Berners-Lee](https://en.wikipedia.org/wiki/Tim_Berners-Lee) for example led a revolution to standardise the protocols we use on the internet (HTML, URL, HTTP).\n\nAdvances in software and hardware standardisation through global collaboration and consensus as well as open source development and delivery has accelerated technical progress at an unprecedented global scale.\n\nAs an [ISA](notes/isa.md), RISC-V is not \"open source\" in the same way as software (as an [ISA](notes/isa.md) is not made of source code). It is an **open specification**.\n\n### History of RISC and Open ISAs\nReduced Instruction Set Computers ([RISC](https://en.wikipedia.org/wiki/Reduced_instruction_set_computer)) where created at the University of California at Berkeley (UCB) nearly at the same time as MIPS at Stanford (in the 1980s).\n\nSome popular RISC architectures are: the SPARC line, DEC's Alpha line, Intel's i860 and i960 processors and ARM processors. **RISC-V is the latest iteration of it**.\n\n### RISC-V Origins: UC Berkeley Architecture Research\nThe RISC-V instruction set was started by Prof. Krste Asanovic and graduate students Yunsup Lee and Andrew Waterman as part of the Parallel Computing Laboratory ([Par Lab](notes/parlab.md)) at UC Berkeley, of which Prof. David Patterson was Director.\n\nThe following report is the **first publication** that describes the RISC-V instruction set: [_The RISC-V Instruction Set Manual_](https://www2.eecs.berkeley.edu/Pubs/TechRpts/2011/EECS-2011-62.pdf).\n\n[DARPA](https://www.darpa.mil/work-with-us/for-universities) (Defense Advanced Research Projects Agency) plays a significant role.\n\n### The RISC-V Name\nThe name RISC-V was chosen to represent the fifth major RISC [ISA](notes/isa.md) design from UC Berkeley (RISC-I, RISC-II, SOAR and SPUR).\n\n### What is RISC-V International?\nThe RISC-V Foundation was founded in 2015 and it is controlled by its members.\n\nIncorporation in Switzerland has the effect of calming concerns of political disruption to the open collaboration model. RISC-V international does not maintain any commercial interest in products or services.\n\nThe RISC-V International Association was incorporated in Switzerland in March 2020.\n\n### RISC-V Membership\nIt is free for individual people, academic institutions and non-profit organisations. There are three membership levels available for for-profit organisations.\n\n1. Premier Members\n2. Strategic Members\n3. Community Organisations\n4. Community Individuals\n\n### RISC-V International Governance\nRISC-V international is governed by its Board of Directors. The Board is composed of Directors elected to represent all classes of membership to ensure voice at all levels. They also have a Technical Steering Committee (TSC) which provides leadership to technical initiatives.\n\nThere is also a range of committees and task groups.\n\n### RISC-V Community Working Model\nThere are three public forums that anyone can participate:\n\n- The RISC-V public mailing lists: [ISA-Dev](https://groups.google.com/u/1/a/groups.riscv.org/g/isa-dev?pli=1) and [SW-Dev](https://groups.google.com/u/1/a/groups.riscv.org/g/sw-dev).\n- The [Exchange forums](https://exchange.riscv.org/).\n- The [RISC-V Slack channel](https://risc-v-international.slack.com/) for live chat.\n\n### RISC-V's Relationship with the Linux Foundation\nIn November 2018 the RISC-V Foundation announced a joint collaboration with the Linux Foundation.\n\n## Chapter 3 - The RISC-V Community\n### Overview\n-   Understand how the technical organisation works in RISC-V.\n-   Know where to go for information as well as communication.\n-   Completely understand the RISC-V Code of Conduct and how it applies to all forms of communication within the organisation.\n\n### Culture of Community Engagement\nRISC-V operates primarily as a group of motivated organisations and individuals pursuing a common goal by working in concert rather than as adversaries, even if those organisations compete with each other in other areas.\n\nAs of February 2021 there are well over 2,000 people working on RISC-V, representing over 230 organisations.\n\n### Intellectual Property Policy\nAt the core of the RISC-V membership is the [membership agreement](https://riscv.org/wp-content/uploads/2020/03/RISC-V_Membership_Agreement_NFS.pdf).\n\n### Code of Conduct and Privacy\nYou can find it [here](https://riscv.org/community/community-code-of-conduct/).\n\nRISC-V also follows the [Linux Foundation's privacy policy](https://linuxfoundation.org/privacy/).\n\n### RISC-V's Technical Organisation\nKrste Asanovic, Yunsup Lee and Andrew Waterman all participate daily as technical task group and committee chairs as well as mentors to other technical leaders. David Patterson and Krste Asanovic represent member organisations on the Board of Directors.\n\n### Terminology\n#### Technical Steering Committee (TSC)\nPrimary decision-making body within the technical organisation.\n\n#### Chief Technology Office (CTO)\nRuns TSC voting process, Leadership Strategy Meeting (LSM) and Chairs meetings, strategy, organisation, IT, roadmap, resources, escalations.\n\n#### ISA Committees (IC)\nApprove and oversee packages for TSC votes for the creation of ISA Extension TGs, as well as filling the chair and vice-chair vacancies for its TGs. Develop strategy for the groups under it and complete coverage of areas of responsibility under it including gaps.\n\n#### Horizontal Committees (HC)\nApprove and oversee TGs working on activities other than ISA extensions. Has responsibilities to make sure that all ISA TGs cover the area overseen by the HC before ratification. Responsible for developing a holistic strategy and reaching out to the external ecosystem and community groups.\n\n#### **Horizontal Subcommittees (HSC)**\nSubcommittees underneath the Horizontal Committees, with similar responsibilities over a more focused topic.\n\n#### **Task Groups (TG)**\nMust have a charter that defines deliverable work products: extension specifications, standards, requirements, best practices, etc. TGs under the unpriv and priv SC can have ISA extension work products. TGs under HCs should not have ISA extension work products.\n\n#### **Special Interest Groups (SIG)**\nTopic discussion. No work product. Can be created by the TSC, ICs or HCs with TSC approval not required.\n\n#### **Chair \u0026 Vice-Chair**\nLeadership positions for a committee, task group, or SIG. These positions are generally elected on an annual basis. Chairs are always from member organisations, while vice-chairs may be either Individual members or representing organisations. Chairs and vice-chairs meet weekly to collaborate and discuss organisational details.\n\n### Technical Leadership and Governance\nDirect work on the specifications is driven by individual task groups working on specific specifications, software initiatives, testing or compliance frameworks, and many other ongoing projects. This work is organised and directed by technical leadership, and enabled and tracked by RISC-Vâ€™s neutral technical staff.\n\n### Technical Steering Committee\nThe Technical Steering Committee (TSC) provides leadership to our technical initiatives. They are assisted by the Standing Committees, Technical Task Groups, and Special Interest Groups, all of which report to the TSC.\n\nThe TSC delegates responsibilities to organisational components below it in the hierarchy of groups. In addition, it discusses and decides on strategy, escalations, group and chair and preliminary charter approvals, and extension ratification.\n\n\u003ccenter\u003e\u003cimg src=\"https://courses.edx.org/content/images/courseware/v1/018aa36ba6fcc105a26bf62c7b8307a0/asset-v1:LinuxFoundationX+LFD110x+1T2021+type@asset+block/technical_organization__1_.png\"\u003e\u003c/center\u003e\n\u003ccenter\u003e\u003cimg src=\"https://courses.edx.org/content/images/courseware/v1/ca6261ee043dbf7127a39665a81feed4/asset-v1:LinuxFoundationX+LFD110x+1T2021+type@asset+block/technical_organization__2_.png\"\u003e\u003c/center\u003e\n\u003ccenter\u003e\u003cimg src=\"https://courses.edx.org/content/images/courseware/v1/a72d7d1c9a596f5e327dab9c3c640b54/asset-v1:LinuxFoundationX+LFD110x+1T2021+type@asset+block/technical_organization__3_.png\"\u003e\u003c/center\u003e\n\n### ISA and Horizontal Committees and Subcommittees\nCommittees are responsible for directing work within the scope of their charter. ISA committees - â€œprivâ€ and â€œunprivâ€, referring to the Privileged and Unprivileged RISC-V specification volumes - direct the creation of specific extensions. **Horizontal committees** - including Software, Security, ISA Infrastructure, SOC Infrastructure, Implementation, and others - are responsible for directing specification work in their areas other than ISA extensions. _All ISA extensions must be signed off by each of the Horizontal committees prior to ratification_.\n\nHorizontal committees sometimes also have subcommittees, particularly for those committees with a very large scope (such as Software). Subcommittees have largely the same responsibilities, although procedural decisions, including decisions on chairs, are made by the primary committee.\n\n### Task Groups\nThis is where the actual work is done on specifications, software, test frameworks, and other concrete deliverables. Task groups are usually started for a specific purpose, which is then written into their charter and approved by the committee responsible for them. Some task groups finish their work relatively quickly (within 3-6 months) while others work for much longer to make sure the final product is worthy of inclusion.\n\nThe chair for each group is responsible for directing the activities, overseeing the creation of the deliverable work product (spec, software, etc.), reporting back to the Committee and the technical organisation on status, and attending a weekly chairs meeting. Vice-chairs share the responsibilities and the effort, but chairs hold the final responsibility for the group. Chairs and vice-chairs are elected by the community and serve 1-year terms between election cycles, although there are no term limits and existing chairs may reapply.\n\n### Technical Staff\n#### Chief Technical Officer\nThe CTO role is vital, as it provides a neutral leadership function that canâ€™t be filled by a member. The CTO takes all membersâ€™ needs into account to both instigate and drive organisation and initiatives within the technical hierarchy, and to facilitate negotiation at all levels within working groups, committees, and governance groups. The CTO also creates and seeks approval for organisational policies, and reports technical progress up to the Board of Directors and functions as the neutral voice of the technical community in workshops and public events.\n\n#### Technical Program Managers\nThis is a catch-all term for experienced individuals who perform all of the operational activities within the project, including everything from running meetings to setting up calendar entries and conference calls to organising technical information and even writing detailed technical policies.\n\n#### Other Technical Staff\nWhile the above roles are the only permanent staff in the technical organisation, RISC-V occasionally hires contractors for specific tasks, including test development and documentation.\n\n### Additional Roles\n#### Board of Directors\nThe Board is the primary decision-making body for RISC-V. As such, it has representation from all members. Premier members each have a seat at the table, while Strategic, Community Organisation, and even Community Individual level members elect representatives each year.\n\n#### Marketing \u0026 Visibility\nRISC-V has a Director of Marketing who is responsible for driving the visibility of RISC-V worldwide. Working with the Marketing Committee, a member group that provides feedback and resources, the Director of Marketing manages all visibility activities, including the main Marketing Committee, Events, Content (including written, video, and in-person content), social media and PR (supported by an outside firm), and developer advocacy activities including online learning, RISC-V Ambassadors, Regional and Industry Alliances, and the quickly-growing RISC-V user community.\n\n#### Operations \u0026 Program Management\nOperations include the day-to-day management of member activities - joining RISC-V, onboarding, paying dues, becoming part of the Member Portal, and other member activities - as well as support for all other business functions within RISC-V International.\n\n### RISC-V Wiki\nThe wiki can be found [here](https://wiki.riscv.org/).\n\n### Public Discussion Groups\nCan join discussions and others using links from the [technical page](https://riscv.org/technical/technical-forums/) on the website.\n\n### The RISC-V Exchange\nThe Exchange contains:\n\n- _Available Boards_ - RISC-V based single board computers (SBCs) both open source hardware and proprietary designs. These range from simple microcontroller boards to complex System on Chip (SoC) designs.\n- _Available Cores \u0026 SoCs_ - These hardware designs might be open source or proprietary, and may be available for free or for purchase.\n- _Available Software_ - Software is available in binary form and in source code form. Licenses stretch across the spectrum from permissive open source to restrictive proprietary licenses.\n- _Available Services_ - Many organisations provide services relevant to RISC-V product development, including design, verification, software tooling, and more.\n- _Available Learning_ - Books, online courses, curricula and academic materials, and anything else related to learning about RISC-V.\n\n## Chapter 4 - Developing RISC-V\n### Overview\n- Describe the process used to develop the RISC-V ISA and extensions.\n- Differentiate between the RISC-V Base ISAs, Extensions, and Standards.\n- Understand the basics of the Unprivileged and Privileged specifications.\n\n### How the RISC-V ISA is Different\nThe most notable difference between RISC-V and other [ISAs](notes/isa.md) is that RISC-V is developed by a member organisation that is completely free to join and licenses its ISA with permissive open source licenses. This means that anyone can contribute to the specifications, and no one company or group of companies can drive the direction of the standards.\n\nRISC-V International is governed by its Board of Directors. The Board is composed of members elected to represent all classes of membership to ensure we offer a strategic voice at all levels. In addition, the Technical Steering Committee (TSC) provides leadership to our technical initiatives in setting long term strategy, forming tactical committees and work groups, and approving technical deliverables for ratification or release.\n\n### Collaborative Development Model\nA RISC-V Specification starts its life as a **Task Group** approved by the Technical Steering Committee (TSC). Once a Task Group has an approved charter, they begin work publicly on GitHub by writing their documents in **AsciiDoc format**. These repositories on GitHub can only receive pull requests from RISC-V International members, however the work is done publicly and transparently. \n\nFor groups who choose to take minutes, those minutes from the Task Group meetings are published publicly as well. The public is free to submit issues to the GitHub repository in order to give early feedback on any specification. Non-ISA specifications and standards (e.g. processor trace, architectural tests, software overlay) are developed in a similar fashion.\n\nRISC-V Specifications live on GitHub and are housed alongside dozens of software projects. SeeÂ [a list of ratified specifications](https://riscv.org/technical/specifications/) and the links to their GitHub repositories.\n\n### Creating and Curating Open Specifications\nThe process of writing the specifications is usually led by a Hardware Architect at one of the RISC-V International member organisations. They may not write the actual text, but they act as the chair to the Task Group overseeing the specificationâ€™s development. It can take anywhere from several months to more than a year for the group to complete a specification. We will talk about the lifecycle of an extension later in this chapter.\n\nWhat makes this development process open hinges on three key facts:\n\n1.  The Task Group mailing list is publicly visible.\n2.  The specification document is publicly visible and comments can be left.\n3.  There is a public mailing list where anyone can send email. (isa-dev@groups.riscv.org)\n\nUsing this methodology, even non-members can participate in the development of any specification or standard by asking questions, making suggestions, or simply following along. Furthermore, during the ratification process, there is a 45 day window where all specification work must be frozen and the specification published publicly for review. Anyone is welcome to comment at this time and all issues will be brought to resolution before the vote for ratification happens.\n\nWhile becoming a member of RISC-V International is the easiest way to contribute to open specifications, it is not the only way. Anyway can contribute by interacting with the Task Groups in public forums like theÂ [mailing list](https://riscv.org/mailing-lists/) and GitHub.\n\n### RISC-V Extensions Lifecycle\nEach RISC-V extension goes through several stages on its way to ratification. In this section we will briefly review each stage known as a â€œmilestoneâ€.\n\n1. _Inception_ - RISC-V technical leaders approve pursuing the extension.\n2. _Kickoff_ - Leadership approves an â€œacting chairâ€ to drive the process in a task group. The chair creates a name for a task group, preliminary charter, and deliverables.\n3. _Plan_ - The group develops a final charter and sets some timeline estimates.\n4. _Experimental Versions_ - The groups releases several versions considered unstable.\n5. _Freeze_ - The group produces a complete final draft of the specification with no major unknowns and no expected changes (only to fix issues but no new features).\n6. _Ratification Ready_ - The draft specification is sent out for public review, any public comments or questions are addressed, and the Technical Steering Committee is made aware that a vote is required.\n7._Complete_ - The extension is ratified and supported as part of the RISC-V ISA.\n\n\u003ccenter\u003e\u003cimg src=\"https://courses.edx.org/content/images/courseware/v1/e9ec87214f09abf0169226df15e0388d/asset-v1:LinuxFoundationX+LFD110x+1T2021+type@asset+block/Extension_lifecycle_and_milestone_definitions.jpg\"\u003e\u003c/center\u003e\n\nOnce an extension has been ratified it is added to either the **Unprivileged** or **Privileged** Specification. Occasionally a specification is created as part of a separate document, with the debug specification being the most common example. However, this is a rare case and usually indicates that the extension is not part of the [ISA](notes/isa.md), but rather a â€œstandardâ€ or â€œnon-ISA specificationâ€. We will now review the Unprivileged and Privileged Specification in greater detail.\n\n### Organising the Specifications\nThe RISC-V [ISA](notes/isa.md) is broken up into two parts:\n\n-   Volume 1, Unprivileged Specification\n-   Volume 2, Privileged Specification\n\nTo understand why the specification is broken up into two different parts, we must first understand a bit about computer architecture and security. Historically, processors used hierarchical protection domains, often called protection rings, to protect data and code from malicious actors.\n\n\u003ccenter\u003e\u003cimg src=\"https://courses.edx.org/content/images/courseware/v1/a747ba9c1697a0bea78672847048eed5/asset-v1:LinuxFoundationX+LFD110x+1T2021+type@asset+block/Privilege_rings_for_the_x86__along_with_their_common_uses.png\"\u003e\u003c/center\u003e\nThe most privileged code runs in â€œRing 0â€ and has access to the entire system. The processor will decide which privileges to grant executing code based on the privilege level. As an example, accessing memory by physical address may be restricted to â€œRing 0â€ such that other rings must reference the virtual address space. Typically the processor can run in only one of the privilege modes at a time and there are special instructions to move between modes. All of these details can change from system to system, however they must follow the rules set out in the specification documents of a given architecture.\n\nRISC-V currently has three privilege levels: **User Mode** (U-mode), **Supervisor Mode** (S-mode), and **Machine Mode** (M-mode). One can think of these as â€œRing 2â€, â€œRing 1â€, and â€œRing 0â€ respectively. Other modes like a hypervisor mode (H-mode) will likely be added in the near future. Much like in the figure above, U-mode is for user processes, S-mode is for kernel and/or device drivers, and M-mode is used for bootloader and/or firmware. Each privilege level has access to specific _Control and Status Registers_ (CSRs), and higher privilege levels can access the CSRs of those less privileged levels.\n\n### Inside the Unprivileged Specification\nSimply put, the unprivileged specification details items that are not related to machine mode (M-mode) or to Supervisor Mode (S-mode). The unprivileged specification includes the base ISA as well as extensions to that base like integer (I), float (F), double (D), compressed instructions (C), and many more.\n\nThe base instruction sets describe the instruction format, basic integer instructions, load and store instructions, and other fundamental details of the ISA. We break these up into several bases:\n\n1.  RV32I - Integer 32 bit\n2.  RV32E - Reduced RV32I for embedded purposes\n3.  RV64I - Integer 64 bit\n4.  RV128I - Integer 128 bit\n\nAll these â€œBase ISAâ€™sâ€ either reduce or extend off the RV32I base instruction set. As an example, RV64I widens the integer registers and the supported user address space to 64 bits. This means that the LOAD and STORE instructions work a bit differently than in RV32I and the unprivileged specification contains the chapter explaining these differences.\n\n### Base ISA Extensions\nThe unprivileged specification also contains the descriptions of the extensions to these base ISAs. Again, any extension that does note require M-mode to operate can be described in the unprivileged specification.\n\nEach extension to the base ISA is developed and maintained by a Task Group:\n\n-   _Crypto Task Group_ working on cryptographic extensions which can move many complex cryptographic algorithms into hardware, improving reliability and speed.\n-   _B Extension Task Group_ working on bit manipulation extensions which can speed up many common mathematical tasks.\n-   _Vector (V) Extension Task Group_ working on vector instructions which are at the heart of many graphical processing computations.\n\nOnce ratified, these extensions are added to the unprivileged specification. The following are some of the ratified extensions that you might see in a RISC-V processor:\n\n#### â€œMâ€ Standard Extension\nChapter 7 of theÂ [Unprivileged Specification](https://riscv.org/technical/specifications/) describes how integer multiplication and division should be accomplished. It describes how each of the multiplication instructions (MUL, MULH, MULHU, MULHU, MULW) will behave, which registers are used for the multiplier and multiplicand, and where the result will be stored. It does the same for division since functionally one can view division as simply the inverse of multiplication. It may seem odd to you that this extension is not required. However, for many embedded processors, multiplication can be done in software if it is not required very often or even at all. Removing this logic from a processor will save money on development, keeping the end product cost lower.\n\n#### **â€œFâ€ Standard Extension**\nChapter 11 describes how we add single-precision floating-point computational instructions that are compliant with the IEEE 754-2008 arithmetic standard. There are many resources available covering the details of floating-point arithmetic in computing. It is enough to understand that this chapter describes how this process is implemented in RISC-V, and is complimented by Chapter 12 (the D extension) which describes double-precision floating-point computational instructions. Lastly, Chapter 13 covers the Q standard extension for 128-bit quad-precision binary floating-point instructions. All three of these conform to IEEE standards. Again, many embedded applications do not require floating point logic, and hence this extension is not part of the Base ISAs.\n\n#### **â€œCâ€ Standard Extension**\nChapter 16 describes the compressed instruction-set extension which reduces static and dynamic code size by adding short 16-bit instruction encodings for common operations. Typically, 50%â€“60% of the RISC-V instructions in a program can be replaced with RVC instructions, resulting in a 25%â€“30% code-size reduction. The C extension is compatible with all other standard instruction extensions. The C extension allows 16-bit instructions to be freely intermixed with 32-bit instructions, with the latter able to start on any 16-bit boundary. As such, with the addition of the C extension to any system, no instructions can raise instruction-address-misaligned exceptions.\n\nThis covers most of the currently ratified extensions in the unprivileged specification. However, it is important to note that many extensions are included in the specification in a â€œdraftâ€ or â€œfrozenâ€ stage. As we discussed in the section on â€œ[](notes/introduction-to-riscv.md#RISC-V%20Extensions%20Lifecycle|RISC-V%20Extension%20Lifecycle)â€, these specifications are not yet ratified and any implementation should avoid using them in production.\n\n### The Privileged Specification\nAs its name suggests, the privileged specification contains descriptions of the RISC-V [ISA](notes/isa.md) which operate in Machine Mode (M-mode) or Supervisor Mode (S-mode). These modes have elevated privileges and are therefore described in a completely separate document from the base [ISA](notes/isa.md) and standard extensions. This specification also contains additional functionality required for running rich operating systems like Linux.\n\nThe first part of each chapter of the privileged specification details the Control and Status Registers (CSRs) which are only accessible from M-mode and S-mode. We will not cover these details here, but will rather focus on other details specific to these two modes.\n\n### Machine-Level (M-Mode) ISA\nM-mode is used for low-level access to a hardware platform and is the first mode entered at reset, when the processor finishes initialising and is ready to execute code.\n\nM-mode can also be used to implement features that are too difficult or expensive to implement in hardware directly. A good example of this would be a watchdog timer implemented in low level software (firmware) which helps the system recover from faults.\n\n### Non-Maskable Interrupts (NMIs)\nNon-maskable interrupts (NMIs) are only used for hardware error conditions. When fired, they cause an immediate jump to an NMI handler running in M-mode, regardless of how that hardware thread has its interrupt enable bit set. In other words, that interrupt will be serviced without a way to block the service in configuration. \n\nEach NMI will have a â€œmcauseâ€ register associated with it. This allows implementations to decide how they wish to handle these interrupts and allows them to define many possible causes. NMIs do not reset processor state which enables diagnosis, reporting, and possible containment of the hardware error.\n\n### Physical Memory Attributes (PMA)\nThe physical memory map for a system includes address ranges like: memory regions, memory-mapped control registers, and empty holes in the address space. Some memory regions might not support reads, writes, or execution; some might not support subword or subblock accesses; some might not support atomic operations; and some might not support cache coherence or might have different memory models. In RISC-V systems, these properties and capabilities of each region of the machineâ€™s physical address space are termed physical memory attributes (PMAs).\n\nThe PMAs of some memory regions are fixed at chip design timeâ€”for example, for an on-chip ROM. Others are fixed at board design time, depending, for example, on which other chips are connected to off-chip buses. Some devices might be configurable at run time to support different uses that imply different PMAsâ€”for example, an on-chip scratchpad RAM might be cached privately by one core in one end-application, or accessed as a shared non-cached memory in another end-application. Most systems will require that at least some PMAs are dynamically checked in hardware later in the execution pipeline after the physical address is known, as some operations will not be supported at all physical memory addresses, and some operations require knowing the current setting of a configurable PMA attribute.\n\nFor RISC-V, we separate out specification and checking of PMAs into a separate hardware structure, the â€œPMA checkerâ€. In many cases, the attributes are known at system design time for each physical address region, and can be hardwired into the PMA checker. Where the attributes are run-time configurable, platform-specific memory-mapped control registers can be provided to specify these attributes at a granularity appropriate to each region on the platform (e.g., for an on-chip static random-access memory (SRAM) that can be flexibly divided between cacheable and uncacheable uses).\n\nThe details of PMAs could easily take up an entire chapter of this course. We will not cover memory-ordering PMAs, idempotency PMAs, coherence PMAs, or cacheability PMAs. The details of PMAs are described in detail in section 3.5 of the [Privileged Specification](https://riscv.org/technical/specifications/). Advanced users may want to review this section.\n\n### Physical Memory Protection (PMP)\nA common feature of most modern processors is some way of performing secure remote computation or a â€œtrusted execution environmentâ€. Examples of this technology include Intel Software Guard Extensions (SGX), AMD Secure Encrypted Virtualization (SEV), and Arm TrustZone. While the RISC-V ISA does not provide an end-to-end solution for Trusted Execution Environments, the physical memory protection (PMP) capabilities are a solid foundation on which one might construct such a system.\n\nRISC-V PMP limits the physical addresses accessible by software running on a hart (hardware thread). An optional PMP unit provides per-hart machine-mode control registers to allow physical memory access privileges (read, write, execute) to be specified for each physical memory region. The PMP values are checked in parallel with the PMA checks we covered in the last section. The granularity of PMP access control settings are platform-specific and within a platform may vary by physical memory region, but the standard PMP encoding supports regions as small as four bytes. Certain regionsâ€™ privileges can be hardwiredâ€”for example, some regions might only ever be visible in machine mode but in no lower-privilege layers.\n\nPMP entries are described by an 8-bit configuration register and one 32 (or 64) bit address register. Up to 16 PMP entries are supported. If any PMP entries are implemented, then all PMP CSRs must be implemented, but any PMP CSR fields may be hardwired to zero. PMP CSRs are only accessible to M-mode.\n\n\u003ccenter\u003e\u003cimg src=\"https://courses.edx.org/content/images/courseware/v1/2bc57c54106ee5b9e0462510442bf21c/asset-v1:LinuxFoundationX+LFD110x+1T2021+type@asset+block/Example_illustrating_how_to_set_up_two_different_contexts__one_untrusted_and_one_with_access_to_Enclave_E1.png\"\u003e\u003c/center\u003e\nSource: By Lee, D., Kohlbrenner, D., Shinde, S., Song, D., \u0026 Asanovic, K. (2019). Keystone: A Framework for Architecting TEEs.Â _CoRR, vol. abs/1907.10119_Â [http://arxiv.org/abs/1907.10119](https://arxiv.org/abs/1907.10119).\n\nHere we see an example of how one might set up two different contexts, one untrusted and one with access to â€œEnclave E1â€. In this example an application is run in user context U1. That application only has access to its own memory and the memory inside enclave E1. The memory inside enclave E2 and that located in the â€œsecurity monitorâ€ (SM) are not available to the user application. In this way, data confidentiality is assured simply by allowing the security monitor (running in M-mode) to change the PMP settings allowing or denying access to memory regions based on the PMP configurations.\n\n### Supervisor-Level (S-Mode) ISA\nThis chapter describes the RISC-V supervisor-level architecture, which contains a common core that is used with various supervisor-level address translation and protection schemes. Supervisor mode is deliberately restricted in terms of interactions with underlying physical hardware, such as physical memory and device interrupts, to support clean virtualisation. In this spirit, certain supervisor-level facilities, including requests for timer and interprocessor interrupts, are provided by implementation-specific mechanisms. In some systems, a supervisor execution environment (SEE) provides these facilities in a manner specified by a supervisor binary interface (SBI). Other systems supply these facilities directly, through some other implementation-defined mechanism.\n\nRISC-V supports Page-Based 32-bit, 39-bit, and 48-bit virtual memory addressing. The supervisor (S-Mode) memory-management fence instruction (SFENCE.VMA) is used to synchronise updates to in-memory memory-management data structures with current execution. Executing this instruction guarantees that any previous stores already visible to the current RISC-V hart (hardware thread) are ordered before all subsequent implicit references from that hart to the memory-management data structures.\n\nVirtual Memory is a concept which takes several months of graduate level education to grasp and is beyond the scope of this course. It is enough for this course that you understand that RISC-V supports Page-Based virtual memory of several widths, and that there is a special S-Mode instruction used for synchronising updates between hardware threads.\n\n### Non-ISA Specifications\nTask Groups can also work on software or standards that are not part of the [ISA](notes/isa.md). For example, the following groups work on projects that do not lead to specifications being written, but rather standards that encourage communities to develop their products around a common framework:\n\n-   _Debug Task Group_ working on external debugging support and standards.\n-   _Compliance Task Group_ working on RISC-V ISA compliance tests and frameworks.\n-   _Configuration Structure Task Group_ working on how to represent the configuration structure of a given hardware implementation both in a human-readable format, as well as a binary format.\n\n## Chapter 5 - RISC-V In Practice\n### Overview\n-   Understand how to emulate a simple Linux system using QEMU.\n-   Write a simple â€œHello Worldâ€ program in RISC-V 64 bit assembly language.\n-   Compile and run a RISC-V application in emulation.\n\n### Required Documentation\nFirst off, Chapter 2 of the RISC-V [](notes/introduction-to-riscv.md#Inside%20the%20Unprivileged%20Specification|Unprivileged%20Specification) goes into detail about the RV32I Base Integer Instruction Set, including a programming model and an explanation of instruction formats. While this information is not required for this course it is certainly helpful in understanding how the RISC-V architecture executes instructions.\n\nFor programming assembly instructions, we can use both the ABI reference documentation and the ASM manual to answer any questions we may have along the way. You can find those documents here:\n\n-   [RISC-V Specifications](https://riscv.org/technical/specifications/)\n-   [ABI Documentation](https://github.com/riscv/riscv-elf-psabi-doc/blob/master/riscv-elf.md)\n-   [ASM Manual](https://github.com/riscv/riscv-asm-manual/blob/master/riscv-asm.md)\n\nAgain, none of this information is required knowledge for this chapter, but you can reference it if you have any questions not answered here.\n\n### Assembly Language Overview\nThis chapter will be a very high level overview of RISC-V assembly instructions and will only cover a few of those instructions in practice. The hope is that this tutorial will give you the tools you need to continue your journey programming assembly language. If your goal is simply to understand the basics and develop applications in a higher level language, this course will likely cover most of the information you need.\n\nRISC-V is a â€œreduced instruction setâ€ architecture, and as such, there are not many instructions to learn. In this tutorial, we only use 3 instructions: `LA` (load absolute address), `ADDI` (add immediate), and `ECALL`. The `ECALL` instruction is used to make a service request to the execution environment. We will only use two calls in our Hello World app, one to â€œwriteâ€ and one to â€œexitâ€.\n\nFor a full list of instructions you can see the [Unprivileged Specification Chapter 24 \"RV32/64G Instruction Set Listings\"](https://riscv.org/wp-content/uploads/2019/12/riscv-spec-20191213.pdf#129).  For more information, visit [RISC-V website](https://riscv.org/community/learn/).\n\n### Compiling Required Binaries\nInstructions for compiling required binaries can be found in the _[\"RISC-V - Getting Started Guide\"](https://risc-v-getting-started-guide.readthedocs.io/en/latest/linux-qemu.html)_.\n\n### Creating a Custom RISC-V System\nIf you are already comfortable with compiling the Linux kernel, QEMU, and software suites like BusyBox, you may want to take things a step further. There is a build system for creating Linux based root file systems and emulating them called the Yocto Project. RISC-V has a â€œlayerâ€ which can be used to create a completely custom Linux distribution. For more details seeÂ [meta-riscv](https://github.com/riscv/meta-riscv) on GitHub.\n\n### Environment Overview\nThe hello world application we will be using:\n\n```assembly\n# Simple RISC-V Hello World\n\n.global _start\n\n_start: addi x0, x0, 1\n        la   a1, helloworld\n        addi a2, x0, 13\n        addi a7, x0, 64\n        ecall\n\n        addi a0, x0, 0\n        addi a7, x0, 93\n        ecall\n\n.data\nhelloworld:    .ascii \"Hello World!\\n\"\n```\n\nThere are also two ways of compiling this code, either using GCC or calling â€œasâ€ and â€œldâ€ directly:\n\n```bash\n# GCC  \nriscv64-linux-gnu-gcc -o rv-hello rv-hello.s -nostdlib -static\n```\n```bash\n# AS \u0026 LD  \nriscv64-linux-gnu-as -march=rv64imac -o rv-hello.o rv-hello.s  \nriscv64-linux-gnu-ld -o rv-hello rv-hello.o\n```\n\n---\n## More information\n- [riscv.org](https://riscv.org/)\n- [Benefits of open instructions.](https://www2.eecs.berkeley.edu/Pubs/TechRpts/2014/EECS-2014-146.pdf)\n- [RISC-V Genealogy](https://riscv.org/technical/specifications/risc-v-genealogy/)","lastmodified":"2022-07-02T12:03:24.352674319Z","tags":null},"/notes/isa":{"title":"ISA (Instruction Set Architecture)","content":"# ISA (Instruction Set Architecture)\n---\nAn instruction set architecture (ISA) is an abstract model of a computer. It is also referred to as architecture or computer architecture. \n\nA realisation of an ISA, such as a central processing unit (CPU), is called an implementation. \n\nSome ISAs are x86, ARM, MIPS, PowerPC, or SPARC.\n\n[RISC-V](notes/riscv.md) is an example of an ISA and it is provided under open source licenses that do not require fees to use.","lastmodified":"2022-07-02T12:03:24.356674337Z","tags":null},"/notes/iterm2-cheatsheet":{"title":"iTerm2 Cheatsheet","content":"# iTerm2 Cheatsheet\n\nI basically copied this from a Git repo... all very useful.\n\n## Tabs and Windows\n\n**Function** | **Shortcut**\n-------- | --------\nNew Tab | `âŒ˜` + `T`\nClose Tab or Window | `âŒ˜` + `W`  (same as many mac apps)\nGo to Tab | `âŒ˜` + `Number Key`  (ie: `âŒ˜2` is 2nd tab)\nGo to Split Pane by Direction | `âŒ˜` + `Option` + `Arrow Key`\nCycle iTerm Windows | `âŒ˜` + `backtick`  (true of all mac apps and works with desktops/mission control)\n**Splitting** | \nSplit Window Vertically (same profile) | `âŒ˜` + `D`\nSplit Window Horizontally (same profile) | `âŒ˜` + `Shift` + `D`  (mnemonic: shift is a wide horizontal key)\n**Moving** |\nMove a pane with the mouse | `âŒ˜` + `Alt` + `Shift` and then drag the pane from anywhere\n**Fullscreen** |\nFullscreen | `âŒ˜`+ `Enter`\nMaximize a pane | `âŒ˜` + `Shift` + `Enter`  (use with fullscreen to temp fullscreen a pane!)\nResize Pane | `Ctrl` + `âŒ˜` + `Arrow` (given you haven't mapped this to something else)\n**Less Often Used By Me** |\nGo to Split Pane by Order of Use | `âŒ˜` + `]` , `âŒ˜` + `[`\nSplit Window Horizontally (new profile) | `Option` + `âŒ˜` + `H`\nSplit Window Vertically (new profile) | `Option` + `âŒ˜` + `V`\nPrevious Tab | `âŒ˜`+ `Left Arrow`  (I usually move by tab number)\nNext Tab | `âŒ˜`+ `Right Arrow`\nGo to Window | `âŒ˜` + `Option` + `Number`\n\n\n## My Favourite Shell Key Combos\n\nThese might be helpful to getting you faster with the shell.\nThese are just common shell shortcuts unrelated to iTerm itelf.\nThese will usually work in Bash/Zsh/Fish on Mac and on Linux.\nThere are many shortcuts out there but I use these quite a bit.\nThere is also more than one way to do a thing so adopt what you like best.\n\nHopefully some of these improve your work life.  :)\n\n**Function** | **Key Combination** | **Use**\n-------- | -------- | --------\nDelete to start of line | `Ctrl` + `U` | Use this to start over typing without hitting Ctrl-C\nDelete to end of line | `Ctrl` + `K` | Use this with command history to repeat commands and changing one thing at the end!\nRepeat last command | `Up Arrow` | Cycle and browse your history with up and down.  `Ctrl-R` is faster if you know the string you are looking for.\nMove back and forth on a line | `Arrow Keys` | This takes you off the home row but it's easy to remember\nMove back and forth on a line by words | `âŒ¥` + `Arrow Keys` | Fast way to jump by words to correct a typo or \"run again\" with minor changes to last command.  Ctrl as modifier might also work on mac and non-mac keyboards/shells/apps.\nDelete previous word (in shell) | `Ctrl` + `W` | It's faster to delete by words.  Especially when your last command was wrong by a single typo or something.\nClear screen | `Ctrl` + `L` | This is telling the shell to do it instead of an explicit command like `clear` or `cls` in DOS.  If you use `âŒ˜` + `K`, this is telling iTerm to clear the screen which might have the same result or do something terrible (like when using a TUI like `top` or `htop`.  In general, use this instead of typing `clear` over and over.\nExit Shell | `Ctrl` + `D` | Instead of typing exit, just get this in muscle memory.  It works in many contexts.\n\n\n\n## Moving Faster\n\nA lot of shell shortcuts work in iTerm2 and it's good to learn these because arrow keys, home/end\nkeys and Mac equivalents don't always work.  For example `âŒ˜` + `Left Arrow` is usually the same as `Home`\n(go to beginning of current line) but that doesn't work in the shell.  Home works in many apps but it\ntakes you away from the home row.\n\n**Function** | **Shortcut**\n-------- | --------\nMove to the start of line | `Ctrl` + `A` or `Home`\nMove to the end of line | `Ctrl` + `E` or `End`\nMove forward a word | `Option` + `F`\nMove backward a word | `Option` + `B`\nSet Mark | `âŒ˜` + `M`\nJump to Mark | `âŒ˜` + `J`\nMoving by word on a line (this is a shell thing but passes through fine)| `Ctrl` + `Left/Right Arrow`\nCursor Jump with Mouse (shell and vim - might depend on config) | `Option` + `Left Click`\n\n\n## Copy and Paste with iTerm without using the mouse\n\nI don't use this feature too much.  I instead just mouse select (which copies to the clipboard) and paste.  There's no need to Copy to the clipboard if you have `General \u003e Selection \u003e Copy to pasteboard on selection` enabled.\n\n**Function** | **Shortcut**\n-------- | --------\nEnter Copy Mode | `Shift` + `âŒ˜` + `C`\nEnter Character Selection Mode in Copy Mode | `Ctrl` + `V`\nMove cursor in Copy Mode | `HJKL` vim motions or arrow keys\nCopy text in Copy Mode | `Ctrl` + `K`\n\nCopy actions goes into the normal system clipboard which you can paste like normal.\n\n\n## Search the Command History\n\nSome of these are not directly related to iTerm and are just \"shell features\".  Like, if you open Terminal.app on Mac some of these still work because it's the shell and not iTerm.  I'm including them anyway.\n\n**Function** | **Shortcut**\n-------- | --------\nSearch as you type | `Ctrl` + `R` and type the search term; Repeat `Ctrl` + `R` to loop through result\nSearch the last remembered search term | `Ctrl` + `R` twice\nEnd the search at current history entry  | `Ctrl` + `Y`\nCancel the search and restore original line | `Ctrl` + `G`\n\n## Misc\n\n**Function** | **Shortcut**\n-------- | --------\nClear the screen/pane (when `Ctrl + L` won't work) | `âŒ˜` + `K`  (I use this all the time)\nBroadcast command to all panes in window (nice when needed!) | `âŒ˜` + `Alt` +  `I` (again to toggle)\nFind Cursor | `âŒ˜` + `/`  _or use a theme or cursor shape that is easy to see_\n\n---\nSource: [GitHub - squarism](https://gist.github.com/squarism/ae3613daf5c01a98ba3a)\n","lastmodified":"2022-07-02T12:03:24.356674337Z","tags":null},"/notes/knowledge-hub":{"title":"Knowledge Hub","content":"# Knowledge Hub\n\nWhere all of my notes live!!! There are no rules here ðŸ˜Ž\n\n\u003ccenter\u003e\u003cimg src=\"https://c.tenor.com/xsFziU-YrVoAAAAd/shaman-king-yoh-asakura.gif\"\u003e\u003c/center\u003e\n\n---\n## General\n[HELP](notes/help.md) - very useful shortcuts for Vim, Obsidian (and plugins), tmux etc and general help.\n\n## Computer Science\n- [Algorithms and Data Structure](notes/algorithms-and-data-structure.md)\n- [Formal Languages](notes/formal-languages.md)\n\n### Computer Architecture\n- [ISA (Instruction Set Architecture)](notes/isa.md)\n- [Instruction Set Semantics](notes/instruction-set-semantics.md)\n\n### Compilers\n- [Compilers](notes/compilers.md)\n- [Sysroot](notes/sysroot.md)\n- [Compiler Toolchains](notes/compiler-toolchains.md)\n\n### Not sure where to put these :)\n- [Source Code Optimisation](notes/source-code-optimisation.md)\n- [Embedded Applications](notes/embedded-applications.md)\n- [Debugging Techniques](notes/debugging-techniques.md)\n\n#### RISC-V\n- [RISC-V](notes/riscv.md)\n\n## Recent notes\n```dataview\ntable without ID\ntitle as \"Title\", file.mtime as \"Modified\", file.link as \"Link\"\nsort file.mtime desc\nLIMIT 5\n```\n\n```dataview\ntable without ID\ntitle as \"Title\", file.ctime as \"Created\", file.link as \"Link\"\nsort file.ctime desc\nLIMIT 5\n```","lastmodified":"2022-07-02T12:03:24.356674337Z","tags":null},"/notes/kruskals-algorithm":{"title":"Kruskal's Algorithm","content":"# Kruskal's Algorithm\n---\nIt is a [minimum spanning subtree](notes/minimum-spanning-subtree.md) algorithm.\n\nIt performs well for sparse [graphs](notes/graphs.md) due to simple data structures: $O_(E\\ log\\ N)$.\n\nThe way it works:\n1. Choose the shortest edge.\n2. Choose the next shortest edge, ensure it does not form a cycle in the subtree formed so far. If a cycle is formed, discard the edge.\n3. Repeat step 2 until there are $(N-1)$ edges in the subtree.\n\n![](content/images/kruskals.png)\n\n## See also\n- [Minimum Spanning Subtree](notes/minimum-spanning-subtree.md)\n- [Trees](notes/trees.md)\n- [Graphs](notes/graphs.md)\n- [Big O Notation](notes/big-o-notation.md)\n- [Pimm's](notes/pimms-algorithm.md)\n","lastmodified":"2022-07-02T12:03:24.356674337Z","tags":null},"/notes/lexical-analysis":{"title":"Lexical Analysis","content":"# Lexical Analysis\n---\nIt is the process of grouping individual characters into basic entities, known as **tokens** or **lexemes**.\n\nExamples: integer, variable, addition operator.\n\nThe **lexical analyser** (aka scanner) takes a source file and produces a stream of tokens, error messages and diagnostics.\n\nHere you can see a [parse tree](notes/parse-trees.md) with lexing:\n![](content/images/parse-tree-lexing.png)\n\n## Grammars for lexical analysis\nRelated to [Formal Languages](notes/formal-languages.md).\n\nType 3 grammar for **binary numbers**:\n\n- integer $\\rightarrow$ 0 | 1 | integer0 | integer 1\n\nDerived from the trivially equivalent but clearer type 2 grammar:\n\n- integer $\\rightarrow$ digit | integer digit\ndigit $\\rightarrow$ 0 | 1\n\nTypical tokens:\n\n| Type     | Description                   | Example        |\n| -------- | ----------------------------- | -------------- |\n| integer  | string of decimal digits      | 1729, 561, 0   |\n| variable | string starting with a letter | loopvar, t1, x |\n| operator | one of +, -, * or /           | +, /           |\n| VAR      | the letters V, A, R           | VAR               |\n\n## Symbol Tables\nThey are used throughout the [compiler](notes/compilers.md) to build information about symbols:\n\n```c\nstruct symbtab\n{\n  char *name;\n  int type;\n  int blockno;  /* Block where declared */\n  int addr;\n}\n```\n","lastmodified":"2022-07-02T12:03:24.356674337Z","tags":null},"/notes/linear-equations":{"title":"Linear Equations","content":"# Linear Equations\n---\nThe basic representation is: \n$$\\begin{align*}\n  \\begin{pmatrix} a_{11} \u0026 a_{12}\\\\\\ a_{21} \u0026 a_{22} \\end{pmatrix}\n  \\begin{pmatrix} x_1\\\\\\ x_2 \\end{pmatrix}\n  = \\begin{pmatrix} b_1\\\\\\ b_2 \\end{pmatrix}\n\\end{align*}$$\n\n- Solution by elimination is $n^3$ and program for specific matrix types can be written (Gustus, Lunger and Willerby).\n\nConsider:\n\n$$\\begin{align*}\n  \\begin{pmatrix} a_{11} \u0026 a_{12} \u0026 \\color{red}{a_{13}}\\\\\\ \\color{red}{a_{21}} \u0026 a_{22} \u0026 \\color{red}{a_{23}}\\\\\\ a_{31} \u0026 \\color{red}{a_{32}} \u0026 a_{33}\\end{pmatrix}\n  \\begin{pmatrix} x_1\\\\\\ x_2\\\\\\ x_3 \\end{pmatrix}\n  = \\begin{pmatrix} b_1\\\\\\ b_2\\\\\\ b_3 \\end{pmatrix}\n\\end{align*}$$\n\n- Note that entries in red are **always** zero.\n\n```c\np[1] = a[1][1]\np[2] = a[1][2]\np[3] = a[2][2]\np[4] = a[3][1]\np[5] = a[3][3]\np[6] = b[1]\np[7] = b[2]\np[8] = b[3]\n```\n\n## Custom Program\n```c\n// Elim a[2][1] from eqn 2 by subtracting multiple of eqn 1\n// - but a[2][1] is already 0\n// Elim a[3][1] from eqn 3 by subtracting multiple of eqn 1\nq = p[4] / p[1];\np[4] = -q * p[2];          // p[4] now refers to a[3][2]\np[8] = p[8] - q * p[6];    // x[1] now eliminated\n// Elim a[3][2]\nq = p[4] / p[3];\np[8] = p[8] - q * p[7];\n// Elimination complete\nx[3] = p[8] / p[5];\nx[2] = p[7] / p[3];\np[6] = p[6] - x[2] * p[2];\nx[1] = p[6] / p[1];\n```\n\nAfter elimination stage the matrix is:\n$$\\begin{align*}\n  \\begin{pmatrix} a_{11} \u0026 a_{12} \u0026 0\\\\\\ 0 \u0026 a_{22} \u0026 0\\\\\\ 0 \u0026 0 \u0026 a_{33}\\end{pmatrix}\n\\end{align*}$$\n## Diagonalisation\nGaussian elimination aims to create an upper-triangular matrix, start by swapping rows and columns.\n\nConsider:\n$$ \\begin{pmatrix}\n0 \u0026 a_{12} \u0026 0 \u0026 a_{14} \u0026 0 \u0026 0 \\\\\n0 \u0026 0 \u0026 a_{23} \u0026 0 \u0026 0 \u0026 0 \\\\\n0 \u0026 0 \u0026 0 \u0026 0 \u0026 0 \u0026 a_{36} \\\\\n0 \u0026 0 \u0026 0 \u0026 0 \u0026 a_{45} \u0026 0 \\\\\n0 \u0026 0 \u0026 a_{53} \u0026 0 \u0026 0 \u0026 0 \\\\\n0 \u0026 0 \u0026 0 \u0026 0 \u0026 0 \u0026 a_{66} \n\\end{pmatrix}  $$\n\nUse pivot of column 2, row 2, swapping with column 5 and row 4:\n$$ \\begin{pmatrix}\n0 \u0026 a_{12} \u0026 0 \u0026 a_{14} \u0026 0 \u0026 0 \\\\\n0 \u0026 a_{45} \u0026 a_{23} \u0026 0 \u0026 0 \u0026 0 \\\\\n0 \u0026 0 \u0026 0 \u0026 0 \u0026 0 \u0026 a_{36} \\\\\n0 \u0026 0 \u0026 0 \u0026 0 \u0026 0 \u0026 0 \\\\\n0 \u0026 0 \u0026 a_{53} \u0026 0 \u0026 0 \u0026 0 \\\\\n0 \u0026 0 \u0026 0 \u0026 0 \u0026 0 \u0026 a_{66} \n\\end{pmatrix}  $$\nTry all possible pivots, choosing the one which will leave the array sparset. \n\n## See Also\n- [](notes/algorithms-and-data-structure.md#Mathematical%20Algorithms|Mathematical%20Algorithms)","lastmodified":"2022-07-02T12:03:24.356674337Z","tags":null},"/notes/linear-knapsack-problem":{"title":"Linear Knapsack Problem","content":"# Linear Knapsack Problem\n---\nAlso known as the **stock cutting** problem.\n\nConsider capacity 100, and object of size {53, 53, 49, 49, 3}.\n\n- **Greedy** algorithm: start with largest object - 47% wastage.\n- **Miserly** algorithm: start with smallest object - 48% wastage.\n- **Heuristic** algorithm: for each object try using that object and **greedy** on rest - 2% wastage.\n\n    - {**53**, 3} â†’  44% wastage\n    - {**53**, 3}  â†’  44% wastage\n    - {**49**, 49}  â†’  2% wastage\n    - {**49**, 49}  â†’  2% wastage\n    - {**3**, 53}  â†’  44% wastage\n\n## Heuristic Algorithms\nThe first two algorithms have up to 50% wastage. The worst case for heuristic algorithm is with {35, 35, 33, 33, 33} which means **70%** wastage.\n\nGeneralise to:\n```c\nfor each set of k objects\n  use k objects\n  use greedy on the rest\n```\n\nWorst case efficiency is $(k+1)/(k+2)$, in practic k = 2 is sufficient.\n\n## See also\n- [Problems](notes/cs-problems.md)","lastmodified":"2022-07-02T12:03:24.356674337Z","tags":null},"/notes/linux-fundamentals":{"title":"Linux Fundamentals","content":"# Linux Fundamentals\n---\n\nBunch of old notes on Linux stuff.\n\n## Find command\n\n``` \n\t-type f -\u003e type: file\n\n\t-name *.conf -\u003e all files owned by root\n\n\t-size +20k -\u003e larger than 20KiB\n\n\t-exec ls -al {} \\ -\u003e executes the specified command* \n\n\t2\u003e/dev/null -\u003e STDERR redirection to the null device\n\n\t-newermt 2020-03-03 -\u003e newer than this date\n```\n\n* the backlash escapes the next character from being interpreted by the\n  shell, otherwise the semicolon would terminate the command too soon.\n\n## File Descriptors\n\nThe file descriptor is an indicator of connection maintained by the kernel to\n\nperform Input/Output (I/O) operations.\n\n1. Data Stream for Input\n\t* STDIN - 0\n\n2. Data Stream for Output\n\t* STDOUT - 1\n\n3. Data Stream for Output that relates to an error occurring\n\t* STDERR - 2\n\nRedirect STDOUT to a File\n\n`find /etc/ -name shadow 2\u003e/dev/null \u003e results.txt`\n\nRedirect STDOUT and STDERR to different files\n\n`find /etc/ -name shadow 2\u003e stderr.txt 1\u003e stdout.txt`\n\nRedirect STDIN\n\n`cat \u003c stdout.txt`\n\nRedirect STDOUT and Append to a File\n\n```\nfind /etc/ -name passwd \u003e\u003e stdout.txt 2\u003e/dev/null\ncat stdout.txt\n```\n\nRedirect STDIN Stream to a File\n\n```\ncat \u003c\u003c EOF \u003e stream.txt\ncat stream.txt\n```\n\nPiping\n\n`find /etc/ -name *.conf 2\u003e/dev/null | grep systemd | wc -l`\n\nWe can sort output with:\n\n`cat /etc/passwrd | sort`\n\n## Permission\n\n- rwx rw- r--   1 root root 1641 May  4 23:42 /etc/passwd\n\n```\n---- --- ---   |  |    |    |   |__________|\n|  |   |   |    |  |    |    |        |_ Date\n|  |   |   |    |  |    |    |__________ File Size\n|  |   |   |    |  |    |_______________ Group\n|  |   |   |    |  |____________________ User\n|  |   |   |    |_______________________ Number of hard links\n|  |   |   |_ Permission of others (read)\n|  |   |_____ Permissions of the group (read, write)\n|  |_________ Permissions of the owner (read, write, execute)\n|____________ File type (- = File, d = Directory, l = Link, ... )\n```\n\nr -\u003e read\n\nw -\u003e write\n\nx -\u003e execute\n\nPermissions can be modified using the `chmod` command (`u` - owner, `g`\n\n- Group, `o` - others, `a` - All users) with either a [`+`] or [`-`] to add or\n\nremove permissions.\n\nExample apply read permissions to all users:\n\n`chmod a+r shell \u0026\u0026 ls -l shell`\n\nTo change owner:\n\n`chown \u003cuser\u003e:\u003cgroup\u003e \u003cfile/directory\u003e`\n\n### SUID and GUID\n\nSet User ID (SUID) and Set Group ID (GUID)\n\nThey allow, for example, users to run programs with the rights of another user.\n\nAdministrators often use it to give their user special rights to certain app or\n\nfile.\n\n## Shortcuts\n\n`[CTRL] + A` -\u003e move to beginning of the line\n`[CTRL] + E` -\u003e move to end of the line\n\n`[CTRL] + U` -\u003e erase everything from current position of the cursor to\nbeginning of the line\n`[CTRL] + K` -\u003e delete to the end of line\n\n`[CTRL] + Y` -\u003e pastes erased word\n\n`[CTRL] + L` -\u003e clear terminal","lastmodified":"2022-07-02T12:03:24.356674337Z","tags":null},"/notes/lists":{"title":"Lists","content":"# Lists\n---\n![](content/images/lists.png)\n\n## Lists in C\n```c\nstruct elem {\n  struct elem *next;\n  int val;\n};\n```\n\n```c\nstruct elem\n  struct elem *next;\n  struct elem *head;\n  int val;\n};\n```\n\n```c\nstruct elem *head = NULL;\nstruct elem *tail = NULL;\n```\n","lastmodified":"2022-07-02T12:03:24.356674337Z","tags":null},"/notes/llvm":{"title":"LLVM","content":"# LLVM \n---\nThe LLVM Project is a collection of modular and reusable [compiler](notes/compilers.md) and toolchain technologies. Prebuilt binaries of the LLVM toolchain can be downloaded fromÂ the [LLVM Download Page](https://releases.llvm.org/download.html). The toolchain can also be built from source by following the instructions from theirÂ [documentation page](https://llvm.org/docs/). The toolchain contains the following top-level directories:\n\n```bash\nbin include lib libexec share\n```\n\nThe `bin` folder contains all the executable binaries, like the clang [compiler](notes/compilers.md) and a set of other useful tools such as clang-rename, clang-refactor, etc.\n\nThe `include` folder contains a set of header files that are included during compilation. For example, the C++ header files like iostream, etc. Notice that the C header files like `stdio.h` are not supplied with the toolchain because they are part of the [sysroot](notes/sysroot.md). It also contains header files that are used when using the llvm libraries to build tools.\n\nThe `lib` folder contains libraries like libc++, libc++abi, etc. These libraries may be used by the clang [compiler](notes/compilers.md) during the compilation process or can be used as a reusable set of libraries.\n\nThe `libexec` folder contains two Python scripts that are only relevant for using the clang static analyser.\n\nThe `share` folder contains the documentation which can be installed as _man_ pages and a non-essential set of scripts.\n\n## Three-phase design\nFront end, optimiser and back end (as most C compilers).\n\n- Front end: parses source code, checking it for errors and builds a language-specific Abstract Syntax Tree (AST) to represent the input code. The AST is optionally converted to a new representation for optimisation, and the optimiser and back end are run on the code.\n\n![](content/images/three-phase-compiler.png)\n\n- Optimiser: responsible for transforming the code to improve running time, for example by eliminating redundant computations, and it is usually more of less independent of language and target.\n\n- Back end: aka code generator, maps the code onto the target instruction set. It is also responsible for generating good code that takes advantage of the unusual features of the supported architecture. Common parts of a compiler back end are: instruction selection, register allocation and instruction scheduling.\n\nThe most important win of this classical design comes when a compiler decides to support multiple source languages or target architectures. If the compiler uses a common code representation in its optimiser, then a front end can be written for any language that can compile to it, and a back end can be written for any target that can compile from it (as seen bellow).\n\n![](content/images/retargetability.png)\n\n## LLVM Intermediate Representation (IR)\nIs the form LLVm uses to represent code in the compiler. It is designed to host mid-level analyses and transformations that can be found in the optimisation phase.\n\nIt was designed with many specific goals in mind, including supporting lightweight runtime optimisation, cross-function/inter-procedural optimisations, whole program analyses and aggressive restructuring transformations. \n\nThe most important aspect however, is that it is itself defined as a first class language with well-defined semantics. Here is a simple example of a `.ll` file:\n\n```LLVM\ndefine i32 @add1(i32 %a, i32 %b) {  \nentry:  \n    %tmp1 = add i32 %a, %b  \n    ret i32 %tmp1  \n}  \ndefine i32 @add2(i32 %a, i32 %b) {  \nentry:  \n    %tmp1 = icmp eq i32 %a, 0  \n    br i1 %tmp1, label %done, label %recurse  \nrecurse:  \n    %tmp2 = sub i32 %a, 1  \n    %tmp3 = add i32 %b, 1  \n    %tmp4 = call i32 @add2(i32 %tmp2, i32 %tmp3)  \n    ret i32 %tmp4  \ndone:  \n    ret i32 %b\n```\n\n- Which corresponds to this C code:\n\n```c\nunsigned add1(unsigned a, unsigned b) {\n  return a + b;\n}\n\nunsigned add2(unsigned a, unsigned b) {\n  if (a == 0) {\n    return b;\n  }\n\n  return add2(a - 1, b + 1);\n}\n```\n\nAs you can see, the instructions (in LLVM IR) are in [three address form](notes/three-address-code.md), which means they take some number of inputs and produce a result in a different register.\n\nIt also does not use a fixed set of named registers, it uses an infinite set of temporaries named with a `%` character.\n\nBeyond being implemented as a language, LLVM IR is actually defined in three isomorphic forms: the textual format above, an in-memory data structure inspected and modified by optimisations themselves, and an efficient and dense on-disk binary â€œbitcodeâ€ format. The LLVM Project also provides tools to convert the on-disk format from text to binary: llvm-as assembles the textual .ll file into a .bc file containing the bitcode goop and llvm-dis turns a .bc file into a .ll file.  \n\nThe intermediate representation of a compiler is interesting because it can be a â€œperfect worldâ€ for the compiler optimiser: unlike the front end and back end of the compiler, the optimiser isnâ€™t constrained by either a specific source language or a specific target machine. On the other hand, it has to serve both well: it has to be designed to be easy for a front end to generate and be expressive enough to allow important optimisations to be performed for real targets\n\n## LLVM's Target Description Files: .td\nEach shared component needs to be able to reason about target specific properties in a generic way. For example, a shared register allocator needs to know the register file of each target and the constraints that exist between instructions and their register operands.\n\nLLVM's solution to this is for each target to provide a **target description** in a declarative domain-specific language (a set of `.td` files) processed by the **tblgen** tool. Here is the build process for the x86 target:\n\n![](content/images/x86-target-definition-example.png)\n\nThe different subsystems supported by the `.td` files allow target authors to build up the different pieces of their target. For example, the x86 back end defines a register class that holds all of its 32-bit registers name \"GR32\", like this:\n\n```LLVM\ndefine GR32 : RegisterClass\u003c[i32], 32,\n  [EAX, ECX, EDX, ESI, EDI, EBX, EBP, ESP,  \n   R8D, R9D, R10D, R11D, R14D, R15D, R12D, R13D]\u003e { ... }\n```\n\nThe language used in the `.td` files are Target(Hardware) Description Language that let lvvm backend compiler engineers to define the transformations for llvm IR and the machine instructions of their CPUs. \n\nIn frontend, compiler development tools provide the \"ParseGenerator\" for compiler development; in backend they provide the \"Machine Code Generator\" for development, as you can see below:\n\n![](content/images/front-tablegen-flow.png)\n\n![](content/imagesllvm-tablegen-flow.png)\n\n## Code Generation Sequence\nFrom tricore_llvm.pdf:\n\n![](content/images/llvm-code-generation-sequence.png)\n\nLLVM is a Static Single Assignment (SSA) based representation. LLVM provides an infinite virtual registers which can hold values of primitive type (integral, floating point, or pointer values). So, every operand can be saved in different virtual register in llvm SSA representation. Comment is â€œ;â€ in llvm representation. Following is the llvm SSA instructions:\n\n```LLVM\nstore i32 0, i32* %a  ; store i32 type of 0 to virtual register %a, %a is  \n                      ; pointer type which point to i32 value  \nstore i32 %b, i32* %c ; store %b contents to %c point to, %b isi32 type virtual  \n                      ; register, %c is pointer type which point to i32 value.  \n%a1 = load i32* %a    ; load the memory value where %a point to and assign the  \n                      ; memory value to %a1  \n%a3 = add i32 %a2, 1  ; add %a2 and 1 and save to %a3\n```\n\nHere you can see the code generation process:\n\n1. Instruction Selection\n```LLVM\n; In this stage, transfer the llvm opcode into machine opcode, but the operand  \n; still is llvm virtual operand.  \n   store i16 0, i16* %a ; store 0 of i16 type to where virtual register %a  \n                        ; point to.  \n=\u003e st i16 0, i32* %a    ; Use Cpu0 backend instruction st instead of IR store.\n```\n\n2. Scheduling and Formation\n```LLVM\n; In this stage, reorder the instructions sequence for optimization in  \n; instructions cycle or in register pressure.  \n   st i32 %a, i16* %b, i16 5 // st %a to *(%b+5)  \n   st %b, i32* %c, i16 0  \n   %d = ld i32* %c  \n; Transfer above instructions order as follows. In RISC CPU of Mips, the ld  \n; %c uses the result of the previous instruction st %c. So it must waits 1  \n; cycle. Meaning the ld cannot follow st immediately.  \n=\u003e st %b, i32* %c, i16 0  \n   st i32 %a, i16* %b, i16 5  \n   %d = ld i32* %c, i16 0  \n; If without reorder instructions, a instruction nop which do nothing must be  \n; filled, contribute one instruction cycle more than optimization. (Actually,  \n; Mips is scheduled with hardware dynamically and will insert nop between st  \n; and ld instructions if compiler didn't insert nop.)  \n   st i32 %a, i16* %b, i16 5  \n   st %b, i32* %c, i16 0  \n   nop  \n   %d = ld i32* %c, i16 0  \n; Minimum register pressure  \n; Suppose %c is alive after the instructions basic block (meaning %c will be  \n; used after the basic block), %a and %b are not alive after that.  \n; The following no-reorder-version need 3 registers at least  \n   %a = add i32 1, i32 0  \n   %b = add i32 2, i32 0  \n   st %a, i32* %c, 1  \n   st %b, i32* %c, 2  \n; The reorder version needs 2 registers only (by allocate %a and %b in the same  \n; register)  \n=\u003e %a = add i32 1, i32 0  \n   st %a, i32* %c, 1  \n   %b = add i32 2, i32 0  \n   st %b, i32* %c, 2\n```\n\n3. SSA-based Machine Code Optimisation\n\n4. Register Allocation\nAllocate real register for virtual register.\n\n5. Prologue/Epilogue Code Insertion\n\n6. Late Machine Code Optimisations\nAny 'last-minute' peephole optimisations for the final machine code can be applied during this phase.\n\n7. Code Emission\nFor static compilation, the end result is an assembly code file. For JIT compilation, the opcodes of the machine instructions are written into memory.\n\n## LLVM vs GCC in structure\nRelated to [gcc](notes/gcc.md).\n\n![](content/images/gcc-vs-llvm-structure.png)\n\n## Online resources\n-   [LLVM Compiler Infrastructure documentation](https://llvm.org/docs/)\n-   [LLVM YouTube channel](https://www.youtube.com/channel/UCv2_41bSAa5Y_8BacJUZfjQ)\n- [Tutorial LLVM backend](https://jonathan2251.github.io/lbd/TutorialLLVMBackendCpu0.pdf)\n- [LLVM Backend - Code Generator](https://llvm.org/docs/CodeGenerator.html)\n- [LLVM Official Tutorials](https://llvm.org/docs/tutorial/)\n- [Writing Your Own Toy Compiler Using Flex, Bison and LLVM](https://gnuu.org/2009/09/18/writing-your-own-toy-compiler/)\n\n### Mailing lists\n-   [The llvm-dev Archives](https://lists.llvm.org/pipermail/llvm-dev/)\n\n## Resources\n- [How to Write a LLVM Backend](notes/how-to-write-a-llvm-backend.md)\n","lastmodified":"2022-07-02T12:03:24.356674337Z","tags":null},"/notes/minimum-spanning-subtree":{"title":"Minimum Spanning Subtree","content":"# Minimum Spanning Subtree\n---\nIt is a subtree with the minimum possible edge weight that connects all nodes together.\n\nThere must exist **no cycles** in the subtree.\n\nThe two most popular algorithms are [Kruskal's](notes/kruskals-algorithm.md) and [Pimm's](notes/pimms-algorithm.md).\n\nA graph **can** have multiple minimum spanning subtrees:\n![](content/images/minimum_spanning_subtree.png)\n\n## See also\n- [Trees](notes/trees.md)\n- [Graphs](notes/graphs.md)\n","lastmodified":"2022-07-02T12:03:24.356674337Z","tags":null},"/notes/newton-raphson":{"title":"Newton-Raphson Iteration","content":"# Newton-Raphson Iteration\n---\nWant to find the root of $f(x)$, for example a value for $x$ such that $f(x) = 0$.\n\nNewton-Raphson starts with an initial estimate, $x_0$, and computes a better estimate, $x_1$\n$x_1 = x_0 - \\dfrac {f(x_0)}{f'(x_0)}$\n\nFor example, to compute $\\dfrac {1}{b}$, we use:\n$f(x) = \\dfrac {1}{x} - b$\n        $=$ $x^{-1} - b$\n        \n$f'(x) = -x^{-2}$\n\nLeading to the formula:\n$x_1 = x_0 - \\dfrac {x_0^{-1} - b}{-x_0^{-2}}$\n     $=$ $2x_0 - bx_0^{2}$\n\n## Division\n$c = \\dfrac {a}{b}$\n\nCompute $r = \\dfrac {1}{b}$, then $c = r * a$\n\nAlgorithm:\n  - $r_0$ as guess for $\\dfrac {1}{b}$.\n  - $r_{i+1} = 2r_i = br_i^{2}$ (Newton-Raphson)\n\nSecond order convergent, so $O(log\\ r)$.\n\n---\n## See Also\n- [](notes/algorithms-and-data-structure.md#Mathematical%20Algorithms|Mathematical%20Algorithms)","lastmodified":"2022-07-02T12:03:24.356674337Z","tags":null},"/notes/obsidian-cheatsheet":{"title":"Obsidian Cheatsheet","content":"\n# Obsidian Cheatsheet\n\nWhere I dump all the useful Obsidian commands I'd hope to remember.\n\n[Here](https://morioh.netlify.app/) is the website and everything on how to run it [here](obsidian-website).\n\n## Essentials\n### Some basics\n\n_Make new note_ â€” `Cmd-n`\n_Create note in new pane_ â€” `Cmd-shift-n`\n_Open the link youâ€™re hovering over in a new pane (while in edit mode)_ â€” `Cmd-click`\n_Toggle edit/preview mode_ â€” `Cmd-e`\n_Open quick switcher_ â€” `Cmd-o`\n_Close active pane_ â€” `Cmd-w`\n_Go back_ â€” `Cmd-backspace`\n_Fold all_ â€” `Cmd-shift-.`\n_Unfold all_ â€” `Cmd-shift-,`\n\n### Formatting basics\n\n_Undo, cut, copy, paste, bold, italicise â€” `Cmd-z,x,c,v,b,i`\n\n---\n\n## Intermediate\n\n_Open command palette_ â€” `Cmd-p`\n_Search and replace in current file_ â€” `Cmd-f`\n_Search in all files_ â€” `Cmd-shift-f`\n_Split horizontally_ â€” `Cmd-d`\n_Split vertically_ â€” `Cmd-shift-d`\n_Save as PDF_ â€” `Cmd-shift-p`\n\n---\n## Advanced\n### Changing the view\n\n_Toggle left sidebar_ â€” I mapped this to: `Cmd-LeftArrow`\n_Toggle right sidebar_ â€” I mapped this to: `Cmd-RightArrow`\n\n### Setup and File Management\n\n_Open settings_ â€” `Cmd-,`\n\n### Very cool!\n\n_Multiple cursors_ â€” `option-click`\n\n---\n\n## Community Plugins\n\n- [Admonition Cheatsheet](notes/admonition-cheatsheet.md)\n- [Ozan's Image Editor](notes/ozans-image-editor.md)\n\n### Hotkeys++\n\n_Change list type_ â€” `Cmd-shift-m`\n_Toggle to-do list type_ â€” `Cmd-m`\n_Toggle to-do list_ â€” `Cmd-enter`\n\n### Advanced tables\n\n_Can use : on the left or right_ â€” makes it left or right aligned\n\n### Note Refactor\n\nThe default hotkeys are:\n\n| Hotkey                                                                   | Action                           |\n| ------------------------------------------------------------------------ | -------------------------------- |\n| \u003ckbd\u003eCmd\u003c/kbd\u003e + \u003ckbd\u003eShift\u003c/kbd\u003e + \u003ckbd\u003eN\u003c/kbd\u003e                    | **Extract selection to new note - first line as filename:** Copy selection into new note with the first line as the file name and replace with a link.                 |\n| \u003ckbd\u003eCmd\u003c/kbd\u003e + \u003ckbd\u003eShift\u003c/kbd\u003e + \u003ckbd\u003eC\u003c/kbd\u003e                    | **Extract selection to new note - content only:** Copy selection into new note, prompt for a file name and replace with a link.                 |\n\n```ad-warning\ntitle: Warning\n\nHotkey defaults are deliberately not set for note splitting commands to avoid unwanted accidents.\n```\n\nThe new note file is created at the root of the vault with the filename as the first line of the selected text and the content as the rest of the selected text.\n\nHeading characters (`#`) and other illegal characters for filenames are removed including `:`, `\\`, `/`.\n\n## Resources\nDataview [Wiki](https://blacksmithgu.github.io/obsidian-dataview/).","lastmodified":"2022-07-02T12:03:24.356674337Z","tags":null},"/notes/ozans-image-editor":{"title":"Ozan's Image Editor","content":"# Ozan's Image Editor\n---\nMore [here](https://github.com/ozntel/oz-image-in-editor-obsidian).\n\nTo embed a PDF:\n\n![](/goodnotes/linker-notes.pdf#page=2)","lastmodified":"2022-07-02T12:03:24.356674337Z","tags":null},"/notes/p-vs-np":{"title":"P vs NP Problem","content":"# P vs NP Problem\n---\nImagine an Oracle. Guesses and gets the right answer.\n\nBuild by (infinitely) many processors in a tree. If $2^n$ possible answers, tree is $n$ deep. A non-deterministic computer.\n\n- _P_ - the set of problems solvable in polynomial time.\n- _NP_ - the set of problems solvable in polynomial time on a non-deterministic computer.\n    - Alternatively, verifiable in polynomial time on a deterministic computer.\n- _NP hard_ - any problem at least as hard as the hardest problems in _NP_.\n- _NP complete_ - a set of _NP hard_ problems, all of which are equivalent.\n\n- $P$ $\\subseteq$ $NP$\n- $NP$ $\\neq$ $P$ has not been proven yet, but widely believed to be true.\n\n![](content/images/p-np.png)\n\n## See also\n- [Problems](notes/cs-problems.md)\n","lastmodified":"2022-07-02T12:03:24.356674337Z","tags":null},"/notes/parlab":{"title":"Parallel Computing Laboratory","content":"# Parallel Computing Laboratory\n---\nThe Par Lab was a five-year project to advance parallel computing funded by Microsoft and Intel for $10M over 5 years, from 2008 to 2013. It also received funding from several other companies and the State of California. \n\nProf. David Patterson was the Director.\n\nThe Chisel hardware construction language was used to design many RISC-V processors was also developed in the Par Lab.\n\nAll projects were **open source** using the Berkeley Software Distribution (BSD) license, including RISC-V and Chisel.\n\nThey never explicitly ask for RISC-V itself, their interest was in parallel processing systems.\n\nMore info: [The Berkeley Par Lab: Progress in the Parallel Computing Landscape](https://www.amazon.com/Berkeley-Par-Lab-Computing-Landscape-ebook/dp/B00EQM51I4?)\n","lastmodified":"2022-07-02T12:03:24.356674337Z","tags":null},"/notes/parse-trees":{"title":"Parse Trees","content":"# Parse Trees\n---\n![](content/images/parse-tree-example.png)\n\n## Grammatically \n$S \\rightarrow A | B$\n\n$A \\rightarrow A\\ x | y$\n\n$B \\rightarrow z$\n\n- Parse tree for *yxxz*:\n\n![](content/images/parse-tree.png)\n\n### Parsing Sentences\nApply successive productions.\n\nConsider parsing the sentence **yz** using this grammar:\n\nS $\\rightarrow$ AB\nA $\\rightarrow$ A x|y\nB $\\rightarrow$ z\n\nWe use three productions:\n\nS $\\rightarrow$ AB  (giving sentential form AB)\nA $\\rightarrow$ y  (giving sentential form yB)\nB $\\rightarrow$ z  (giving the sentence yz)\n\nThis is a **leftmost derivation**.\n\nWe could instead have used:\n\nS $\\rightarrow$ AB (giving the sentential form AB)\nB $\\rightarrow$ z (giving the sentential form Az)\nA $\\rightarrow$ y (giving the sentential form yz)\n\nThis is a **rightmost derivation**.\n\nWhilst the resulting parse tree is the same, the order of the the derivation governs the order in which the language structures appear in the parse tree as it is built.\n\n## C Representation\n```c\nstruct node {\n  int nodetype;\n  struct node *field1;\n  struct node *field2;\n  struct node *field3;\n  struct node *field4;\n  struct node *field5;\n}\n```\n\n- `nodetype` can be defined as small constants:\n```c\n#define NT_PROGRAM 1\n#define NT_FUNCTION_LIST 2\n#define NT_FUNCTION 3\n...\n```\n\n### Simplification\nNo need for a **program** node, use `function_list`.\n\nAvoid lexical detail, for example:\n\ninteger $\\rightarrow$ digit | integer digit\ndigit      $\\rightarrow$ 0 | 1 | ... | 8 | 9\n\nJust add a appropriate fields to `struct` node:\n```c\nstruct nnode {\n  int nodetype;\n  struct node *field1;\n  ...\n  struct node *field5;\n  char *name; // variables and text\n  int value;  // integer constants\n}\n```\n\n## DAGs for Parse Trees\nA DAG (Directed Acyclic Graph) can allow us to share common parse tree structures. It saves space and identifies possible common sub-expressions for optimisation.\n\nHowever, they are hard to construct and syntactic identify does not mean semantic identity.\n\n## See Also\n- [Formal Languages](notes/formal-languages.md)\n- [Trees](notes/trees.md)\n","lastmodified":"2022-07-02T12:03:24.356674337Z","tags":null},"/notes/pimms-algorithm":{"title":"Pimm's Algorithm","content":"# Pimm's Algorithm\n---\nIt is a [minimum spanning subtree](notes/minimum-spanning-subtree.md) algorithm.\n\nIt scales well, fast with dense [graphs](notes/graphs.md).\n\nIt has a [](notes/compiler-optimisation.md#Performance|performance) of $O_{E\\ log\\ N}$ with [binary heap](notes/binary-heap.md) and $O_{E\\ +\\ log\\ N}$ with Fibonacci heap.\n\nIt works like this:\n1. Choose any node.\n2. Choose nearest node that is not included in the spanning subtree formed so far.\n3. Repeat step 2 until all nodes are included in the subtree.\n\n![](content/images/prims.png)\n\n## See also\n- [Minimum Spanning Subtree](notes/minimum-spanning-subtree.md)\n- [Trees](notes/trees.md)\n- [Graphs](notes/graphs.md)\n- [Big O Notation](notes/big-o-notation.md)\n- [Kruskal's](notes/kruskals-algorithm.md)\n","lastmodified":"2022-07-02T12:03:24.356674337Z","tags":null},"/notes/quicksort":{"title":"Quicksort","content":"# Quicksort\n---\nIt picks a **midpoint** (approximate the median) and partition values, into those less than the **midpoint** (left) and greater (right).\n\nThen recurse on each partition in turn until there is one value in each partition.\n\n```c\nvoid\nquicksort (int *a, int lo, int hi)\n{\n  if (lo \u003c hi)\n  {\n    int p = partition (a, lo, hi);\n    quicksort (a, lo, p);\n    quicksort (a, p + 1, hi);\n  }\n}\n```\n\n## Issues\n- It is not [](notes/sorting.md#Stability|stable).\n- Average [](notes/compiler-optimisation.md#Performance|performance): $O_{n\\ log\\ n}$ \n- Worst case performance: $O_(n^2)$\n\nNote that this is [big O notation](notes/big-o-notation.md).\n\nQuicksort is critically dependant on choice of median. Taking best of low, high and mid points deals with the obvious case of sorted data.\n\nIt is implemented as **qsort** in the standard C maths library.\n\n## Quicksort Partition\n```c\nint\npartition (int *a, int lo, int hi)\n{\n  int pivot = a[lo];            /* Guess median */\n  int i = lo - 1, j = hi + 1;\n\n  while (1)\n  {\n    do                          /* Leftmost element \u003e= pivot */\n      i++;\n    while (a[i] \u003c pivot);\n    do                          /* Rightmost element \u003c= pivot */\n      j--;\n    while(a[j] \u003e pivot);\n    if (i \u003e= j)\n      return j;\n    swap (\u0026(a[i]), \u0026(a[j]));\n  }\n}\n```\n\n### Output\n```bash\n16 16  0 14  9 11 10  2  3  4  1 11  8 17 14  5 11 12 15 16\n16 16  0 14  9 11 10  2  3  4  1 11  8 17 14  5 11 12 15 16\n16 15  0 14  9 11 10  2  3  4  1 11  8 17 14  5 11 12 16 16\n16 15  0 14  9 11 10  2  3  4  1 11  8 12 14  5 11 17 16 16\n11 15  0 14  9 11 10  2  3  4  1 11  8 12 14  5 16 17 16 16\n 5 15  0 14  9 11 10  2  3  4  1 11  8 12 14 11 16 17 16 16\n 5  8  0 14  9 11 10  2  3  4  1 11 15 12 14 11 16 17 16 16\n 5  8  0 11  9 11 10  2  3  4  1 14 15 12 14 11 16 17 16 16\n 5  8  0 11  9  1 10  2  3  4 11 14 15 12 14 11 16 17 16 16\n 4  8  0 11  9  1 10  2  3  5 11 14 15 12 14 11 16 17 16 16\n 4  3  0 11  9  1 10  2  8  5 11 14 15 12 14 11 16 17 16 16\n 4  3  0  2  9  1 10 11  8  5 11 14 15 12 14 11 16 17 16 16\n 4  3  0  2  1  9 10 11  8  5 11 14 15 12 14 11 16 17 16 16\n 1  3  0  2  4  9 10 11  8  5 11 14 15 12 14 11 16 17 16 16\n 0  3  1  2  4  9 10 11  8  5 11 14 15 12 14 11 16 17 16 16\n 0  2  1  3  4  9 10 11  8  5 11 14 15 12 14 11 16 17 16 16\n 0  1  2  3  4  9 10 11  8  5 11 14 15 12 14 11 16 17 16 16\n 0  1  2  3  4  5 10 11  8  9 11 14 15 12 14 11 16 17 16 16\n 0  1  2  3  4  5  8 11 10  9 11 14 15 12 14 11 16 17 16 16\n 0  1  2  3  4  5  8  9 10 11 11 14 15 12 14 11 16 17 16 16\n 0  1  2  3  4  5  8  9 10 11 11 14 15 12 14 11 16 17 16 16\n 0  1  2  3  4  5  8  9 10 11 11 11 15 12 14 14 16 17 16 16\n 0  1  2  3  4  5  8  9 10 11 11 11 14 12 15 14 16 17 16 16\n 0  1  2  3  4  5  8  9 10 11 11 11 12 14 15 14 16 17 16 16\n 0  1  2  3  4  5  8  9 10 11 11 11 12 14 14 15 16 17 16 16\n 0  1  2  3  4  5  8  9 10 11 11 11 12 14 14 15 16 16 16 17\n 0  1  2  3  4  5  8  9 10 11 11 11 12 14 14 15 16 16 16 17\n```\n\n### As a tree-sort\n![](content/images/quicksort-tree.png)\n\n## Code Example\n```c\n/* Basic Quicksort\n\n   Copyright (C) 2020 Embecosm Limited \u003cwww.embecosm.com\u003e\n   Contributor: Jeremy Bennett \u003cjeremy.bennett@embecosm.com\u003e\n   SPDX-License-Identifier: GPL-3.0-or-later */\n\n/* This version uses Tony Hoare's original algorithm as described in Comp. J,\n * 5(1), April 1962, pp 10-15. */\n\n#include \u003cstdlib.h\u003e\n#include \u003cstdio.h\u003e\n\n#ifndef N\n#define N 20\n#endif\n\nvoid\npopulate (int arr[])\n{\n  for (int i = 0; i \u003c N; i++)\n    arr[i] = rand () % N;\n}\n\nvoid\nswap (int *a, int *b)\n{\n  int t = *a;\n  *a = *b;\n  *b = t;\n}\n\nvoid\ndump_array (int arr[])\n{\n  for (int i = 0; i \u003c N; i++)\n    printf (\"%2d \", arr[i]);\n\n  printf (\"\\n\");\n}\n\nint median (int x, int y, int z)\n{\n  int b[] = {x, y, z};\n  int j, k;\n\n  for (k = 1; k \u003c 3; k++)\n    for (j = k; (j \u003e 0) \u0026\u0026 (b[j] \u003c b[j - 1]); j--)\n      swap (\u0026(b[j]), \u0026(b[j - 1]));\n\n  return b[1];\n}\n\n/* Partition data around pivot, returning the index of the pivot as result */\nint\npartition (int *a, int lo, int hi)\n{\n#ifdef MEDIAN\n  int pivot = median (a[lo], a[hi], a[(lo + hi) / 2]);\n#else\n  int pivot = a[lo];\n#endif\n  int i = lo - 1;\t\t/* Don't worry gets incremented before use! */\n  int j = hi + 1;\t\t/* Don't worry gets decremented before use! */\n\n  while (1)\n    {\n      do\t\t\t/* Leftmost element \u003e= pivot */\n\ti++;\n      while (a[i] \u003c pivot);\n\n      do\t\t\t/* Rightmost element \u003c= pivot */\n\tj--;\n      while (a[j] \u003e pivot);\n\n      if (i \u003e= j)\t\t/* Two pointers have met */\n\treturn j;\n\n      swap (\u0026(a[i]), \u0026(a[j]));\n      dump_array (a);\n    }\n}\n\n/* Find a pivot, partition around that pivot, recurse on each partition */\nvoid\nquicksort (int *a, int lo, int hi)\n{\n  if (lo \u003c hi)\n    {\n      int p = partition (a, lo, hi);\n      quicksort (a, lo, p);\n      quicksort (a, p + 1, hi);\n    }\n}\n\nint\nmain ()\n{\n  int a[N];\n  int i, j, k, m;\n\n  srand (561U);\n\n  populate (a);\n  dump_array (a);\n\n  quicksort (a, 0, N - 1);\n\n  return 0;\n}\n\n/*\nLocal Variables:\nmode: C\nc-file-style: \"gnu\"\nEnd:\n*/\n```\n","lastmodified":"2022-07-02T12:03:24.356674337Z","tags":null},"/notes/relocations":{"title":"Relocations","content":"# Relocations\n---\n## What is a relocation?\nThey are very common in position-dependant code and implemented at link time.\n\nBefore linking, an instruction might need a label which gets assigned\na temporary symbolic reference. Then during the link stage, the label might be\nmoved (once optimised). Once the actual address is found, the symbol gets\nreplaced by the relocated address label.\n\nThe [howto table](notes/howto-table.md) stores a list of pointers to the absolute address called\n[fixups](notes/fixups.md), which are changed when the code gets relocated.\n\n* Overflow = [fixup](notes/fixups.md) crossed boundary.\n\n## Useful Commands\nTo separate the linker from the compiler:\n\n```bash\nriscv32-unknown-elf-as -march=rv32imc_xcorevhwlp1p0 -o file.o file.s\nriscv32-unknown-elf-gcc -march=rv32imc -Os -c file0.c\nriscv32-unknown-elf-gcc -o file file0.o file.o\n```\n\nNote: `-c` stops before link time.\n\n## Adding a New Relocation\n### Testing\nThe `ld` testsuite contains the linker tests, the tests for the relocations. They will look similar to `gas` tests.\n\n### Changed files (for CORE-V)\n* `bfd/elfxx-riscv.c`: Describe the relocation in the [howto table](notes/howto-table.md). Define ENCODE_ITYPE_IMM mask.\n* `include/elf/riscv.h`: Add the relocation number.\n* `bfd/bfd-in2.h`: Regenerate.\n* `bfd/elfnn-riscv.c: Add relocation mask (eg ENCODE_ITYPE_IMM for 12 bit immediate).\n* `bfd/reloc.c`: Add relocation BFD name.","lastmodified":"2022-07-02T12:03:24.356674337Z","tags":null},"/notes/riscv":{"title":"RISC-V","content":"# RISC-V\n---\n- [Introduction to RISC-V](notes/introduction-to-riscv.md)","lastmodified":"2022-07-02T12:03:24.356674337Z","tags":null},"/notes/riscv-toolchain":{"title":"RISC-V Toolchain","content":"# RISC-V Toolchain\n---\nThere are two RISC-V toolchains that are popularly used:\n\n1.  The GNU RISC-V toolchain\n2.  The LLVM RISC-V toolchain\n\nBothÂ toolchains provide a state-of-the-art optimising [compiler](notes/compilers.md), assembler, linker, and various other tools to build applications that run on RISC-V machines.\n\n## Where to download the toolchains and simulator\nThe officialÂ [RISC-V GitHub repository](https://github.com/riscv-collab/riscv-gcc) provides the source code for the `riscv-gnu` toolchain, and the prebuilt toolchain can be downloaded from [here](https://github.com/riscv-software-src/riscv-gnu-toolchain). \n\nThe RISC-V compiler is generally used as a cross-compiler, as many RISC-V processors are used for low-power embedded applications. Currently, the RISC-V cross-compilers can only be run onÂ [ELF targets](https://en.wikipedia.org/wiki/Comparison_of_executable_file_formats) like Linux machines.\n\nThe RISC-V LLVM toolchain is not readily available from third-party providers, but one can build it from source by downloading the open source [llvm-project](https://github.com/llvm/llvm-project). We describe an easy way to use the llvm toolchain with gnu sysroot.\n\nThe RISC-V simulator can be downloaded from the official RISC-V GitHub repository: [riscv/riscv-isa-sim: Spike, a RISC-V ISA Simulator](https://github.com/riscv/riscv-isa-sim). Although RISC-V boards are readily available from several vendors, using simulators is an easy way to get started with RISC-V development.\n\n## Building Application with the Toolchain\nIn order to build a RISC-V application, using a [cross-compiler](notes/cross-compilation.md) toolchain is the same as any other cross-compiler-based development system. Two things are required:\n\n-   The [compiler toolchain](notes/compiler-toolchains.md)\n-   [sysroot](notes/sysroot.md)\n\nWe have described the compiler toolchain and sysroot in the first chapter. Before learning how to build applications with the RISC-V toolchain, weâ€™d like to introduce an interesting naming convention that has been used for cross-compilers.\n\n### Compiler Naming Convention\nWhen you download the GCC toolchain, you'll find a `riscv64-unknown-elf-gcc` binary in the `bin` directory. This is the same GCC [compiler](notes/compilers.md) with inbuilt information of sysroot and platform. It is a convention to name [cross-compilers](notes/cross-compilation.md) that way. \n\nThe naming is typicallyÂ using the `arch-vendor-os-abi` format. So, `riscv64-unknown-elf-gcc`Â means that this is a [cross-compiler](notes/cross-compilation.md) for RISC-V 64 bit, and tit will generate an `elf` binary,Â which can run on Linux machines for example. An excellent reference on naming convention can be found [here](http://web.eecs.umich.edu/~prabal/teaching/eecs373-f12/notes/notes-toolchain.pdf). In cases where a compiler's name doesn't have the target triplet, the `-dumpmachine` flag can be used to get that:\n\n```bash\n$ gcc -dumpmachine \nx86_64-linux-gnu\n```\n\nWith the `riscv64-unknown-elf-gcc` compiler handy, a file can then be compiled in the following ways:\n\n```bash\n$ riscv64-unknown-elf-gcc -O2 -o a.out hello.c\n$ riscv64-unknown-elf-gcc -O2 hello.c -mabi=lp64d -march=rv64ifd\n```\n\nThe `-march` flag is used to specify the target sub-architecture for which the assembly will be generated. The `-mabi` flag is used to specify data models. For more details on data models, refer toÂ [this](https://en.wikipedia.org/wiki/64-bit_computing#64-bit_data_models) section of 64-bit computing in Wikipedia.\n\nWith the [llvm toolchain](notes/llvm.md), the binary can be built similarly. Assuming [sysroot](notes/sysroot.md) is in the `riscv64-unknown-elf` directory:\n\n```bash\n$ clang test.c -c --sysroot riscv64-unknown-elf -target  \nriscv64-unknown-elf -march=rv64ifd\n```\n\nRISC-V applications can be launched on a device, a simulator, or an emulator.\n\n## Running the Applications on Spike Simulator\nOne of the most convenient ways to run small applications is to use the RISC-V simulator. The build and installation steps are fairly straightforward. For this, you need the following dependencies:\n\n1.  A Linux machine - building a Linux image on non-Linux machines is non-trivial, so it is recommended you have a Linux machine to begin with.\n2.  RISC-V toolchain:Â [https://github.com/riscv-software-src](https://courses.edx.org/xblock/One of the most convenient ways to run small applications is to use the RISC-V simulator. The build and installation steps are fairly straightforward. For this you need the following dependencies: A Linux machine. Building a Linux image on non-Linux machines is non-trivial so it is recommended you have a Linux machine to begin with. RISC-V toolchain (https://github.com/riscv-software-src) RISC-V simulator spike (https://github.com/riscv-software-src/riscv-isa-sim) RISC-V proxy kernel pk (https://github.com/riscv-software-src/riscv-pk)  The instructions to run a simple hello world app on the spike simulator is mentioned in their github README. To install the proxy kernel follow the instructions on their github README. For convenience, you can install both spike and pk in the same directory as the riscv64 toolchain directory by providing the path to toolchain directory as install prefix for both.)\n3.  RISC-V simulator spike:Â [https://github.com/riscv-software-src/riscv-isa-sim](https://github.com/riscv-software-src/riscv-isa-sim)\n4.  RISC-V proxy kernel pk:Â [https://github.com/riscv-software-src/riscv-pk](https://github.com/riscv-software-src/riscv-pk)\n\nThe instructions to run a simple `hello-world` app on the Spike simulator are mentioned in their GitHub [README](https://github.com/riscv/riscv-isa-sim#compiling-and-running-a-simple-c-program). To install the proxy kernel, follow the instructions on their GitHub [README](https://github.com/riscv-software-src/riscv-pk). For convenience, you can install both `spike` and `pk` in the same directory as the `riscv64` toolchain directory by providing the path to the toolchain directory as install `prefix` for both.\n\n## Running Applications on an Emulator\nRunning a RISC-V application on an emulator gives you more flexibility, but the installation steps are more involved. In order to run a RISC-V application on an emulator, you need to have the following dependencies:\n\n1.  A Linux machine - building a Linux image on non-Linux machines is non-trivial, so it is recommended you have a Linux machine to begin with.\n2.  RISC-V toolchain:Â [https://github.com/riscv-software-src](https://courses.edx.org/xblock/Running an RISC-V application on an emulator gives you more flexibility but the installation steps are more involved. In order to run a RISC-V application on an emulator you need to have the following dependencies. A Linux machine. Building a Linux image on non-Linux machines is non-trivial so it is recommended you have a Linux machine to begin with. RISC-V toolchain (https://github.com/riscv-software-src) QEMU (git clone --depth 1 --branch v5.0.0 https://github.com/qemu/qemu) Linux (git clone --depth 1 --branch v5.4 https://github.com/torvalds/linux) Busybox (git clone --depth 1 git://git.busybox.net/busybox)  The branches listed above are suggested versions and that may change frequently. You can choose other branches as well. The documentation above may become stale if any of the dependencies have breaking changes. Check https://risc-v-getting-started-guide.readthedocs.io/en/latest/linux-qemu.html to see the latest supported versions. If this documentation does not work, be sure to ask in the linux-riscv mailing list.  Build QEMU with the RISC-V target: cd qemu ./configure --target-list=riscv64-softmmu --prefix=/path/to/keep/qemu make -j $(nproc) make install  Build Linux for the RISC-V target: cd linux make ARCH=riscv CROSS_COMPILE=riscv64-unknown-linux-gnu- defconfig make ARCH=riscv CROSS_COMPILE=riscv64-unknown-linux-gnu- -j $(nproc)  Make sure to have the prefix of the cross compiler match from your toolchain. In the above example the gcc compiler is riscv64-unknown-linux-gnu-gcc so the CROSS_COMPILE flag is riscv64-unknown-linux-gnu-  Build the busybox  cd busybox CROSS_COMPILE=riscv64-unknown-linux-gnu- make defconfig CROSS_COMPILE=riscv64-unknown-linux-gnu- make -j $(nproc)  To run linux image on QEMU run sudo /path/to/keep/qemu/bin/qemu-system-riscv64 -nographic -machine virt /      -kernel /path/to/linux/image -append \"root=/dev/vda ro console=ttyS0\" /      -drive file=busybox,format=raw,id=hd0 /      -device virtio-blk-device,drive=hd0  You can also run bare metal app on QEMU like this /path/to/keep/qemu/bin/qemu-system-riscv64 -nographic -machine virt -kernel /path/to/binary -bios none  For additional QEMU configurations for RISC-V, checkout the official documentation. In addition to simulators and emulators, RISC-V applications can be run on virtual machines as well as commercially available development boards. Additional documentation to debug bare metal issues can be found here. You can install the RISC-V virtual machine as documented here.)\n3.  QEMU:Â `git clone --depth 1 --branch v5.0.0 https://github.com/qemu/qemu`\n4.  Linux: `git clone --depth 1 --branch v5.4 https://github.com/torvalds/linux`\n5.  Busybox: `git clone --depth 1 git://git.busybox.net/busybox`\n\nThe branches listed above are suggested versions and that may change frequently. You can choose other branches as well. The documentation above may become stale if any of the dependencies have breaking changes. Check theÂ [Running 64- and 32-bit RISC-V Linux on QEMU documentation page](https://risc-v-getting-started-guide.readthedocs.io/en/latest/linux-qemu.html) to see the latest supported versions. If this documentation does not work, be sure to ask in theÂ [linux-riscv](http://lists.infradead.org/pipermail/linux-riscv/) mailing list.\n\n### Build QEMU with the RISC-V target:\n\n```bash\ncd qemu  \n./configure --target-list=riscv64-softmmu --prefix=/path/to/keep/qemu  \nmake -j $(nproc)  \nmake install\n```\n\n### Build Linux for the RISC-V target:\n\n```bash\ncd linux\nmake ARCH=riscv CROSS_COMPILE=riscv64-unknown-linux-gnu- defconfig \nmake ARCH=riscv CROSS_COMPILE=riscv64-unknown-linux-gnu- -j $(nproc)\n```\n\nMake sure to have the prefix of the [cross-compiler](notes/cross-compilation.md) match from your toolchain. In the above example, the GCC [compiler](notes/compilers.md) is `riscv64-unknown-linux-gnu-gcc` so the `CROSS_COMPILE` flag is `riscv64-unknown-linux-gnu-`\n\n### Build the busybox:\n\n```bash\ncd busybox\nCROSS_COMPILE=riscv64-unknown-linux-gnu- make defconfig \nCROSS_COMPILE=riscv64-unknown-linux-gnu- make -j $(nproc)\n```\n\n### To run the Linux image on QEMU, do:\n\n```bash\nsudo /path/to/keep/qemu/bin/qemu-system-riscv64 -nographic -machin  \nvirt   \nÂ  Â  Â -kernel /path/to/linux/image -append \"root=/dev/vda ro  \nconsole=ttyS0\" \\  \nÂ  Â  Â -drive file=busybox,format=raw,id=hd0 \\  \nÂ  Â  Â -device virtio-blk-device,drive=hd0\n```\n\n### You can also run the bare metal app on QEMU like this:\n\n```\n/path/to/keep/qemu/bin/qemu-system-riscv64 -nographic -machine virt  \n-kernel /path/to/binary -bios none\n```\n\nFor additional QEMU configurations for RISC-V, check out theÂ [official documentation](https://wiki.qemu.org/Documentation/Platforms/RISCV). In addition to simulators and emulators, RISC-V applications can be run on virtual machines, as well as commercially available development boards. \n\nAdditional documentation to debug bare metal issues can be found [here](https://embeddedinn.xyz/articles/tutorial/Adding-a-custom-peripheral-to-QEMU/). You can install the RISC-V virtual machine as documented [here](https://wiki.debian.org/RISC-V).\n\n## References\n-   [Tech: Toolchain \u0026 Runtime Subcommittee mailing list](mailto:tech-toolchain-runtime@lists.riscv.org)\n-   [GCC Cross-Compiler](https://wiki.osdev.org/GCC_Cross-Compiler)\n-   [64-bit data models](https://en.wikipedia.org/wiki/64-bit_computing#64-bit_data_models)\n-   [The linux-riscv Archives](https://en.wikipedia.org/wiki/64-bit_computing#64-bit_data_models)\n-   [Running 64- and 32-bit RISC-V Linux on QEMU](https://risc-v-getting-started-guide.readthedocs.io/en/latest/linux-qemu.html)\n-   [Qemu: Documentation/Platforms/RISCV](https://wiki.qemu.org/Documentation/Platforms/RISCV)\n-   [Debian - RISC-V Wiki](https://wiki.debian.org/RISC-V)\n\n### RISC-V Boards: \nTheÂ [RISC-V Exchange](https://riscv.org/exchange/) page is a collection of available physical hardware in the RISC-V ecosystem. This list is curated by the community.\n\n### RISC-V Cores:Â   \nTheÂ [RISC-V Exchange: Cores \u0026 SoCs](https://riscv.org/exchange/cores-socs/) page is a collection of available intellectual property (IP) cores and SoCs in the RISC-V ecosystem.\n\n### Toolchain and other hardware bringup software providers:\n-   [RISC-V Software Collaboration](https://github.com/riscv-collab)\n-   [sifive/freedom-tools](https://github.com/sifive/freedom-tools/releases)\n-   [lowRISC](https://github.com/lowRISC)\n-   [stnolting/riscv-gcc-prebuilt](https://github.com/stnolting/riscv-gcc-prebuilt)\n-   [SiFive/Software](https://www.sifive.com/software)","lastmodified":"2022-07-02T12:03:24.356674337Z","tags":null},"/notes/sets-and-maps":{"title":"Sets and Maps","content":"# Sets and Maps\n---\n**Sets** are a collection of objects:\n  - They might be ordered or unordered.\n  - Two variants:\n      1. Single instance of any object.\n      2. Multiple instances.\n\n**Maps** associate a *value* or *values* with a *key*:\n  - They might be ordered or unordered.\n  - Two variants:\n      1. Single value per key.\n      2. Multiple values per key.\n\nExample:\n```c\n#include \u003cmap\u003e\n\nstd::map\u003csize_t, std::string\u003e map;\n\nmap[0] = \"Hello\";\nmap[1] = \"you\";\nmap[2] = \"there!\";\n```\n\nExample in C++:\n```cpp\n#include \u003cmap\u003e\n#include \u003cstring\u003e\nusing namespace std;\n\nint main() {\n  map\u003cint, string\u003e sample_map;\n  sample_map.insert(pair\u003cint, string\u003e(1, \"one\"));\n  sample_map.insert(pair\u003cint, string\u003e(2, \"two\"));\n\n  cout \u003c\u003c sample_map[1] \u003c\u003c \" \" \u003c\u003c sample_map[2] \u003c\u003c endl;\n}\n```\n\nAnother example but needs C++11:\n```cpp\n#include \u003ciostream\u003e\n#include \u003cmap\u003e\n#include \u003cstring\u003e\nusing namespace std;\n\nint main() {\n  map\u003cint, string\u003e sample_map { { 1, \"one\"}, { 2, \"two\" } };\n\n  cout \u003c\u003c sample_map[1] \u003c\u003c \" \" \u003c\u003c sample_map[2] \u003c\u003c endl;\n}\n```\n```ad-note\nC++ has great built-in support for these, C does not.\n```\n\n---\n### Resources\n[C++ Maps Explained](https://www.udacity.com/blog/2020/03/c-maps-explained.html)","lastmodified":"2022-07-02T12:03:24.356674337Z","tags":null},"/notes/shell-sort":{"title":"Shell Sort","content":"# Shell Sort\n---\nShell sort adds one more loop outside [bubble sort](notes/bubble-sort.md).\n\nIt starts by sorting small overlapping subsets, then makes then smaller but by then the array is mostly sorted.\n\nIt is an **unstable** sort.\n\n## Shell Sort in C\n```c\nm = N;\n\ndo {\n  m = (m + 2) / 3;\n\n  for (i = 0; i \u003c m; i++) \n    for (k = i + m; k \u003c N; k += m) \n      for (j = k; (j \u003e 0) \u0026\u0026 (a[j] \u003c a[j - m]); j -= m) {\n        swap (\u0026(a[j]), \u0026(a[j - m])); \n        dump_array(a);     \n      }\n  }\nwhile (m != 1);\n```\n\n### Output:\n```bash\n16 16 0 14 9 11 10 2 3 4 1 11 8 17 14 5 11 12 15 16\n2 16 0 14 9 11 10 16 3 4 1 11 8 17 14 5 11 12 15 16\n2 16 0 14 9 11 10 14 3 4 1 11 8 17 16 5 11 12 15 16\n2 3 0 14 9 11 10 14 16 4 1 11 8 17 16 5 11 12 15 16\n2 3 0 14 9 11 10 14 5 4 1 11 8 17 16 16 11 12 15 16\n2 3 0 1 9 11 10 14 5 4 14 11 8 17 16 16 11 12 15 16\n2 3 0 1 9 11 10 14 5 4 12 11 8 17 16 16 11 14 15 16\n2 3 0 1 9 8 10 14 5 4 12 11 11 17 16 16 11 14 15 16\n1 3 0 2 9 8 10 14 5 4 12 11 11 17 16 16 11 14 15 16\n1 3 0 2 9 8 4 14 5 10 12 11 11 17 16 16 11 14 15 16\n1 3 0 2 9 8 4 14 5 10 12 11 11 17 16 15 11 14 16 16\n1 3 0 2 9 8 4 12 5 10 14 11 11 17 16 15 11 14 16 16\n1 3 0 2 9 8 4 12 5 10 14 11 11 11 16 15 17 14 16 16\n1 3 0 2 9 8 4 12 5 10 11 11 11 14 16 15 17 14 16 16\n1 3 0 2 9 8 4 11 5 10 12 11 11 14 16 15 17 14 16 16\n1 3 0 2 9 8 4 11 5 10 12 11 11 14 16 15 16 14 16 17\n1 3 0 2 9 5 4 11 8 10 12 11 11 14 16 15 16 14 16 17\n1 3 0 2 9 5 4 11 8 10 12 11 11 14 14 15 16 16 16 17\n1 0 3 2 9 5 4 11 8 10 12 11 11 14 14 15 16 16 16 17\n0 1 3 2 9 5 4 11 8 10 12 11 11 14 14 15 16 16 16 17\n0 1 2 3 9 5 4 11 8 10 12 11 11 14 14 15 16 16 16 17\n0 1 2 3 5 9 4 11 8 10 12 11 11 14 14 15 16 16 16 17\n0 1 2 3 5 4 9 11 8 10 12 11 11 14 14 15 16 16 16 17\n0 1 2 3 4 5 9 11 8 10 12 11 11 14 14 15 16 16 16 17\n0 1 2 3 4 5 9 8 11 10 12 11 11 14 14 15 16 16 16 17\n0 1 2 3 4 5 8 9 11 10 12 11 11 14 14 15 16 16 16 17\n0 1 2 3 4 5 8 9 10 11 12 11 11 14 14 15 16 16 16 17\n0 1 2 3 4 5 8 9 10 11 11 12 11 14 14 15 16 16 16 17\n0 1 2 3 4 5 8 9 10 11 11 11 12 14 14 15 16 16 16 17\n```\n\n## Code Example\n```c\n/* Basic Shell's sort\n\n   Copyright (C) 2020 Embecosm Limited \u003cwww.embecosm.com\u003e\n   Contributor: Jeremy Bennett \u003cjeremy.bennett@embecosm.com\u003e\n   SPDX-License-Identifier: GPL-3.0-or-later */\n\n#include \u003cstdlib.h\u003e\n#include \u003cstdio.h\u003e\n\n#ifndef N\n#define N 20\n#endif\n\nvoid\npopulate (int arr[])\n{\n  for (int i = 0; i \u003c N; i++)\n    arr[i] = rand () % N;\n}\n\nvoid\nswap (int *a, int *b)\n{\n  int t = *a;\n  *a = *b;\n  *b = t;\n}\n\nvoid\ndump_array (int arr[])\n{\n  for (int i = 0; i \u003c N; i++)\n    printf (\"%d \", arr[i]);\n\n  printf (\"\\n\");\n}\n\nint\nmain ()\n{\n  int a[N];\n  int i, j, k, m;\n\n  srand (561U);\n\n  populate (a);\n  dump_array (a);\n\n  m = N;\n\n  do\n    {\n      m = (m + 2) / 3;\n\n      for (i = 0; i \u003c m; i++)\n\tfor (k = i + m; k \u003c N; k += m)\n\t  for (j = k; (j \u003e i) \u0026\u0026 (a[j] \u003c a[j - m]); j -= m)\n\t    {\n\t      swap (\u0026(a[j]), \u0026(a[j - m]));\n\t      dump_array (a);\n\t    }\n    }\n  while (m != 1);\n\n  return 0;\n}\n\n/*\nLocal Variables:\nmode: C\nc-file-style: \"gnu\"\nEnd:\n*/\n```\n","lastmodified":"2022-07-02T12:03:24.356674337Z","tags":null},"/notes/sorting":{"title":"Sorting","content":"# Sorting\n---\n## Sorting methods\n- [Bubble Sort](notes/bubble-sort.md)\n- [Shell Sort](notes/shell-sort.md)\n- [Quicksort](notes/quicksort.md)\n- [Heapsort](notes/heapsort.md)\n- [Bucket Sort](notes/bucket-sort.md)\n\n## Stability\nA **stable** sort guarantee to preserve the ordering from a first sort, where the second sort finds the records to be equal.\n\nAn **unstable** sort does not make this guarantee.\n\n### Examples\n- Stable methods:\n    - Merge sort and variants.\n    - Variants of [bubble sort](notes/bubble-sort.md).\n    - Insertion sort and variants.\n    - Variants on [bucket sort](notes/bucket-sort.md).\n        - Counting sort and variants.\n    - Timsort (merge/insertion variant, Python).\n\n**Unstable methods can all be made stable**.\n\n- Add second level of comparison for equal keys.","lastmodified":"2022-07-02T12:03:24.356674337Z","tags":null},"/notes/source-code-optimisation":{"title":"Source Code Optimisation","content":"# Source Code Optimisation\n---\nIn addition to [compiler](notes/compilers.md) optimisations, there are several software engineering techniques to reduce code size. These techniques take advantage of well-known software engineering methodologies and programming language features.\n\n## Code Refactoring\nMoving function definitions to the `.c/.cpp` file. When function definitions are put in header files, they get duplicated in every translation unit that includes the header file. Even though only one definition remains in the end (thanks to ODR), these functions may have been inlined in their callers and that extra code size will persist in the binary. So, it is a good idea to put function definitions in `.c/.cpp` files.\n\nIn addition to functions that were written by developers, there are [compiler](notes/compilers.md)-generated functions like constructors, destructors, operator overloads, etc. Even these functions can contribute to code size depending on the structure of the type and language rules. So, programmers can explicitly instantiate these methods in the `.cpp` file. One can either do a â€˜defaultâ€™ instantiation or an explicit instantiation. For example:\n\nInÂ `test.h`, the class is declared\n\n```cpp\nclass A {  \nÂ  A(); \nÂ  A(A const\u0026);\nÂ  ~A();\n};\n```\n\nIn `test.cpp`, the definitions are instantiated:\n\n```cpp\nA::A() = default;  \nA(A const\u0026) = default;  \nA::~A() = default;\n```\n\nSimilar to how function definitions in header files contribute to code size, template functions do the same. It is however a non-trivial amount of work to reduce their overhead. It is often the case that some types are used more often than others. For the commonly used types, we can explicitly instantiate them in a `.cpp` file. For example:\n\nIn the `test.h` file, the template is defined:\n\n```cpp\ntemplate\u003cclass T\u003e  \nstructÂ  a {  \nvoid f(T t) { /* */ }  \n};\n```\n\nIn the `test.cpp` file, the template is explicitly instantiated:\n\n```cpp\ntemplate struct A\u003cint\u003e;\n```\n\nExplicit instantiations also save compile time as the instantiation happens once. For more ideas on source code optimisations, you can watch Aditya Kumar's presentation at the RISC-V Global Forum 2020: [_\"Code Size Compiler Optimisations and Techniques for Embedded Systems\"_](https://www.youtube.com/watch?v=6IuDWfuMEno).\n\n## Function Attributes\n\nFunction attributes that reduce inline potential can help reduce code size. For example:\n\n- `__attribute__((cold))`\n- `__attribute__((noinline))`\n\nNote that in some cases, inlining may reduce the code size. Especially, with tiny functions, inlining removes the function call overhead, which may be more than the size of the function body itself. It is advisable to use these attributes in limited cases as they affect the readability of programs.\n\n## Reducing Binary Size by Moving Evaluations Out of the Binary**\nWith a good knowledge of [compiler](notes/compilers.md) optimisations and requirements of the programming language, it is possible to move evaluations out of the binary. Some of the expressions can be evaluated at compile time, while some others can be delayed until runtime. Both approaches help reduce the binary size. Following are motivating examples:\n\nEarly evaluation: Using language features like `constexpr`, `static_assert` of C++ some of the expressions can be evaluated early for example:\n\n```cpp\nconstexpr auto gcd(int a, int b){  \nÂ while (b != 0){  \nÂ  auto t= b;  \nÂ  b= a %b;  \nÂ  a= t;  \nÂ }  \nÂ return a;  \n}\n\nint main(){  \nÂ  Â int a= 11;  \nÂ  Â int b= 121;  \nÂ  Â int j= gcd(a,b);  \nÂ  Â constexpr int i= gcd(10,12); // saves â€˜2â€™ in the final assembly.  \nÂ  Â return i + j;  \n}\n```\n\nCompiling the above program with `g++ -std=c++17 -fno-exceptions -S`:\n\n```assembly\nmain:  \nÂ  Â  Â  Â movÂ  Â  Â edx, 121  \nÂ  Â  Â  Â movÂ  Â  Â eax, 11  \n.L2:Â  Â  Â  Â  Â  Â  Â  Â  Â # inlined call to gcd(a, b)  \nÂ  Â  Â  Â movÂ  Â  Â ecx, edx  \nÂ  Â  Â  Â cdq  \nÂ  Â  Â  Â idivÂ  Â  ecx  \nÂ  Â  Â  Â movÂ  Â  Â eax, ecx  \nÂ  Â  Â  Â testÂ  Â  edx, edx  \nÂ  Â  Â  Â jneÂ  Â  Â .L2  \nÂ  Â  Â  Â addÂ  Â  Â eax, 2 # Precomputed value of gcd(10,12)  \nÂ  Â  Â  Â ret\n```\n\nWe can see in the assembly that the second `gcd` has been evaluated at the compile time, but the first call to `gcd` has the entire code in it. This is because the second call to the `gcd` function is a `constexpr`. You can learn more about `constexpr` expressionsÂ on theÂ [constexpr specifier web page](https://en.cppreference.com/w/cpp/language/constexp).\n\n## Simple Tricks to Find Dead Code in Binary\nIn any large project, there is likely dead code because of various reasons. Some of the dead code can be removed with simple tricks; for example:\n\n- Finding testing and debugging code shipped in production. It is non-trivial to find testing/debugging code by grepping the source code; however, searching in the binary provides a high signal/noise ratio. `nm` can be used to search symbol names in a binary. \n \n`nm \u003cBinary\u003e | grep -i \"test\\|debug\"`\n\n- Finding strings in the binary using the `strings` tool. As explained before, strings will print all the C-strings hardcoded in the binary. By looking at the strings we can investigate why a particular string ends up in the final binary.","lastmodified":"2022-07-02T12:03:24.356674337Z","tags":null},"/notes/stacks-and-queues":{"title":"Stacks and Queues","content":"# Stacks and Queues\n---\n- **Stack**: last in, first out (LIFO), simple [list](notes/lists.md) works well for this. \n    - Think of a stack of plates.\n    - The add and remove operations are called **push** and **pop**.\n\n- **Queue**: first in, last out (FIFO), double linked [list](notes/lists.md) works well.\n    - Think of a standard queue, for example at the bank.\n    - The add and remove operations are called **enqueue** and **dequeue**.\n\n## Stack API\nA basic interface is:\n\n```java\npublic interface StringStack {\n  StringStack();\n  void push(String item);\n  String pop();\n  boolean isEmpty();\n  // optional\n  int size();\n}\n```","lastmodified":"2022-07-02T12:03:24.356674337Z","tags":null},"/notes/syntax-directed-translation":{"title":"Syntax Directed Translation","content":"# Syntax Directed Translation\n---\nUse **attribute grammars**, where productions are supplemented with information to control semantic analysis and translation.\n\nAssociate attributes with each grammar symbol to describe its properties.\n\nFor each production add **semantic rules** (aka semantic actions) to compute attribute values.\n\ndig $\\rightarrow$ 0 { dig.val = 0 }\n           1 { dig.val = 1}\n           ...\n           9 { dig.val = 9}\n\n## Decorated Syntax of a Digit\n$int_1 \\rightarrow$ dig         { $int_1$.val = dig.val }\n        |    $int_2$dig  { $int_1$.val = $int_2$.val * 10 + dig.val }\n\n![](content/images/decorated-parse-tree.png)\n\n## See Also\n- [Formal Languages](notes/formal-languages.md)\n","lastmodified":"2022-07-02T12:03:24.356674337Z","tags":null},"/notes/sysroot":{"title":"Sysroot","content":"# Sysroot\n---\nAny [compiler](notes/compilers.md) needs to know where the standard headers, standard libraries, and the c-runtime are present. All of these are packaged together for each target (e.g., arm64, x86) in a directory called `sysroot`. When we compile a program, we need to pass the path to `sysroot` for a compiler to know where to look for standard headers during compilation, and where to look for common libraries (`libc`, `libstdc++`, etc.) during linkage.\n\nNormally, when we compile a program for the same machine, the compiler uses the standard headers available in `/usr/include`Â and libraries from `/usr/lib`. These paths are hardcoded in the compiler itself, so we never have to think about it. However, when building a custom compiler or when cross-compiling programs, we tell the compiler where the `sysroot` is by passing a flag (e.g. `gcc --sysroot=\"/path/to/arm64/sysroot/usr\" hello.cpp`). \n\nMost often, pre-packaged cross compilers come with a script/binary that has a `sysroot` path embedded into it (e.g., `aarch64-linux-gnu-gcc)` [g++-10-aarch64-linux-gnu (10.3.0-8ubuntu1cross1) package](https://packages.ubuntu.com/impish/devel/g++-10-aarch64-linux-gnu).","lastmodified":"2022-07-02T12:03:24.356674337Z","tags":null},"/notes/three-address-code":{"title":"Three Address Code","content":"# Three Address Code\n---\n[Parse trees](notes/parse-trees.md) are sometimes used in early stages of [compilers](notes/compilers.md).\n\n- They are **not** ideal for [optimisation](notes/compiler-optimisation.md).\n\nMain part of the compilers today use [](notes/instruction-set-semantics.md#^44cfb5|three%20address%20code):\n\n`result = operand1 operator operand2`\n\n## Example\nThe expression $a * b + a * b$ might be represented in TAC as:\n\n```assembly\nt1 := a  * b\nt2 := a  * b\nc  := t1 + t2\n```\n\n## Types\n- **Binary operators.**\n- **Unary operators** - one argument is ignored.\n- **Assignment** - one argument and operator is ignored.\n- **Unconditional jump** - result is label of a TAC instruction.\n- **Conditional jump** - variants for comparing arguments and jumping to result, or compare to generate `bool` followed by jump on a `bool`.\n- **Call and return** - one argument is the address, result is the return value.\n\n## Representation in C\n```c\nstruct tac {\n  int op;\n  struct tacarg arg1;\n  struct tacarg arg2;\n  struct tacarg res;\n}\n```\n\n```c\nstruct tacarg {\n  int disc;\n  union\n  {\n    int const;\n    struct symtab *name;\n    struct tac *label;\n  } data;\n}\n```\n\nRather than allocating each node in turn and linking them together, we can represent in a vector:\n```c\nstruct tac icode[1000];\n```\n\nThen have a function to generate a new node:\n```c\nvoid tacgen (int op, struct tacarg a, struct b, struct c) {\n  icode[pc].op = op;\n  icode[pc].arg1 = a;\n  icode[pc].arg2 = b;\n  icode[pc].res = c;\n  pc++;\n}\n```\n\n## Syntax Directed Translation\nRelated to [this](notes/syntax-directed-translation.md).\n\nasgmt $\\rightarrow$ var := expr\n                {tacgen(TAC_COPY, var.entry, NULL,\n                expr.place);}\n\n- The **entry** attribute would be the variable's symbol table entry.\n- The **place** attribute would be the location of the expression.\n    - Generated during the parsing of `expr`.\n    - Could be a variable, temporary variable or constant.","lastmodified":"2022-07-02T12:03:24.356674337Z","tags":null},"/notes/tmux-cheatsheet":{"title":"Tmux Cheatsheet","content":"# Tmux Cheatsheet\n---\n**tmux** is a terminal multiplexer: it enables a number of terminals to be created, accessed, and controlled from a single screen.  **tmux** may be detached from a screen and continue running in the background, then later reattached.\n\n   When **tmux** is started, it creates a new session with a single window and displays it on screen.  A status line at the bottom of the screen shows information on the current session and is used to enter interactive commands.\n\n   A session is a single collection of pseudo terminals under the management of **tmux**.  Each session has one or more windows linked to it.  A window occupies the entire screen and may be split into rectangular panes, each of which is a separate pseudo terminal. Any number of **tmux** instances may connect to the same session, and any number of windows may be present in the same session.  Once all sessions are killed, **tmux** exits.\n\n   Each session is persistent and will survive accidental disconnection (such as ssh connection timeout) or intentional detaching (with the `C-t d` key strokes).  **tmux** may be reattached using:\n\n```bash\n $ tmux attach\n```\n\nIn **tmux**, a session is displayed on screen by a client and all sessions are managed by a single server. The server and each client are separate processes which communicate through a socket in `/tmp`.\n\n## Commands\n`tmux info` - Show every session, window, pane, etc...\n`tmux new -s mysession` - Start a session with the name _mysession_.\n`tmux ls` - List all sessions.\n`tmux a -t mysession` - Attach to _mysession_.\n`tmux kill-ses -t mysession` - Kill _mysession_.\n`tmux kill-session -a -t mysession` - Kill all but _mysession_.\n\n## Sessions\n| Shortcut         | Function               |\n| ---------------- | ---------------------- |\n| `Ctrl` + `t`     | Leader key.            |\n| `\u003cleader\u003e` + `$` | Rename session.        |\n| `\u003cleader\u003e` + `d` | Detach from session.   |\n| `\u003cleader` + `s`  | Show all sessions.     |\n\n## Windows\n| Shortcut         | Function               |\n| ---------------- | ---------------------- |\n| `\u003cleader\u003e` + `c` | Create window.         |\n| `\u003cleader\u003e` + `,` | Rename current window. |\n| `\u003cleader\u003e` + `\u0026` | Close current window.  |\n| `\u003cleader\u003e` + `n` | Next window.           |\n\n## Panes\n| Shortcut         | Function                  |\n| ---------------- | ------------------------- |\n| `\u003cleader\u003e` + `-` | Split pane horizontally.  |\n| `\u003cleader\u003e` + `\\` | Split pane vertically     |\n| `\u003cleader\u003e` + `{` | Move pane left.           |\n| `\u003cleader\u003e` + `}` | Move pane right.          |\n| `\u003cleader\u003e` + `!` | Convert pane into window. |\n| `\u003cleader\u003e` + `x` | Close current pane.       |\n\n## Other\n| Shortcut         | Function          |\n| ---------------- | ----------------- |\n| `\u003cleader\u003e` + `?` | List key bindings |","lastmodified":"2022-07-02T12:03:24.356674337Z","tags":null},"/notes/trees":{"title":"Trees","content":"# Trees\n---\n[Abstract data type](https://en.wikipedia.org/wiki/Abstract_data_type \"Abstract data type\") that represents a hierarchical [tree structure](https://en.wikipedia.org/wiki/Tree_structure \"Tree structure\") with a set of connected [nodes](https://en.wikipedia.org/wiki/Node_(computer_science) \"Node (computer science)\"). Each node in the tree can be connected to many children (depending on the type of tree), but must be connected to exactly one parent, except for the _root_ node, which has no parent. \n\nThese constraints mean there are no cycles or \"loops\" (no node can be its own ancestor), and also that each child can be treated like the root node of its own subtree, making [recursion](https://en.wikipedia.org/wiki/Recursion \"Recursion\") a useful technique for tree traversal. In contrast to linear data structures, many trees cannot be represented by relationships between neigh-boring nodes in a single straight line.\n\n[Binary trees](notes/binary-trees.md) are a commonly used type, which constrain the number of children for each parent to exactly two. When the order of the children is specified, this data structure corresponds to an [ordered tree](https://en.wikipedia.org/wiki/Ordered_tree \"Ordered tree\") in graph theory. A value or pointer to other data may be associated with every node in the tree, or sometimes only with the _leaf nodes_, which have no children.\n\nThe abstract data type can be represented in a number of ways, including a list of parents with pointers to children, a list of children with pointers to parents, or a list of nodes and a separate list of parent-child relations (a specific type of [adjacency list](https://en.wikipedia.org/wiki/Adjacency_list \"Adjacency list\")). Representations might also be more complicated, for example using [indexes](https://en.wikipedia.org/wiki/Database_index \"Database index\") or ancestor lists for performance.\n\nSource: [Wikipedia](\u003chttps://en.wikipedia.org/wiki/Tree_(data_structure)\u003e)\n\n## Types of tree\n- [Binary Trees](notes/binary-trees.md)\n- [2-3 Trees](notes/2-3-trees.md)\n- [B-Trees](notes/b-trees.md)\n- [Binary Heap](notes/binary-heap.md)\n- [Parse Trees](notes/parse-trees.md)\n\n## See also\n- [Graphs](notes/graphs.md)\n- [Minimum Spanning Subtree](notes/minimum-spanning-subtree.md)","lastmodified":"2022-07-02T12:03:24.356674337Z","tags":null},"/notes/university-hub":{"title":"Brunel - Computer Science Hub","content":"# Brunel - Computer Science Hub\n\n\u003ccenter\u003e\u003cimg src=\"http://content/images.stickpng.com/images/584fce586a5ae41a83ddee93.png\" width=60% height=60%\u003e\u003c/center\u003e\n\nHere you can find everything related to my university course.\n\n## Useful Links\n[Blackboard](https://blackboard.brunel.ac.uk/)\n\n## Notes\n2022/2023 - [Year 2](university/year-2.md)\n","lastmodified":"2022-07-02T12:03:24.356674337Z","tags":null},"/notes/useful-commands-dump":{"title":"Useful Commands Dump","content":"# Useful Commands Dump\n---\n\nWell... where I dump any useful commands I find and them hopefully I'll categorise them... eventually...\n\n## Terminal\n* Change file extension of all files:\n```bash\nfor file in *.txt; do mv \"$file\" \"${file%.txt}.md\"; done\n```\n\n* If Git is hanging after total is because:\n```bash\ngit config --global http.postBuffer 157286400\n```\n\n## GDB\n| Command                      | Description                                                      |\n| ---------------------------- | ---------------------------------------------------------------- |\n| `gdb --args \u003cbinary\u003e \u003cargs\u003e` | Start the program with an argument list.                         |\n| `b FileName:linenum`         | For setting a breakpoint.                                        |\n| `bt`                         | For getting backtrace.                                           |\n| `thread apply all bt`        | For getting the backtrace of all threads.                        |\n| `p variableName`             | For printing the value of a variable/object.                     |\n| `up`                         | For going up the stack frame.                                    |\n| `down`                       | For going down the stack frame.                                  |\n| `l`                          | For listing source lines of code around the current stack frame. |\n| `disassemble`                | For showing the assembly code of the current function.           |\n| `n`                          | For executing the next source instruction.                       |\n| `si`                         | For executing the next machine instruction.                      |\n| `q`                          | To quit the debugger.                                            |\n| `r`                          | To run the program.                                              |\n\nThe docs are [here](https://www.gnu.org/software/gdb/documentation/).\nMore info on [GDB](notes/gdb.md).\n\n## The dump of dumps\n\n### BSC/Tiger related\n```bash\nruntest --tool=gcc --tool_exec=bsc-elf-clang  --tool_opts= --directory=${HOME}/tiger/gcc-for-llvm-testing/gcc/testsuite/gcc.target --srcdir=${HOME}/tiger/gcc-for-llvm-testing/gcc/testsuite --target_board=bsc-embdebug --target=bsc-elf \"bsc.exp=bsc/or.c\"\n```\n\n```bash\nexport PATH=${HOME}/riscv32-clang-gcc-testing/install/bin:$PATH\nexport BSC_TIMEOUT=300\nexport BSC_TRIPLE=bsc-elf\nexport BSC_SIM_COMMAND=bsc-run\nexport BSC_SIM_FLAGS=\nexport DEJAGNU=${HOME}/tiger/toolchain/site.exp\nexport TOOLDIR=${HOME}/tiger/toolchain/\n```\n\n```bash\nbsc-elf-gdb -ex 'target remote | embdebug --soname bsc --stdin' -ex 'break exit' -ex 'break abort' test2.exe\n```\n\n```bash\nllvm-objdump -d \u003ctestobject\u003e\n```\n\n```bash\nbsc-run --max-steps=200 --trace-inst --trace-regs --trace-stack ds.exe 2\u003e\u00261 | tee output.txt\n```\n\n```bash\npietraferreira@tom:~/insn-test-tiger$ bsc-elf-gdb -ex 'target remote | embdebug --soname bsc --stdin' -ex 'break exit' -ex 'break abort' sub.exe\n```\n\nAsk the front end to produce unoptimised LLVM IR:\n```bash\nbsc-elf-clang -Wall -O0 -S -emit-llvm --target=bsc 20180309-1.c -o 20180309-1.ll\n```\n\nCompile but stop at assembly:\n```bash\nllc --debug -mtriple=bsc 20180309-1.ll -o 20180309-1.s\n```\n\n```bash\nllvm-objdump -d sim-test.exe\n```\n\n```bash\nbsc-elf-gdb sim-test.exe -ex \"target remote | embdebug --soname sysc-bsc --vcd=trace-do --debug=0x00070000 --clk-mhz=1 --sim-cycles=10000 --stdin\" -ex load -ex c -ex detach -ex quit 2\u003e\u00261 | tee sim-test.log\n```\n\n## Website URL Fix\n```bash\ngrep -rl 'images' . | sort | uniq | xargs perl -e \"s/assets/assets\\/engineer-training/\" -pi\n```","lastmodified":"2022-07-02T12:03:24.356674337Z","tags":null},"/notes/vectors-arrays":{"title":"Vectors and Arrays","content":"# Vectors and Arrays\n---\n- Vectors are typically 1-d whereas arrays can be multi-dimensional.\n- in **C/C++** they are indexed from zero.\n\nDeclared arrays have *literal* constant size **fixed** at compile time:\n```c\n#define SIZE 42\nint c[SIZE];\n```\n\nWe **cannot** use *const* variables as size:\n```c\nconst int NEW_SIZE = 561\nint c[NEW_SIZE];  /* This is not a literal constant! */\n```\n\nFor **variable size** vectors we use **malloc** and **pointers** (allocated on the heap). However there are some constraints on its use:\n```c\nint func(int n) {\n  int *vec = (int *) malloc (n * sizeof (*vec));\n\n  for(int i=0; i\u003cn; i++) {\n  vec[i] = n; \n  }\n}\n```\n\n```ad-note\nWe can also use **alloca** (allocated on the stack).\n```\n\n## Associative arrays\n- Also known as **addressable arrays** or [maps](notes/sets-and-maps.md).\n\nOrdinary arrays/vectors when given an index into the array output a value whereas **associative arrays** when given a value outputs an index.\n\nThey are common in hardware and efficient to implement. However they are harder to implement in software.\n\n## Sparse arrays\nIt is an array of data in which many elements have a value of zero. It can be compressed or truncated to fit storage spaces. For example, rather than holding all of the zero values in variables, the array could simply point to the number of zero values in a sequence or otherwise compress the array's data storage.\n\nIf they are regular (e.g. in numerical analysis), then map mathematically to vector.\n\nIf irregular, use a vector of pointers to sparse rows, represented in compact form (e.g. column/value pairs or linked list).\n\nReference: [Sparse Array - Techopedia](https://www.techopedia.com/definition/9480/sparse-array)","lastmodified":"2022-07-02T12:03:24.356674337Z","tags":null},"/notes/vim-cheatsheet":{"title":"Vim Cheatsheet","content":"# Vim Cheatsheet\n\nThankfully I remember most of these but all of them are great :)\n\n* **MD to PDF** and **MD to HTML** are custom.\n\n**Shortcut** | **Function**\n-------- | --------\n`g` + `t` | Next tab\n`g` + `T` | Previous tab\n`z` + `z` | Center on this line\n`Ctrl` + `[`, `Ctrl` + `]` | Previous or next tab\n`Ctrl` + `w` + `s` | Horizontal split\n`Ctrl` + `w` + `v` | Vertical split\n`Ctrl` + `w` + `q` | Close \n`Ctrl` + `w` + `w` | Switch splits \n`Ctrl` + `j`, `h`, `k`, `l` | Move around\n`\u003cleader\u003e` + `N` | Toggle number\n`\u003cleader\u003e` + `r` | Shortcut to replace, press * on word then type replacement\n`\u003cleader\u003e` + `p` + `p` | MD to PDF\n`\u003cleader\u003e` + `p` + `h` | MD to HTML \n\n## How to macro\n\nTo enter a macro, type: `q\u003cletter\u003e\u003ccommands\u003eq`\n\nTo execute the macro **number** of times (once by default), type:\n`\u003cnumber\u003e@\u003cletter\u003e`\n\nSo, the complete process looks like:\n\nCommand | What happens\n------- | ------------\n`qd` | start recording to register\n`...` | your complex series of commands\n`q` | stop recording\n`@d` | execute your macro\n`@@` | execute your macro again\n\n ## Insert text into multiple lines at once\n Press `Ctrl + v` to enter into visual block mode.\n\nUse `â†‘` / `â†“` / `j` / `k` to select multiple lines.\n\nPress `Shift + i` and start typing what you want.\n\nAfter you press `Esc`, the text will be inserted into all the lines you selected.\n\n## Plugins\n### Telescope\n**Shortcut** | **Function**\n-------- | --------\n`leader` + `f` + `f` | Find files\n`leader` + `f` + `g` | Live grep\n`leader` + `f` + `k` | List key-maps and search\n`Ctrl` + `x` | Open in vertical split\n`Ctrl` + `v` | Open in horizontal split\n\n### FzF\n| Shortcut   | Function                 |\n| ---------- | ------------------------ |\n| `:Files`     | Search files.            |\n| `:GFiles?`    | Git files (`git status`).  | \n| `:Buffers`   | Open buffers.            | \n\n### LSP\n| Shortcut                             | Function                   |\n| ------------------------------------ | -------------------------- |\n| `g` + `l`                            | Check message on the side. |\n| `g` + `D`                            | Go to declaration.         |\n| `g` + `d`                            | Go to definition.          |\n| `K`                                  | Hover message.             |\n| `g` + `r`                            | Goto references.           |\n| `:lua vim.lsp.buf.formatting_sync()` | Format code.               |\n","lastmodified":"2022-07-02T12:03:24.356674337Z","tags":null},"/notes/work-hub":{"title":"Work Hub","content":"# Work Hub\n\n\u003ccenter\u003e\u003cimg src=\"https://www.embecosm.com/app/uploads/logo-1.png\"\u003e\u003c/center\u003e\n\nEverything work related, mostly organised by project.\n\n## Useful Links\n* [Wiki](https://internal.embecosm.com/wiki/Main_Page)\n* [Engineering Training](https://git.embecosm.com/engineering-training)\n- [Onboarding Guide for the OpenHW Group](https://docs.google.com/document/d/1wLbqSYdxl5GMawt9ggqnX9Yuqy6FLsH0t0uuXcZ_Tms/edit)\n\n## Projects\n### Engineer Training\n- [Hub](notes/engineer-training-hub.md)\n\n### RISC-V\n- [Notes](notes/riscv.md)\n\n#### Relocation Handling Prototype (CORE-V)\n* [Notes](work/relocation-prototype/relocation-prototype.md)\n* [Reports](work/relocation-prototype/relocation-prototype-reports/relocation-prototype-reports-hub.md)\n\n#### CORE-V\n- [CORE-V Toolchain](notes/corev-toolchain.md)\n- [Assembly Test Example](work/assembly-test-example-corev.md)\n\n##### Videos\n- [Porting the GNU CORE-V Toolchain](https://www.youtube.com/watch?v=RT0GqJySnBc\u0026t=333s)\n- [Adding an Instruction to the GNU assembler](https://www.youtube.com/watch?v=GcnkcK3uYYI\u0026t=228s)\n- [GNU toolchain for CORE-V](https://www.youtube.com/watch?v=3f3VuSzslxU\u0026t=1418s) (Jessica talks about relocation handling [here](https://youtu.be/3f3VuSzslxU?t=1192))\n\n### Tiger\n- [Introduction to the project](content/images/tiger.pdf)\n\n### DejaGNU\n- [DejaGNU documentation notes](work/dejagnu-documentation-notes.md)\n\n### LLVM\n- [LLVM Toolchain](notes/llvm.md)\n- [How to Write a LLVM backend](notes/how-to-write-a-llvm-backend.md)\n\n### GCC\n- [GCC Toolchain](notes/gcc.md)\n\n## Talks\n### 2020 Meetup\n- [Script](work/meetup-2020-corev-script.md)\n- [Slides](content/images/meetup-2020-corev-presentation-v11.odp)\n\n### Facial Recognition - Coral Board\n- [Script](work/facial-recognition-board-talk-script.md)\n\n### Strode College Talk - About me\n- [Script](work/strode-talk-script.md)\n\n## Meeting Notes\n```dataview\ntable without ID\nfile.link as \"Link\", file.ctime as \"Created Time\"\nfrom #meeting\nsort file.ctime desc\n```\n\n## All notes\n```dataview\ntable without ID\ntitle as \"Title\", file.ctime as \"Created Time\", file.link as \"Link\"\nfrom #work and -#report\nsort file.ctime desc\n```","lastmodified":"2022-07-02T12:03:24.356674337Z","tags":null},"/old.index":{"title":"ðŸª´ Quartz 3.2","content":"\nHost your second brain and [digital garden](https://jzhao.xyz/posts/networked-thought) for free. Quartz features\n\n1. Extremely fast full-text search by pressing `Ctrl` + `k`\n2. Customizable and hackable design based on Hugo\n3. Automatically generated backlinks, link previews, and local graph\n4. Built-in [[notes/CJK + Latex Support (æµ‹è¯•) | CJK + Latex Support]]\n5. Support for both Markdown Links and Wikilinks\n\n## Get Started\n\u003e ðŸ“š Step 1: [Setup your own digital garden using Quartz](notes/setup.md)\n\nNot convinced yet? Look at some [community digital gardens](notes/showcase.md) built with Quartz, or read about [why I made Quartz](notes/philosophy.md) to begin with.\n\nReturning user? Figure out how to [[notes/updating|update]] your existing Quartz garden.\n\n### Content Lists\nIf you prefer browsing the contents of this site through a list instead of a graph, you see a list of all [setup-related notes](/tags/setup).\n\n### Troubleshooting\n- ðŸš§ [Troubleshooting and FAQ](notes/troubleshooting.md)\n- ðŸ› [Submit an Issue](https://github.com/jackyzha0/quartz/issues)\n- ðŸ‘€ [Discord Community](https://discord.gg/cRFFHYye7t)\n","lastmodified":"2022-07-02T12:03:24.356674337Z","tags":null}}