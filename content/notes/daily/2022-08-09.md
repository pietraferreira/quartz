---
title: "2022-08-09"
tags:
  - assembly
programming-languagues:
created: 2022-08-09
---
# 2022-08-09
---
## Data Storage Sizes
| C/C++     | Storage         | Size (bits) | Size (bytes) |
| --------- | --------------- | ----------- | ------------ |
| char      | Byte            | 8-bits      | 1 byte       |
| short     | Word            | 16-bits     | 2 bytes      |
| int       | Double-word     | 32-bits     | 4 bytes      |
| long      | Quadword        | 64-bits     | 8 bytes      |
| long long | Quadword        | 64-bits     | 8 bytes      |
| int *     | Quadword        | 64-bits     | 8 bytes      |
| double    | Quadword        | 64-bits     | 8 bytes      |
| float     | Double quadword | 128-bits    | 16 bytes     |

- `.cfi_def_cfa_offset`: CFI directives are used for debugging. It allows the debugger to unwind a stack, for example: if a procedure A calls procedure B which then calls a common procedure C. Procedure C fails. You now want to know who actually called C and then you may want to know who called B.

A debugger can **unwind** this stack by using the stack pointer (`%rsp`) and register `%rbp`, however it needs to know how to find them. This is where CFI comes in:

```as
movq    %rsp, %rbp
.cfi_def_cfa_register 6
```

The last line tell it that the **Call Frame Address** is now in register 6 (`%rbp`).

To disable these, g++ needs `-fno-exceptions` along with `-fno-asynchronous-unwind-tables`, provided that you don't use exceptions. `-fno-dwarf2-cfi-asm` may also be needed.

On Godbolt: `-g0 -fno-asynchronous-unwind-tables`

Something like this:

```bash
g++ -fno-asynchronous-unwind-tables -fno-exceptions -fno-rtti -fverbose-asm -Wall -Wextra foo.cpp -O3 -masm=intel -S -o- | less
```

## Useful compiler options for making asm for human consumption:

-   **Remember, your code only has to compile, not link: passing a pointer to an external function like `void ext(void*p)` is a good way to stop something from optimising away**. You only need a prototype for it, with no definition so the compiler can't inline it or make any assumptions about what it does. (Or [inline asm like `Benchmark::DoNotOptimize`](https://stackoverflow.com/questions/40122141/preventing-compiler-optimizations-while-benchmarking) can force a compiler to materialise a value in a register, or forget about it being a known constant, if you know GNU C inline asm syntax well enough to use constraints to understand the effect you're having on what you're requiring of the compiler.)
    
-   I'd recommend using `-O3 -Wall -Wextra -fverbose-asm -march=haswell` for looking at code. (`-fverbose-asm` can just make the source look noisy, though, when all you get are numbered temporaries as names for the operands.) When you're fiddling with the source to see how it changes the asm, you _definitely_ want compiler warnings enabled. You don't want to waste time scratching your head over the asm when the explanation is that you did something that deserves a warning in the source.
    
-   To see how the calling convention works, **you often want to look at caller and callee without inlining**.
    
    You can use `__attribute__((noipa)) foo_t foo(bar_t x) { ... }` on a definition, or compile with `gcc -O3 -fno-inline-functions -fno-inline-functions-called-once -fno-inline-small-functions` to disable inlining. (But those command line options don't disable cloning a function for constant-propagation. `noipa` = no Inter-Procedural Analysis. It's even stronger than `__attribute__((noinline,noclone))`.) See [From compiler perspective, how is reference for array dealt with, and, why passing by value(not decay) is not allowed?](https://stackoverflow.com/questions/50775127/from-compiler-perspective-how-is-reference-for-array-dealt-with-and-why-passi) for an example.
    
    Or if you just want to see how functions pass / receive args of different types, you could use different names but the same prototype so the compiler doesn't have a definition to inline. This works with any compiler. Without a definition, a function is just a black box to the optimiser, governed only by the calling convention / ABI.
    
-   `-ffast-math` will get many libm functions to inline, some to a single instruction (esp. with SSE4 available for `roundsd`). Some will inline with just `-fno-math-errno`, or other "safer" parts of `-ffast-math`, without the parts that allow the compiler to round differently. If you have FP code, definitely look at it with/without `-ffast-math`. If you can't safely enable any of `-ffast-math` in your regular build, maybe you'll get an idea for a safe change you can make in the source to allow the same optimisation without `-ffast-math`.
    
-   **`-O3 -fno-tree-vectorize` will optimise without auto-vectorising**, so you can get full optimisation without if you want to compare with `-O2` (which doesn't enable autovectorisation on gcc11 and earlier, but does on all clang).
    
    **`-Os` (optimise for size and speed) can be helpful** to keep the code more compact, which means less code to understand. clang's `-Oz` optimises for size even when it hurts speed, even using `push 1` / `pop rax` instead of `mov eax, 1`, so that's only interesting for [code golf](https://codegolf.stackexchange.com/questions/132981/tips-for-golfing-in-x86-x64-machine-code).
    
    Even `-Og` (minimal optimisation) might be what you want to look at, depending on your goals. `-O0` is full of store/reload noise, which makes it harder to follow, [unless you use `register` vars](https://stackoverflow.com/questions/53366394/why-does-clang-produce-inefficient-asm-with-o0-for-this-simple-floating-point). The only upside is that each C statement compiles to a separate block of instructions, and it makes `-fverbose-asm` able to use the actual C var names.
    
-   clang unrolls loops by default, so **`-fno-unroll-loops` can be useful in complex functions**. You can get a sense of "what the compiler did" without having to wade through the unrolled loops. (gcc enables `-funroll-loops` with `-fprofile-use`, but not with `-O3`). (This is a suggestion for human-readable code, not for code that would run faster.)
    
-   **Definitely enable some level of optimisation, unless you specifically want to know what `-O0` did**. Its "predictable debug behaviour" requirement makes the compiler store/reload everything between every C statement, so you can modify C variables with a debugger and even "jump" to a different source line within the same function, and have execution continue as if you did that in the C source. `-O0` output is so noisy with stores/reloads (and so slow) not just from lack of optimisation, but [forced de-optimisation to support debugging](https://stackoverflow.com/questions/53366394/why-does-clang-produce-inefficient-asm-with-o0-for-this-simple-floating-point). (also [related](https://stackoverflow.com/questions/46638527/when-will-the-trivial-code-that-has-no-effect-code-gets-removed-in-compilation/46640101#46640101)).
    
---
**To get a mix of source and asm**, use [`gcc -Wa,-adhln -c -g foo.c | less`](https://stackoverflow.com/a/137479/224132) to pass extra options to `as`. (More discussion of this in [a blog post](http://www.systutorials.com/240/generate-a-mixed-source-and-assembly-listing-using-gcc/), and [another blog](https://panthema.net/2013/0124-GCC-Output-Assembler-Code/).). Note that the output of this isn't valid assembler input, because the C source is there directly, not as an assembler comment. So don't call it a `.s`. A `.lst` might make sense if you want to save it to a file.

Godbolt's color highlighting serves a similar purpose, and is great at helping you see when multiple _non-contiguous_ asm instructions come from the same source line. I haven't used that gcc listing command at all, so IDK how well it does, and how easy it is for the eye to see, in that case.

I like the high code density of godbolt's asm pane, so I don't think I'd like having source lines mixed in. At least not for simple functions. Maybe with a function that was too complex to get a handle on the overall structure of what the asm does...

---
And remember, when you want to just look at the asm, **leave out the `main()` and the compile-time constants**. You want to see the code for dealing with a function arg in a register, not for the code after constant-propagation turns it into `return 42`, or at least optimises away some stuff.

Removing `static` and/or `inline` from functions will produce a stand-alone definition for them, as well as a definition for any callers, so you can just look at that.

**Don't put your code in a function called `main()`**. gcc knows that `main` is special and assumes it will only be called once, so it marks it as "cold" and optimises it less.

---
The other thing you can do: If you did make a `main()`, you can run it and use a debugger. `stepi` (`si`) steps by instruction. See the bottom of the [x86](https://stackoverflow.com/questions/tagged/x86 "show questions tagged 'x86'") [tag wiki](https://stackoverflow.com/tags/x86/info) for instructions. But remember that code might optimise away after inlining into main with compile-time-constant args.

`__attribute__((noinline))` may help, on a function that you want to not be inlined. gcc will also make constant-propagation clones of functions, i.e. a special version with one of the args as a constant, for call-sites that know they're passing a constant. The symbol name will be `.clone.foo.constprop_1234` or something in the asm output. You can use `__attribute__((noclone))` to disable that, too.).

---
### For example
If you want to see how the compiler multiplies two integers: I put the following code [on the Godbolt compiler explorer](http://gcc.godbolt.org/#compilers:!((compiler:g530,options:%27-xc+-std%3Dgnu11+-Wall+-Wextra++-O3+-fverbose-asm+-ffast-math+-march%3Dhaswell%27,source:%27int+constants()+%7B+int+a+%3D+10,+b+%3D+20%3B+return+a+*+b%3B+%7D%0Aint+variables(int+a,+int+b)+%7B+return+a+*+b%3B+%7D%0A%27)),filterAsm:(commentOnly:!t,directives:!t,intel:!t,labels:!t),version:3) to get the asm (from `gcc -O3 -march=haswell -fverbose-asm`) for the wrong way and the right way to test this.

```csharp
// the wrong way, which people often write when they're used to creating a runnable test-case with a main() and a printf
// or worse, people will actually look at the asm for such a main()
int constants() { int a = 10, b = 20; return a * b; }
    mov     eax, 200  #,
    ret                     # compiles the same as  return 200;  not interesting

// the right way: compiler doesn't know anything about the inputs
// so we get asm like what would happen when this inlines into a bigger function.
int variables(int a, int b) { return a * b; }
    mov     eax, edi  # D.2345, a
    imul    eax, esi        # D.2345, b
    ret
```

## Objdump Tips
You can even tell `objdump` to intermix source with assembly, making it easier to figure out what source line corresponds to what instructions. Example session:

```csharp
$ cat test.cc
int foo(int arg)
{
    return arg * 42;
}

$ g++ -g -O3 -std=c++14 -c test.cc -o test.o && objdump -dS -M intel test.o

test.o:     file format elf64-x86-64


Disassembly of section .text:

0000000000000000 <_Z3fooi>:
int foo(int arg)
{
    return arg + 1;
   0:   8d 47 01                lea    eax,[rdi+0x1]
}
   3:   c3                      ret    
```

Explanation of `objdump` flags:

-   `-d` disassembles all executable sections
-   `-S` intermixes assembly with source (`-g` required while compiling with `g++`)
-   `-M intel` chooses intel syntax over ugly AT&T syntax (_optional_)

---
## Two's Complement
- `1111` -> -1, `1001` -> -2

## Loading and Storing Data
To load data from memory into registers or store data in registers to memory we use the `L` and `S` instructions. You need to use different suffixes to indicate what you are loading:

-   `LB` - **L**oad **B**yte.
-   `LW` - **L**oad **W**ord.
-   `SB` - **S**tore **B**yte.
-   `SW` - **S**tore **W**ord.

On RISC-V a word means 32-bits, while a byte obviously means 8-bits. These instructions take three operands but the third one is an immediate value. In assembly programming an immediate value is the same as a constant. It is encoded with the instruction rather than being stored in memory or inside a register.

Some examples of usage:

LW  x2, 2(x0)   # x2 ← [2], load contents at address 2  
LW  x3, 4(x2)   # x3 ← [4 + x2], load content of addr 4 + x2  
SW  x1, 8(x0)   # x1 → [8], store x1 at addr 8

## Addresses, Jumps and Labels
For a RISC-V program we know every instruction takes 32-bits. That corresponds to 4 bytes. Thus in a program the first instruction will typically be at address 0, the second at 4, the third at 8 and so on.

Let us write out an earlier program with addresses in the first column to make it easier to see how jumps work. First let us clarify a jump or branch is. If you want to repeat part of your code several times over you need to make a jump to a previous instruction.

The microprocessor keeps track of the next instruction to execute with a special register called the _Program Counter (PC)_. It gives the address in bytes of the next instruction to execute. Since each instruction is 4 bytes long, the PC gets incremented by 4 each time.

Let us look at an example:

```as
BEQ x2, x4, 12
```

The `BEQ` instruction means branch or jump if registers are **EQ**ual. If `x2 = x4` then the program counter (PC) will be updated to:

```as
PC ← PC + 12
```
That means jumping 3 instructions forward. That means we skip the next two instructions. Let us look at the count down program from earlier. The first column contains the instruction address:

```as
00:  ADDI x2, zero, 1   # x2 ← 0  + 1     
04:  SUB x1, x1, x2     # x1 ← x1 - 1  
08:  SW  x1, 4(zero)    # x1 → [4 + 0]  
12:  BLT zero, x1, -8   # 0 < x1 => PC ← PC - 8 = 4  
16:  HLT                # Halt, stop execution
```

You can copy this to the simulator without the address column. What you see here is that branching is relative to where you are. On line `12`, we want to check if `x1` is still larger than zero to see if we should continue our countdown. If it is we want to jump to line `04` where we use `SUB` to subtract 1 from `x1`. However we don't write `BLT zero, x1, 4`. Instead we specify `-8`. That is because jumps are relative. We jump two instructions backwards.

This is in fact quite practical because it means we could move our program to a different location in memory and it would still work. However more importantly it saves a lot of space. You only got 32-bits to encode an instruction:

-   Each register requires 5 bits to encode and the branch specifies two registers which eats up 10-bits.
-   The opcode and function eat up 10-bits.
-   That leaves 12-bits to specify an address to jump to. The maximum number you get with 12-bits is 4096 (²¹²). Thus if your program was larger than 4 KB you couldn’t perform jumps.

With relative addressing this is not a problem. You can jump 2048 bytes backwards or forwards in the program. Most for-loops, while-loop and if-statement will not be larger than that.

However there is one problem with relative addressing. It is awkward for the programmer to write. This is where address labels save us:

```as
ADDI x2, x0, 1  
  
loop:  
   SUB x1, x1, x2  
   SW  x1, 4(x0)   
   BLT x0, x1, loop
```

You can simply label the location you want to jump. Here we use the label `loop`. Use a colon to indicate this is a label. The assembler will use the label to calculate what offset needs to be used to jump to the given label. Thus depending on what instruction is using the `loop` label, a different offset will be calculated.

Ok let us look at different types of jumps. An instruction which makes an unconditional jump start with a `J`. Jumps which are conditional start with a `B` for Branch.

## Branching — Conditional Jumps
For conditional branching we compose the mnemonic from a `B` and a two or three letter combination describing the condition such as:

-   `EQ` = **EQ**ual.
-   `NE` ≠ **N**ot **E**qual.
-   `LT` < **L**ess **T**han.
-   `GE` ≥ **G**reater or **E**qual.

Let us look at a few examples of what that would translate to:

```as
BEQ x2, x4, offset    # x2 = x4  => PC ← PC + offset  
BNE x2, x4, offset    # x2 ≠ x4  => PC ← PC + offset  
BLT x2, x4, offset    # x2 < x4  => PC ← PC + offset  
BGE x2, x4, offset    # x2 ≥ x4  => PC ← PC + offset
```

## Unconditional Jumps
Often we need to jump around in code without checking if a condition is true or false. Examples of this are:

-   Calling a function. That means setting `a` registers to function inputs and doing a unconditional jump to location in memory where instructions for function reside.
-   Returning from a function. When we are done executing code in a function we need to return to instruction after call-site.

But often you simply need to make unconditional jumps to deal with different conditions.

## Jump and Link — JAL
The `JAL` instruction can be used for both calling functions or just make a simple unconditional jump.

`JAL` makes a relative jump (relative to PC) just like the conditional branch instructions. However the provided register argument is not used for comparisons but to store return address. If you don't want to store the return address you can simply provide the `zero` register `x0`.

```as
JAL rd, offset    # rd ← PC + 4, PC ← PC + offset
```

The convention used with RISC-V is that the return address should be stored with the return address register `ra` which is `x1`. Say you got some C code with call like this:

```c
foobar(2, 3)
```

In assembly this would be:

```as
ADDI a0, zero, 2  
ADDI a1, zero, 3  
JAL  ra, foobar
```

Why the emphasis on relative jumps in RISC-V? In earlier CPUs jumps where typically to absolute addresses. The reason is that in modern operating systems, one needs to be able to move code around in memory. Thus a developer cannot know the position of his or her code in memory. A relative jump will always work, regardless of where in memory a program is placed.

## Jump and Link Register — JALR
This is really the same instruction but with the difference that we use an offset from register? What is the point of that?

In `JAL` there is simply not enough space to encode a full 32-bit address. That means you cannot jump anywhere in the code if you are in a larger program. But if you use an address contained in a register, you can jump to any address.

Other than that `JALR` works almost the same as `JAL`. It will also store the return address in `rd`.

```as
JALR rd, offset(rs1)    # rd ← PC + 4, PC ← rs1 + offset
```

A big difference is that `JALR` jumps are not relative to `PC`. Instead it is relative to `rs1` .

While we could use a regular `ADDI` function to set the `rs1` register that is impractical. We want an address relative to the program counter (PC). Fortunately we have a special instruction `AUIPC` which stands for: Add Upper Immediate to PC.

```as
AUIPC rd, immediate    # rd ← PC + immediate[31:12] << 12
```

The explanation may be hard to read, but it basically just means that we store the upper 20-bits of the offset to some label in the upper 20-bits of the `rd` register.

The `JALR` offset can be 12-bits wide, so together (20 + 12 = 32) they make up a 32-bit address. `JAL` uses a 20-bit address, so if you need to call a function `foobar` further away than that we use a combination of `AUIPC` and `JALR` like this:

```as
ADDI   a0, zero, 2       # Set first argument to function  
ADDI   a1, zero, 3       # Set second argument.  
AUIPC  t0, foobar        # Store upper 20-bits address of foobar  
JALR   ra, foobar(t0)    
```

## Resources
-   [Venus](https://www.kvakil.me/venus/) — This is a natural next step to learn RISC-V. This supports more instructions and assembly directives. Also runs in browser for easy startup.
-   [RARS](https://github.com/TheThirdOne/rars) — A more complex environment but also with a lot more functionality. This is a Java app you got to download. But with this you can also simulate connections to different hardware such as keypads, seven-segment displays, bitmap displays etc. Lots of tools to analyze registers, memory, performance.
-   [Ripes](https://github.com/mortbopet/Ripes) —An advanced Qt based GUI application for simulating RISC-V, and writing assembly code. This is a quite a lot more advanced. It shows a diagram of the CPU, where you can look at values flowing between different functional units at each clock cycle. Harder for beginners as you don’t really step one instruction at a time, but a clock cycle, and an instruction will take multiple clock cycles to complete. It also simulates a pipeline so that several instructions are in flight at once.
-   [Assembly directives and instruction](https://michaeljclark.github.io/asm.html) — An overview by creator of the rv8 simulator which tells you want directives like `.text` `.data` means as well as pseudo instructions like `NOP`, `NOT`, `NEG` and `LI` means. Pseudo instruction are not actually defined in the ISA but shorthand for one or more common ISA instructions.

It is worth noting that a lot of these different assemblers use many of the same concepts and conventions. Many have e.g. an `ecall` instruction added which lets you call functions for printing out to console. Here are some examples of functions built into the Venus simulator: [Environmental Calls](https://github.com/kvakil/venus/wiki/Environmental-Calls).

There RISC-V tools for building executables which you can run in simulated environments but my focus in more on teaching and education rather than building any actual RISC-V systems so I will not focus on that here.